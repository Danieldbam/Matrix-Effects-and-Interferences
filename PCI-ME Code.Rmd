---
title: "Publication Ready PCI ME Article"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

### Reproducibility

```{r}
## This project uses renv for dependency management.
## R version required: 4.3.3

## Reproduce the computational environment
install.packages("renv", ask = FALSE)
renv::restore
```

# Load libraries

```{r}
## Core data + plotting
library(tidyverse)
library(readxl)
library(scales)
library(zoo)
library(patchwork)
library(RColorBrewer)
library(cowplot)

## Statistics / modelling
library(broom)
library(rstatix)
library(fuzzyjoin)
library(stringdist)
library(pracma)

## Tables / reporting
library(knitr)
library(kableExtra)
library(ggpubr)

## MS / metabolomics
library(xcms)
library(MassTools)
library(homologueDiscoverer)
library(classyfireR)

## Heatmaps / layout
library(pheatmap)
library(gridExtra)
library(grid)

## Utilities
library(here)
library(renv)
library(tinytex)
```

original filepath

```{r}
setwd("C:/Users/DanielMalheiro/Clinical Microbiomics/Teamwebsted - MS-Omics Team Folder/Daniel/PhD/Manuscript/Github/Matrix-Effects-and-Interferences")

```

## Figure 1. Flowrate

### Data extraction

```{r}
# -------------------------------
# File names (defined once)
# -------------------------------
PCI_data <- "Skyline-Exp04-KU-IS-PAN-PCI.tsv"
Pump_pressure_data <- "240815-PAN-001-Blank-1uM-05ulmin-pump pressure.csv"

# -------------------------------
# Load PCI chromatogram data
# -------------------------------
# Reads Skyline export containing chromatogram intensities and times
data <- read_tsv(
  here("Data", PCI_data)
)

# -------------------------------
# Load pump pressure data
# -------------------------------
# Reads pump pressure log; skip header metadata rows
Pressure_data <- read_csv(
  here("Data", Pump_pressure_data),
  skip = 3
)

# -------------------------------
# Prepare PCI data for analysis
# -------------------------------
# - Rename columns for clarity
# - Parse chromatogram metadata from filenames
# - Filter invalid / shutdown runs
# - Calculate normalized and offset intensities
data1 <- data %>%
  dplyr::rename(
    Chromatograms = FileName,
    Compound = PeptideModifiedSequence,
    Adduct = PrecursorCharge,
    Charge = ProductCharge
  ) %>%
  select(-IsotopeLabelType, -TotalArea, -FragmentIon) %>%
   mutate(
    Chromatograms = str_replace(Chromatograms, "Without", "0uM"),
    Chromatograms = str_replace(Chromatograms, "PCI", "00ulmin")) %>%
  separate(
    Chromatograms,
    into = c(
      "Date",
      "PAN",
      "Sequence_Number",
      "Sample",
      "Concentration",
      "Flow_Rate"
    ),
    sep = "-",
    remove = FALSE
  ) %>%
  mutate(    
    Sequence_Number = str_extract(Sequence_Number, "\\d+"),
    Concentration = str_extract(Concentration, "\\d+uM"),
    Flow_Rate = as.numeric(str_extract(Flow_Rate, "\\d+"))
  ) %>%
  filter(!str_detect(Chromatograms, regex("shutdown", ignore_case = TRUE))) #%>%
  #filter(Compound %in% c("Phenylalanine-d8-POS", "Phenylalanine-d8-NEG"))

data_intensity <- data1 %>%
  select(Chromatograms, Compound, Intensities) %>%
  separate_wider_delim(Intensities,
                       delim = ";",
                      names_sep = "",
                      too_few = "align_start") %>%
  mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))  
  
data_time <- data1 %>%
  select(Chromatograms,Compound, Times) %>%
  separate_wider_delim(Times,
                       delim = ";",
                       names_sep = "",
                       too_few = "align_start") %>%
  mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))  

combined_data <- data1 %>%
  select(-Intensities,-Times) %>%
  right_join(data_time, by = c("Chromatograms","Compound")) %>%
  right_join(data_intensity, by = c("Chromatograms","Compound"))

long_data <- combined_data %>%
    pivot_longer(
    cols = c(starts_with("Times"), starts_with("Intensities")),
    names_to = c(".value", "pair"),
    names_pattern = "(Times|Intensities)(\\d+)")

Pressure_data <- Pressure_data %>%
  dplyr::rename( "Time" = "Time(min)", "Pressure" = "ElutingPump_Pressure bar")

```

### Plot: Effect of PCI programmed flow rates

```{r}
# ---- Data preparation ----
small_data <- long_data %>%
  filter(Times >= 0, Times <= 20,
         Concentration == "5uM",
         Charge == 1,
         Compound == "Leucine d-10-POS",
         Sequence_Number != "000") %>%
  group_by(Flow_Rate) %>%
  mutate(
    Average = rollmean(Intensities, k = 9, fill = "extend", align = "left"),
    Normalized_Average = (Average - min(Average, na.rm = TRUE)) / 
                         (max(Average, na.rm = TRUE) - min(Average, na.rm = TRUE))
  ) %>%
  ungroup() %>%
  arrange(desc(Flow_Rate)) %>%
  mutate(
    Flow_Rate_Label = factor(paste0(Flow_Rate, " µL/min"), 
                             levels = paste0(sort(unique(Flow_Rate), decreasing = TRUE), " µL/min")),
    Flow_Rate_Rank = dense_rank(Flow_Rate),
    Offset = 0.1 * (Flow_Rate_Rank - 1),
    Offset_Average = Normalized_Average + Offset
  ) %>%
  filter(between(Times, 2, 6))

# Pressure transformation
intensity_range <- range(small_data$Offset_Average, na.rm = TRUE)

Pressure_data_filtered <- Pressure_data %>%
  filter(Time >= min(small_data$Times), Time <= max(small_data$Times)) %>%
  mutate(Scaled_Pressure = rescale(Pressure, to = intensity_range))

pressure_range <- range(Pressure_data$Pressure, na.rm = TRUE)
a <- diff(intensity_range) / diff(pressure_range)
b <- intensity_range[1] - a * pressure_range[1]
inv_rescale <- function(x) (x - b) / a

# Labeling for legend
small_data$Legend_Label <- small_data$Flow_Rate_Label
Pressure_data_filtered$Legend_Label <- "Pressure Curve"

# Color palette (Dark2 or Okabe–Ito)
n_colors <- length(unique(small_data$Flow_Rate_Label))
chromatogram_colors <- brewer.pal(min(n_colors, 8), "Dark2")

# ---- Create label data near the start of each curve ----
label_data <- small_data %>%
  filter(Times >= 2, Times <= 2.5) %>%
  group_by(Flow_Rate_Label) %>%
  slice_min(Times, with_ties = FALSE) %>%
  ungroup() %>%
  filter(Flow_Rate_Label != "Pressure Curve") %>%  # Remove Pressure Curve
  mutate(Offset_Label = Offset_Average + 0.02)     # Raise label above curve

# ---- Plot construction with above-curve labels ----
Figure.1 <- ggplot() +
  geom_line(data = small_data, aes(x = Times, y = Offset_Average, 
                                   color = Flow_Rate_Label,
                                   group = Flow_Rate_Label), size = 0.8) +
  geom_line(data = Pressure_data_filtered, aes(x = Time, y = Scaled_Pressure), 
            linetype = "longdash", color = "black", size = 1) +
  geom_vline(xintercept = 3.8, linetype = "dotted", color = "black", size = 1) +
  geom_vline(xintercept = 4.95, linetype = "dotted", color = "black", size = 1) +
  geom_text(
    data = label_data,
    aes(x = Times + 0.1, y = Offset_Label + 0.01, label = Flow_Rate_Label, color = Flow_Rate_Label),
    vjust = 0, size = 4.5, show.legend = FALSE
  ) +
  annotate("text",
           x = 3.8,
           y = max(small_data$Offset_Average, na.rm = TRUE) + 0.03,
           label = "25% B",
           size = 4.2,
           hjust = -0.1,
           vjust = -0.6) +
  annotate("text",
           x = 4.95,
           y = max(small_data$Offset_Average, na.rm = TRUE) + 0.03,
           label = "51% B",
           size = 4.2,
           hjust = -0.1,
           vjust = -0.6) +
  annotate("text",
           x = 4.4,
           y = max(Pressure_data_filtered$Scaled_Pressure, na.rm = TRUE) + 0.00,
           label = "Pressure Curve",
           color = "black",
           size = 4.5,
           hjust = 0.5) +
  labs(
    x = "Time (min)",
    y = "Normalized Intensity with Offset"
  ) +
  scale_y_continuous(
    sec.axis = sec_axis(~ inv_rescale(.), name = "Pressure (bar)")
  ) +
  scale_color_manual(
    values = setNames(chromatogram_colors, unique(small_data$Flow_Rate_Label))
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    legend.position = "none"
  )

# ---- Render Plot ----
print(Figure.1)


```

### Article figure 1.

```{r}
# define output directory inside repo

output_dir <- here("Figures")


ggsave(
  filename = file.path(output_dir, "Figure_1.png"),
  plot = Figure.1,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

ggsave(
  filename = file.path(output_dir, "Figure_1.tiff"),
  plot = Figure.1,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)

```

## Figure 2. Effect of PLR

### Data: faster to extract TIC using mzR

```{r}
# Set working directory #Change Dir
filepath <- "C:/Users/DanielMalheiro/Downloads/Exp7-241008/mzML-PAN"

# List all mzML files in the folder
mzml_files <- list.files(path = filepath, pattern = "*.mzML", full.names = TRUE)

extract_tic <- function(file_path) {
  # Open mzML file
  raw_data <- openMSfile(file_path)
  
  # Extract scan metadata
  header_info <- header(raw_data)
  
  # Extract TIC data
  tic_data <- data.frame(
    rt = header_info$retentionTime / 60,  # Convert RT to minutes
    intensity = header_info$totIonCurrent,
    polarity = header_info$polarity,
    filename = basename(file_path)  # Extract file name
  )
  
  return(tic_data)
}

# Extract TIC for all files
tic_list <- lapply(mzml_files, extract_tic)

tic_df_all <- bind_rows(tic_list)

# Process TIC Data
tic_df <- tic_df_all %>%
  # Remove file extension & split filename into metadata
  mutate(filename = str_remove(filename, "\\.mzML$")) %>%
  separate(filename, 
           into = c("Date", "Exp", "PAN", "Batch", "Sequence", "Wash", "Sample", "Dilution"), 
           sep = "-", 
           remove = FALSE,
           convert = TRUE) %>%
  # Keep metadata columns at the beginning
  select(filename, Date, Exp, PAN, Batch, Sequence, Wash, Sample, Dilution, everything()) %>%
  
  # Convert polarity to readable format
  mutate(polarity = ifelse(polarity == 1, "POS", "NEG")) %>%
  
  # Assign Scan numbers per filename & polarity
  group_by(filename, polarity) %>%
  mutate(Scan = row_number()) %>%
  ungroup() %>%
  
  # Sort and assign replicate numbers based on Wash & Sample
  arrange(Wash, Sample, Sequence) %>%
  group_by(Wash, Sample) %>%
  mutate(Replicate = dense_rank(Sequence)) %>%
  ungroup() %>%
  mutate(Sample = ifelse(Wash == "NoFilter" & Sample == "Blank", "Reference", Sample))

 tic_df <- tic_df %>%
  # Ensure Reference samples are retained for valid washes
  bind_rows(
    tic_df %>%
      filter(Sample == "Reference") %>%
      select(-Wash) %>%
      crossing(Wash = unique(tic_df$Wash[tic_df$Wash != "NoFilter"]))
  ) %>%
  
  # Filter out "NoFilter" and keep only the valid Wash types
  filter(Wash != "NoFilter") %>%
  filter(Wash %in% c("NoFilter", "22x", "08x", "04x", "NoWash", "PPT")) %>%
  
  # Rename Sample types for clarity
  mutate(Sample = case_when(
    Sample == "Reference" ~ "Solvent",
    Sample == "Blank" ~ "Process",
    TRUE ~ Sample
  )) %>%
   mutate(Average = rollmean(intensity, k = 9, fill = NA, align = "left")) %>%
   filter(between(rt, 0, 15))
```

### Plot:

```{r}
# -----------------------------
# Define wash order and labels
# -----------------------------
wash_order <- c("PPT", "NoWash", "22x")

wash_labels <- c(
  "PPT"    = "PPT",
  "NoWash" = "PLR unwashed",
  "22x"    = "PLR 22x washed"
)

# -----------------------------
# Calculate max intensity
# -----------------------------
max_intensity <- max(tic_df$Average, na.rm = TRUE)

# -----------------------------
# Define vertical offsets
# -----------------------------
offsets <- c(
  "22x"    = 0,
  "NoWash" = max_intensity * 0.2,
  "PPT"    = max_intensity * 0.40
)

# -----------------------------
# Data for line-end labels
# -----------------------------
label_df <- tic_df %>%
  filter(
    Sample == "NIST",
    Wash %in% wash_order,
    Replicate == 3,
    polarity == "POS"
  ) %>%
  group_by(Wash) %>%
  slice_max(rt, n = 1) %>%
  ungroup() %>%
  mutate(
    Average_offset = Average + offsets[Wash],
    label = wash_labels[Wash]
  )

# -----------------------------
# Create the plot
# -----------------------------
Figure.2 <- tic_df %>% 
  filter(
    Sample == "NIST",
    Wash %in% wash_order,
    Replicate == 3,
    polarity == "POS"
  ) %>%
  mutate(
    Average_offset = Average + offsets[Wash]
  ) %>%
  ggplot(aes(x = rt, y = Average_offset,
             group = Wash, color = Wash)) +
  
  # Shaded regions
  annotate(
    "rect",
    xmin = 7.5, xmax = 14,
    ymin = -Inf, ymax = Inf,
    fill = "gray80", alpha = 0.5
  ) +
  annotate(
    "rect",
    xmin = 5, xmax = 7,
    ymin = -Inf, ymax = Inf,
    fill = "gray90", alpha = 0.5
  ) +
  
  
  # TIC lines
  geom_line(size = 0.9) +
  
  # Direct labels at line ends
  geom_text(
    data = label_df,
    aes(x = 1.2, y = Average_offset, label = label),
    hjust = 0,
    vjust = 3,
    size = 4.5,
    fontface = "bold",
    show.legend = FALSE
  ) +
  
  # Annotations
  annotate(
    "text",
    x = 10.75,
    y = max_intensity * 1.25,
    label = "Phospholipids",
    size = 5,
    fontface = "bold"
  ) +
  annotate(
    "text",
    x = 6,
    y = max_intensity * 1.25,
    label = "Filter Contaminants",
    size = 5,
    fontface = "bold"
  ) +
  
  # Axis labels
  labs(
    x = "Retention Time (min)",
    y = "Total Ion Current"
  ) +
  
  # Color scale (unchanged)
  scale_color_brewer(
    palette = "Dark2"
  ) +
  
  # Use coord_cartesian to avoid clipping offsets
  coord_cartesian(
    ylim = c(0, max_intensity * 1.3)
  ) +
  
  # Theme cleanup
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black")
  )

# -----------------------------
# Print plot
# -----------------------------
print(Figure.2)


```

### Article figure 2.

```{r}

# -----------------------------
# Save output
# -----------------------------
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_2.png"),
  plot = Figure.2,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

# Save TIFF 
ggsave(
  filename = file.path(output_dir, "Figure_2.tiff"),
  plot = Figure.2,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)

```

## Figure 3. ME PPT vs PLR unwashed

### Data extraction

```{r}
file <- "Skyline-PCI-Exp7-241008.tsv" 
data <- read_tsv(here("Data", file))
replacements <- c(
  "Leucine d10" = "Leucine-d10" ,
   "Glutamic acid-d5"= "GlutamicAcid-d5",
   "DL-Tryptophan-d5" = "Tryptophan-d5",
   "Stearic-d35 (18:0)" = "StearicAcid-d35",
   "Cholic acid-d4" = "CholicAcid-d4")

data2 <- data %>%
  dplyr::rename(
    Chromatograms = FileName,
    Compound = PeptideModifiedSequence,
    Adduct = PrecursorCharge,
    Charge = ProductCharge
  ) %>%
  select(-IsotopeLabelType, -TotalArea, -FragmentIon) %>%
  separate(
    Chromatograms,
    into = c(
      "Date",
      "Exp",
      "PAN",
      "Batch",
      "Sequence",
      "Wash",
      "Sample",
      "Dilution"),
    sep = "-",
    remove = FALSE
  ) %>%
  mutate(
    Sample = str_remove(Sample, "\\.raw"),
    Dilution = str_remove(Dilution,"\\.raw"),
    Wash = str_remove(Wash,"\\.raw"),
    Compound = replace(Compound, Compound == "#N/A", "TIC"),
    Compound = recode(Compound, !!!replacements),  # Apply replacements
    Sequence = as.numeric(Sequence),
    Dilution = as.factor(Dilution)
  ) %>%
  select(-Batch,-Exp) %>%
  arrange(Date) %>%
  filter(#Sample %in% c("Process", "NIST"),
         Adduct != "[M35H2-H]",
        Adduct != "[M5H2+H]",
        Compound != "Isoleucine-13C6",
        Compound != "Arginine-13C6") %>%
  group_by(Wash, Sample, Compound, Charge) %>%
  mutate(Replicate = row_number()) %>%
 ungroup() %>%
  select(1:5, Replicate, everything()) %>%
  #filter(Replicate <= 3) %>%
  mutate(Sample = ifelse(Wash == "NoFilter" & Sample == "Blank", "Reference", Sample)) %>%
   filter(Compound != "TIC") 

# Get unique washes to replicate Reference for each wash
unique_washes <- unique(data2$Wash)
print(unique_washes)

# Add Reference sample for all washes except "NoFilter"
data2 <- data2 %>%
  bind_rows(
    data2 %>%
      filter(Sample == "Reference") %>%
      select(-Wash) %>%  # Remove the existing Wash column
      crossing(Wash = unique(data2$Wash[data2$Wash != "NoFilter"]))  # Add each wash except "NoFilter"
  ) %>%
filter(Wash != "NoFilter") %>%
filter(Wash %in% c("NoFilter", "22x", "08x", "04x","NoWash","PPT")) %>%
   mutate(
    Sample = case_when(
      Sample == "Reference" ~ "Solvent",
      Sample == "Blank" ~ "Process",
      TRUE ~ Sample))  

unique_washes <- unique(data2$Wash) %>% print()
unique_sample <- unique(data2$Sample) %>% print()

data_intensity <- data2 %>%
  select(Chromatograms, Compound, Intensities) %>%
  separate_wider_delim(Intensities,
                       delim = ";",
                      names_sep = "",
                      too_few = "align_start") %>%
  mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))  
  
data_time <- data2 %>%
  select(Chromatograms,Compound, Times) %>%
  separate_wider_delim(Times,
                       delim = ";",
                       names_sep = "",
                       too_few = "align_start") %>%
  mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))

combined_data <- data2 %>%
  select(-Intensities, -Times) %>%
  right_join(
    data_time,
    by = c("Chromatograms", "Compound"),
    relationship = "many-to-many"
  ) %>%
  right_join(
    data_intensity,
    by = c("Chromatograms", "Compound"),
    relationship = "many-to-many"
  )

long_data <- combined_data %>%
  pivot_longer(
    cols = c(starts_with("Times"), starts_with("Intensities")),
    names_to = c(".value", "Scan"),
    names_pattern = "(Times|Intensities)(\\d+)") %>%
  mutate(
    Scan = as.numeric(Scan),
    Intensities = if_else(Intensities == 0, 1, Intensities)  
  ) %>%
  filter(Times >= 0, Times <= 15) %>%
  mutate(Average = rollmean(Intensities, k = 9, fill = NA, align = "left"))
```

### Plot: Carnitine and Leucine PPT vs NoWash

```{r}
# Define x-axis limits
x_limits <- c(0, 14)

# Filter data
filtered_data <- long_data %>%
  filter(between(Times, x_limits[1], x_limits[2]),
         Compound %in% c("Carnitine-d9", "Leucine-d10"),
         Wash %in% c("PPT","NoWash"),
          Replicate %in% 1:8 ) %>%
  filter(!(Sample == "NIST" & Replicate >= 4)) #%>%
 # filter(!(Replicate %in% c("1","2","3", "4","6") & Sample == "Solvent")) %>%
  #filter(!(Replicate %in% c("4", "5","7","8") & Sample == "Solvent"))

# Step 1: Create Summary Table for Filtered Data (Plot Data)
summary_table_F <- filtered_data %>%
  group_by(Scan, Compound, Wash) %>%
  summarise(
    avg_time = mean(Times, na.rm = TRUE),
    Process = mean(Average[Sample == "Process"], na.rm = TRUE),
    NIST = mean(Average[Sample == "NIST"], na.rm = TRUE),
    Solvent = mean(Average[Sample == "Solvent"], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    # Calculate Matrix Effects
    Matrix_Effect_NIST_Process = ((NIST / Process) * 100) - 100,
    Matrix_Effect_Process_Solvent = ((Process / Solvent) * 100) - 100,
    Matrix_Effect_NIST_Solvent = ((NIST / Solvent) * 100) - 100
  ) %>%
  pivot_longer(
    cols = starts_with("Matrix_Effect"),
    names_to = "Comparison",
    values_to = "Matrix_Effect"
  ) %>%
  group_by(Comparison, avg_time, Scan, Compound, Wash) %>%
  summarise(
    # Aggregate Matrix Effects and Calculate Min/Max
    Matrix_Effect = mean(Matrix_Effect, na.rm = TRUE),
   .groups = "drop"
  ) %>%
  mutate(
    # Recode Comparisons for Better Readability
    Comparison = recode(Comparison,
                        "Matrix_Effect_NIST_Process" = "NIST / Process",
                        "Matrix_Effect_Process_Solvent" = "Process / Solvent",
                        "Matrix_Effect_NIST_Solvent" = "NIST / Solvent")
  )

# Relabel and reorder Wash levels
summary_table_F <- summary_table_F %>%
  mutate(Wash = recode(Wash, "NoWash" = "PLR unwashed"),
         Wash = factor(Wash, levels = c("PPT", "PLR unwashed")))

# Calculate global max intensity for annotation height
max_intensity <- max(summary_table_F$Matrix_Effect, na.rm = TRUE)

# Create the plot
Figure.3 <- summary_table_F %>%
  filter(Comparison == "NIST / Solvent") %>%
  ggplot(aes(x = avg_time)) +
  
  # Matrix effect lines
  geom_line(aes(y = Matrix_Effect, color = Compound), size = 0.8) +
  
  # Reference line
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.7) +
  
  # Shaded regions
  annotate("rect", xmin = 7.5, xmax = 14, ymin = -Inf, ymax = Inf, 
           fill = "gray80", alpha = 0.25) +
  annotate("text", x = 4.8, y = 5, label = "*", size = 6, fontface = "bold") +
 geom_rect(data = summary_table_F %>% filter(Wash == "PLR unwashed") %>% distinct(Wash, Compound),
          aes(xmin = 5, xmax = 7, ymin = -Inf, ymax = Inf),
          fill = "gray70", alpha = 0.25, inherit.aes = FALSE)+


  # Text annotations (for PPT rows only)
  geom_text(data = summary_table_F %>% filter(Wash == "PPT") %>% distinct(Wash, Compound),
            
            aes(x = 10.75, y = max_intensity * 1.05, label = "Phospholipids"), 
            size = 4, fontface = "bold", hjust = 0.5, inherit.aes = FALSE) +
  geom_text(data = summary_table_F %>% filter(Wash == "PLR unwashed") %>% distinct(Wash, Compound),
            aes(x = 6, y = max_intensity * 1.05, label = "Filter Contaminants"), 
            size = 4, fontface = "bold", hjust = 0.5, inherit.aes = FALSE) +

  facet_grid(Wash ~ Compound) +
  labs(
    x = "Retention Time (mins)",
    y = "Matrix Effect (%)",
    color = "Compound"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text.y = element_text(angle = 0),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.margin = margin(5, 10, 5, 5, unit = "mm")
  )

# Display
print(Figure.3)
```

### Article figure 3.

```{r}

# Save output
output_dir <- here("Figures")
output_dir <- "C:/Users/DanielMalheiro/OneDrive - Clinical Microbiomics/Documents/R scripts/PCI ME Figures"

# Save as PNG
ggsave(
  filename = file.path(output_dir, "Figure_3.png"),
  plot = Figure.3,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

# Save as TIFF
ggsave(
  filename = file.path(output_dir, "Figure_3.tiff"),
  plot = Figure.3,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## Figure 4. ME and Blanks

### Data Extraction 1 and 2

```{r}

# Define axis limits
x_limits <- c(0, 13)
zoom_limits <- c(4,5 )
vline_positions <- c(4.375, 4.825)

# Filter data
filtered_data_1 <- long_data %>%
  filter(
    between(Times, x_limits[1], x_limits[2]),
    Compound == "Leucine-d10",
    Wash %in% c("PPT", "NoWash", "22x"),
    Replicate %in% 1:8,
   !(Sample == "NIST" & Replicate >= 4),
    #(Replicate %in% c("5", "7", "8") & Sample == "Solvent")
  ) %>%
  mutate(Wash = factor(Wash, levels = c("22x", "NoWash", "PPT")))

# Create replicate summary
replicate_counts <- filtered_data_1 %>%
  group_by(Scan, Wash, Sample) %>%
  summarise(n = n_distinct(Replicate), .groups = "drop") %>%
  pivot_wider(names_from = Sample, values_from = n, values_fill = 0) %>%
  mutate(
    Process_n = coalesce(Process, 0),
    NIST_n = coalesce(NIST, 0),
    Solvent_n = coalesce(Solvent, 0)
  )

# Summary table
summary_table_1 <- filtered_data_1 %>%
  group_by(Scan, Wash, Compound) %>%
  summarise(
    avg_time     = mean(Times, na.rm = TRUE),
    Process_mean = mean(Average[Sample == "Process"], na.rm = TRUE),
    Process_sd   = sd(Average[Sample == "Process"], na.rm = TRUE),
    NIST_mean    = mean(Average[Sample == "NIST"], na.rm = TRUE),
    NIST_sd      = sd(Average[Sample == "NIST"], na.rm = TRUE),
    Solvent_mean = mean(Average[Sample == "Solvent"], na.rm = TRUE),
    Solvent_sd   = sd(Average[Sample == "Solvent"], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  left_join(replicate_counts, by = c("Scan", "Wash")) %>%
  mutate(
    Process_se = Process_sd / sqrt(Process_n),
    NIST_se    = NIST_sd    / sqrt(NIST_n),
    Solvent_se = Solvent_sd / sqrt(Solvent_n),
    t_process  = qt(0.975, df = pmax(Process_n - 1, 1)),
    t_nist     = qt(0.975, df = pmax(NIST_n - 1, 1)),
    t_solvent  = qt(0.975, df = pmax(Solvent_n - 1, 1)),
    Process_lower = Process_mean - t_process * Process_se,
    Process_upper = Process_mean + t_process * Process_se,
    NIST_lower    = NIST_mean    - t_nist * NIST_se,
    NIST_upper    = NIST_mean    + t_nist * NIST_se,
    Solvent_lower = Solvent_mean - t_solvent * Solvent_se,
    Solvent_upper = Solvent_mean + t_solvent * Solvent_se,
    Matrix_Effect_NIST_Process     = ((NIST_mean / Process_mean) * 100) - 100,
    Matrix_Effect_Process_Solvent = ((Process_mean / Solvent_mean) * 100) - 100,
    Matrix_Effect_NIST_Solvent     = ((NIST_mean / Solvent_mean) * 100) - 100,
    ME_NS_mean  = ((NIST_mean / Solvent_mean) * 100) - 100,
    ME_NS_se    = abs((NIST_mean / Solvent_mean) * 100) *
                  sqrt((NIST_se / NIST_mean)^2 + (Solvent_se / Solvent_mean)^2),
    t_ME        = pmax(t_nist, t_solvent, na.rm = TRUE),
    ME_NS_lower = ME_NS_mean - t_ME * ME_NS_se,
    ME_NS_upper = ME_NS_mean + t_ME * ME_NS_se
  ) %>%
  pivot_longer(
    cols = starts_with("Matrix_Effect"),
    names_to = "Comparison",
    values_to = "Matrix_Effect"
  ) %>%
  mutate(
    Comparison = recode(Comparison,
      "Matrix_Effect_NIST_Process"     = "NIST / Process",
      "Matrix_Effect_Process_Solvent" = "Process / Solvent",
      "Matrix_Effect_NIST_Solvent"     = "NIST / Solvent")
  ) %>%
    mutate(
   Wash = recode(Wash,
                  "22x" = "22x wash PLR", #previously "PLR 22x wash"
                  "NoWash" = "Unwashed PLR"), #previously "PLR unwashed"
    Wash = factor(Wash, levels = c("22x wash PLR", "Unwashed PLR", "PPT"))
  )

# Global limits based on new CI
global_min_y <- min(summary_table_1$ME_NS_lower, na.rm = TRUE)
global_max_y <- max(summary_table_1$ME_NS_upper, na.rm = TRUE)

# Significant regions
sig_regions <- summary_table_1 %>%
  filter(Comparison == "NIST / Solvent") %>%
  filter(between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  mutate(
    CI_overlap = !(Solvent_lower > NIST_upper | Solvent_upper < NIST_lower),
    Significant = !CI_overlap
  ) %>%
  group_by(Wash) %>%
  arrange(avg_time) %>%
  mutate(group = with(rle(Significant), rep(seq_along(lengths), lengths))) %>%
  filter(Significant) %>%
  group_by(Wash, group) %>%
  summarise(
    xmin = min(avg_time),
    xmax = max(avg_time),
    y = max(c(NIST_mean, Solvent_mean), na.rm = TRUE) * 1.05,
    .groups = "drop"
  ) %>%
  filter( xmin != xmax)

sig_regions_ME <- summary_table_1 %>%
  filter(Comparison == "NIST / Solvent") %>%
  filter(between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  mutate(
    Significant = ME_NS_lower > 0 | ME_NS_upper < 0  # CI excludes 0
  ) %>%
  group_by(Wash) %>%
  arrange(avg_time) %>%
  mutate(group = with(rle(Significant), rep(seq_along(lengths), lengths))) %>%
  filter(Significant) %>%
  group_by(Wash, group) %>%
  summarise(
    xmin = min(avg_time),
    xmax = max(avg_time),
    y = 40,          # bracket at 40%
    label_y = y + 0.2 * y,    
    .groups = "drop"
  ) %>%
  filter( xmin != xmax)


# --- Filter with selected Solvent replicates removed ---
filtered_data_2 <- long_data %>%
  filter(
    between(Times, x_limits[1], x_limits[2]),
    Compound == "Leucine-d10",
    Wash %in% c("PPT", "NoWash", "22x"),
    Replicate %in% 1:8,
    !(Sample == "NIST" & Replicate >= 4),
    !(Replicate %in% c("1", "2", "3", "4", "6") & Sample == "Solvent")
    #!(Replicate %in% c("5", "7", "8") & Sample == "Solvent")
  ) %>%
  mutate(Wash = factor(Wash, levels = c("22x", "NoWash", "PPT")))

# --- Replicate counts ---
replicate_counts_2 <- filtered_data_2 %>%
  group_by(Scan, Wash, Sample) %>%
  summarise(n = n_distinct(Replicate), .groups = "drop") %>%
  pivot_wider(names_from = Sample, values_from = n, values_fill = 0) %>%
  mutate(
    Process_n = coalesce(Process, 0),
    NIST_n = coalesce(NIST, 0),
    Solvent_n = coalesce(Solvent, 0)
  )

# --- Summary table with propagated error ---
summary_table_2 <- filtered_data_2 %>%
  group_by(Scan, Wash, Compound) %>%
  summarise(
    avg_time     = mean(Times, na.rm = TRUE),
    Process_mean = mean(Average[Sample == "Process"], na.rm = TRUE),
    Process_sd   = sd(Average[Sample == "Process"], na.rm = TRUE),
    NIST_mean    = mean(Average[Sample == "NIST"], na.rm = TRUE),
    NIST_sd      = sd(Average[Sample == "NIST"], na.rm = TRUE),
    Solvent_mean = mean(Average[Sample == "Solvent"], na.rm = TRUE),
    Solvent_sd   = sd(Average[Sample == "Solvent"], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  left_join(replicate_counts_2, by = c("Scan", "Wash")) %>%
  mutate(
    Process_se = Process_sd / sqrt(Process_n),
    NIST_se    = NIST_sd    / sqrt(NIST_n),
    Solvent_se = Solvent_sd / sqrt(Solvent_n),
    t_process  = qt(0.975, df = pmax(Process_n - 1, 1)),
    t_nist     = qt(0.975, df = pmax(NIST_n - 1, 1)),
    t_solvent  = qt(0.975, df = pmax(Solvent_n - 1, 1)),
    Matrix_Effect_NIST_Solvent     = ((NIST_mean / Solvent_mean) * 100) - 100,
    ME_NS_mean  = ((NIST_mean / Solvent_mean) * 100) - 100,
    ME_NS_se    = abs((NIST_mean / Solvent_mean) * 100) *
                  sqrt((NIST_se / NIST_mean)^2 + (Solvent_se / Solvent_mean)^2),
    t_ME        = pmax(t_nist, t_solvent, na.rm = TRUE),
    ME_NS_lower = ME_NS_mean - t_ME * ME_NS_se,
    ME_NS_upper = ME_NS_mean + t_ME * ME_NS_se
  ) %>%
  pivot_longer(
    cols = starts_with("Matrix_Effect"),
    names_to = "Comparison",
    values_to = "Matrix_Effect"
  ) %>%
  mutate(
    Comparison = recode(Comparison,
      "Matrix_Effect_NIST_Process"     = "NIST / Process",
      "Matrix_Effect_Process_Solvent" = "Process / Solvent",
      "Matrix_Effect_NIST_Solvent"     = "NIST / Solvent")
  ) %>%
   mutate(
   Wash = recode(Wash,
                  "22x" = "22x wash PLR", #previously "PLR 22x wash"
                  "NoWash" = "Unwashed PLR"), #previously "PLR unwashed"
    Wash = factor(Wash, levels = c("22x wash PLR", "Unwashed PLR", "PPT"))
  )

# --- Significant regions (NIST vs Solvent) ---
sig_regions_2 <- summary_table_2 %>%
  filter(between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  mutate(
    CI_overlap = !(Solvent_mean - t_solvent * Solvent_se > NIST_mean + t_nist * NIST_se |
                   Solvent_mean + t_solvent * Solvent_se < NIST_mean - t_nist * NIST_se),
    Significant = !CI_overlap
  ) %>%
  group_by(Wash) %>%
  arrange(avg_time) %>%
  mutate(group = with(rle(Significant), rep(seq_along(lengths), lengths))) %>%
  filter(Significant) %>%
  group_by(Wash, group) %>%
  summarise(
    xmin = min(avg_time),
    xmax = max(avg_time),
    y = max(c(NIST_mean, Solvent_mean), na.rm = TRUE) * 1.05,
    .groups = "drop"
  )  %>%
  filter( xmin != xmax)

sig_regions_ME_2 <- summary_table_2 %>%
  filter(Comparison == "NIST / Solvent") %>%
  filter(between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  mutate(
    Significant = ME_NS_lower > 0 | ME_NS_upper < 0  # CI excludes 0
  ) %>%
  group_by(Wash) %>%
  arrange(avg_time) %>%
  mutate(group = with(rle(Significant), rep(seq_along(lengths), lengths))) %>%
  filter(Significant) %>%
  group_by(Wash, group) %>%
  summarise(
    xmin = min(avg_time),
    xmax = max(avg_time),
    y = 40,          # bracket at 40%
    label_y = y + 0.2 * y,    
    .groups = "drop"
  ) %>%
  filter( xmin != xmax)

```

### Plot: 1

```{r}

sample_colors <- c(
  "Solvent" = "#6baed6",  # light blue
  "NIST"    = "#d95f02"   # muted orange (Plasma)
)



# ---- PLOT A: Full Matrix Effect ----
plot_matrix_effect_1 <- summary_table_1 %>%
  filter(Comparison == "NIST / Solvent") %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean, color = Wash)) +
  geom_ribbon(aes(ymin = ME_NS_lower, ymax = ME_NS_upper, fill = Wash), alpha = 0.2, color = NA) +
  geom_line(size = 0.8) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.7) +
  annotate("rect", xmin = zoom_limits[1], xmax = zoom_limits[2], ymin = -Inf, ymax = Inf,
           fill = "gray", alpha = 0.5) +
  facet_wrap(~ Wash) +
  coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  scale_x_continuous(breaks = c(0, 5, 10)) +
  labs(
    title = NULL,
    #x = "Retention Time (mins)",
    y = "Matrix Effect (%)",
    color = "Wash",
    fill = "Wash"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.title.x = element_blank(),
    strip.text = element_text(size = 9),  
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.text.y = element_text(angle = 0)
  )

# ---- PLOT B: Zoomed-In Matrix Effect ----
plot_matrix_effect_zoom_1 <- summary_table_1 %>%
  filter(Comparison == "NIST / Solvent", between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean, color = Wash)) +
  geom_ribbon(aes(ymin = ME_NS_lower, ymax = ME_NS_upper, fill = Wash), alpha = 0.2, color = NA) +
  geom_line(size = 0.8) +
  geom_segment(data = sig_regions_ME,
               aes(x = xmin, xend = xmax, y = y, yend = y),
               inherit.aes = FALSE, color = "black", size = 0.8) +
  geom_text(data = sig_regions_ME,
            aes(x = (xmin + xmax) / 2, y = label_y, label = "*"),
            inherit.aes = FALSE, size = 6, fontface = "bold", color = "black") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.7) +
  geom_vline(xintercept = vline_positions, linetype = "dotted", color = "black") +
  facet_wrap(~ Wash) +
  coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  labs(x = NULL, y = "Matrix Effect (%)") +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    axis.title.x = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )

# ---- PLOT C: EIC + Brackets ----
plot_EIC_sig_brackets1 <- ggplot(
  summary_table_1 %>%
    filter(
      Comparison == "NIST / Solvent",
      between(avg_time, zoom_limits[1], zoom_limits[2])
    )
) +
  # Solvent ribbon
  geom_ribbon(
    aes(
      x = avg_time,
      ymin = Solvent_lower,
      ymax = Solvent_upper,
      fill = "Solvent"
    ),
    alpha = 0.3
  ) +
  # Plasma (NIST) ribbon
  geom_ribbon(
    aes(
      x = avg_time,
      ymin = NIST_lower,
      ymax = NIST_upper,
      fill = "NIST"
    ),
    alpha = 0.3
  ) +
  # Mean lines
  geom_line(
    aes(x = avg_time, y = Solvent_mean, color = "Solvent"),
    size = 0.8
  ) +
  geom_line(
    aes(x = avg_time, y = NIST_mean, color = "NIST"),
    size = 0.8
  ) +
  geom_vline(xintercept = vline_positions, linetype = "dotted") +
  facet_grid(~ Wash) +
  scale_x_continuous(
    breaks = seq(4, 5, by = 0.25),
    labels = c("4", "", "4.5", "", "5")
  ) +
  scale_color_manual(values = sample_colors) +
  scale_fill_manual(values = sample_colors) +
  labs(
    x = "Retention Time (mins)",
    y = "Intensity",
    color = "Sample",
    fill  = "Sample"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",   # enable only if you need legend extraction
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.text = element_blank(),
    axis.text.x = element_text(hjust = 0.5)
  )


# ---- Combine vertically ----
MEvsEIC_AllRep <- (plot_matrix_effect_1 / plot_matrix_effect_zoom_1 / plot_EIC_sig_brackets1) +
  plot_layout(heights = c(2, 2, 2))

# ---- Display ----
print(MEvsEIC_AllRep)


```

### Plot: 2

```{r}

global_min_y <- min(summary_table_2$ME_NS_lower, na.rm = TRUE)
global_max_y <- max(summary_table_2$ME_NS_upper, na.rm = TRUE)

# ---- PLOT A: Full Matrix Effect ----
plot_matrix_effect_2 <- summary_table_2 %>%
  filter(Comparison == "NIST / Solvent") %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean, color = Wash)) +
  geom_ribbon(aes(ymin = ME_NS_lower, ymax = ME_NS_upper, fill = Wash), alpha = 0.2, color = NA) +
  geom_line(size = 0.8) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.7) +
  annotate("rect", xmin = zoom_limits[1], xmax = zoom_limits[2], ymin = -Inf, ymax = Inf,
           fill = "gray", alpha = 0.5) +
  facet_wrap(~ Wash) +
  coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  scale_x_continuous(breaks = c(0, 5, 10)) +
  labs(
    title = NULL,
    #x = "Retention Time (mins)",
    y = "Matrix Effect (%)",
    color = "Wash",
    fill = "Wash"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.title.x = element_blank(),
    strip.text = element_text(size = 9),  
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.text.y = element_text(angle = 0),
    axis.title.y = element_blank()
  )

# ---- PLOT B: Zoomed-In Matrix Effect ----
plot_matrix_effect_zoom_2 <- summary_table_2 %>%
  filter(Comparison == "NIST / Solvent", between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean, color = Wash)) +
  geom_ribbon(aes(ymin = ME_NS_lower, ymax = ME_NS_upper, fill = Wash), alpha = 0.2, color = NA) +
  geom_line(size = 0.8) +
  geom_segment(data = sig_regions_ME_2,
               aes(x = xmin, xend = xmax, y = y, yend = y),
               inherit.aes = FALSE, color = "black", size = 0.8) +
  geom_text(data = sig_regions_ME_2,
            aes(x = (xmin + xmax) / 2, y = label_y, label = "*"),
            inherit.aes = FALSE, size = 6, fontface = "bold", color = "black") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.7) +
  geom_vline(xintercept = vline_positions, linetype = "dotted", color = "black") +
  facet_wrap(~ Wash) +
  coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  labs(x = NULL, y = "Matrix Effect (%)") +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_blank()
  )

# ---- PLOT C: EIC + Brackets ----
plot_EIC_sig_brackets2 <- ggplot(
  summary_table_2 %>%
    filter(
      Comparison == "NIST / Solvent",
      between(avg_time, zoom_limits[1], zoom_limits[2])
    )
) +
  # Solvent ribbon
  geom_ribbon(
    aes(
      x = avg_time,
      ymin = Solvent_mean - t_solvent * Solvent_se,
      ymax = Solvent_mean + t_solvent * Solvent_se,
      fill = "Solvent"
    ),
    alpha = 0.3
  ) +
  # Plasma (NIST) ribbon
  geom_ribbon(
    aes(
      x = avg_time,
      ymin = NIST_mean - t_nist * NIST_se,
      ymax = NIST_mean + t_nist * NIST_se,
      fill = "NIST"
    ),
    alpha = 0.3
  ) +
  # Mean lines
  geom_line(
    aes(x = avg_time, y = Solvent_mean, color = "Solvent"),
    size = 0.8
  ) +
  geom_line(
    aes(x = avg_time, y = NIST_mean, color = "NIST"),
    size = 0.8
  ) +
  geom_vline(xintercept = vline_positions, linetype = "dotted") +
  facet_grid(~ Wash) +
  scale_x_continuous(
    breaks = seq(4, 5, by = 0.25),
    labels = c("4", "", "4.5", "", "5")
  ) +
  scale_color_manual(values = sample_colors) +
  scale_fill_manual(values = sample_colors) +
  labs(
    x = "Retention Time (mins)",
    y = "Intensity",
    color = "Sample",
    fill  = "Sample"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",   # turn on only if you want legend
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.text = element_blank(),
    axis.text.x = element_text(hjust = 0.5)
  )

  

# ---- Combine vertically ----
MEvsEIC_SomeRep <- (plot_matrix_effect_2 / plot_matrix_effect_zoom_2 / plot_EIC_sig_brackets2) +
  plot_layout(heights = c(2, 1, 2))

# ---- Display ----
print(MEvsEIC_SomeRep)

```

### Plot: Combined 1 and 2

```{r}

legend_plot <- plot_EIC_sig_brackets2 +
  theme(
    legend.position = c(0.53, 0),     # slight shift right
    legend.justification = c(0.5, 0),
    legend.direction = "horizontal",  # <-- FORCE horizontal keys
    legend.box = "horizontal",
    legend.title = element_blank()
  )

shared_legend <- get_legend(legend_plot)


# ================================
# 2. REMOVE legends from ALL plots
# ================================
plot_matrix_effect_1      <- plot_matrix_effect_1      + theme(legend.position = "none")
plot_matrix_effect_zoom_1 <- plot_matrix_effect_zoom_1 + theme(legend.position = "none")
plot_EIC_sig_brackets1    <- plot_EIC_sig_brackets1    + theme(legend.position = "none")

plot_matrix_effect_2      <- plot_matrix_effect_2      + theme(legend.position = "none")
plot_matrix_effect_zoom_2 <- plot_matrix_effect_zoom_2 + theme(legend.position = "none")
plot_EIC_sig_brackets2    <- plot_EIC_sig_brackets2    + theme(legend.position = "none")

# ================================
# 3. Build sub-layouts (NO legends)
# ================================
MEvsEIC_AllRep <-
  plot_matrix_effect_1 /
  plot_matrix_effect_zoom_1 /
  plot_EIC_sig_brackets1

MEvsEIC_SomeRep <-
  plot_matrix_effect_2 /
  plot_matrix_effect_zoom_2 /
  plot_EIC_sig_brackets2

main_figure <- MEvsEIC_AllRep | MEvsEIC_SomeRep

# ================================
# 4. Add legend as a bottom row
# ================================
Combined_MEvsEIC <- plot_grid(
  main_figure,
  shared_legend,
  ncol = 1,
  rel_heights = c(1, 0.08)  # adjust if legend is too tall/short
)

# ================================
# 5. Display
# ================================
print(Combined_MEvsEIC)
```

### Article figure 4.

```{r}
# Define base file path
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_4.png"),
  plot = Combined_MEvsEIC,
  width = 20,
  height = 20,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_4.tiff"),
  plot = Combined_MEvsEIC,
  width = 20,
  height = 20,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)

```

## Figure 5. Contaminants

### Data:

```{r}

# Set working directory #Change dir
filepath <- "C:/Users/DanielMalheiro/Downloads/Exp7-241008/mzML-PAN"
setwd(filepath)
list.files()

# Load file and extract scan
file_22x <- "241008-Exp-PAN-1-014-22x-NIST.mzML" 
xraw <- xcmsRaw(file_22x)
scan_index <- 787

# Extract spectrum at scan 747
spectrum <- getScan(xraw, scan_index)
mz_vals <- spectrum[, 1]
intensities <- spectrum[, 2]

# Filter for m/z 646–656
scan787_data <- tibble(mz = mz_vals, intensity = intensities) %>%
  filter(between(mz, 647, 656)) %>%
  arrange(mz)

```

### Plot 1:

```{r}

# Identify peaks ~1 m/z apart using simple local maxima logic
annotated_peaks <- scan787_data %>%
  mutate(diff = c(NA, diff(mz))) %>%
  filter(
    intensity == max(intensity, na.rm = TRUE) |  
    (lag(intensity, 1, default = 0) < intensity &
     lead(intensity, 1, default = 0) < intensity)
  ) %>%
  filter(!duplicated(round(mz))) %>%   # avoid dense peaks
  arrange(mz)                          # ensure sorted m/z for spacing below

# ------------------------------------------------------------
# Compute Δm/z, mean, SD
# ------------------------------------------------------------

peak_spacing <- annotated_peaks %>%
  mutate(delta_mz = mz - lag(mz)) %>%
  filter(!is.na(delta_mz))   # remove first NA

avg_delta <- mean(peak_spacing$delta_mz)
sd_delta  <- sd(peak_spacing$delta_mz)

cat("Average mass spacing (Δm/z):", avg_delta, "\n")
cat("Standard deviation:", sd_delta, "\n\n")

# Optional: print spacing table
peak_spacing

# Plot
massspec_ions <- ggplot(scan787_data, aes(x = mz, y = intensity)) +
  geom_line() +
  geom_text(data = annotated_peaks,
            aes(label = sprintf("%.4f", mz)),
            vjust = -0.5, fontface = "bold", size = 3.5) +
 scale_y_continuous(
   labels = scientific,
   expand = expansion(mult = c(0, 0.2))) +
    labs(
    #title = paste0("Mass Spectrum at Scan 747 (", round(xraw@scantime[scan_index], 1), " s)"),
    x = "Mass to Charge Ratio",
    y = "Intensity"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.title.x = element_text(),
    axis.title.y = element_text(),
    strip.text = element_text(size = 14, face = "bold"))

print(massspec_ions)
```

### Data and Plot 2:

```{r}


#load data, preextracted in SI-Figure 4.
largelist_contaminants <- readRDS(here("Data", "eic_df_newions.rds"))

summed_signals <- largelist_contaminants %>%
  group_by(file, rt) %>%
  summarise(total_intensity = sum(average_intensity, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    file_base = str_remove(file, "\\.mzML$"),
    Sequence  = as.numeric(str_split(file_base, "-", simplify = TRUE)[,5]),
    Wash      = str_split(file_base, "-", simplify = TRUE)[,6],
    Sample    = str_split(file_base, "-", simplify = TRUE)[,7]
  ) %>%
  arrange(Sample, Wash) %>%
  group_by(Sample, Wash) %>%
  mutate(Replicate = dense_rank(Sequence),
         Replicate = as.factor(Replicate)) %>%
  ungroup() %>%
  group_by(file) %>%
  arrange(rt, .by_group = TRUE) %>%
  mutate(scan = row_number()) %>%
  ungroup() %>%
  mutate(Wash = replace_na(Wash, "NoFilter"))



# Set the Wash factor with desired order
summed_signals$Wash <- factor(summed_signals$Wash,
                              levels = c("22x", "08x", "04x", "NoWash", "PPT", "NoFilter"))

conta_solvent <- summed_signals %>%
  filter(rt >= 3 & rt <= 6,
         Wash == "NoFilter",
         Sequence %in% 8:45) %>%
  ggplot(aes(
    x = rt,
    y = total_intensity,
    color = as.factor(Replicate),
    group = Replicate
  )) +
  geom_line() +
  facet_wrap(~ Replicate, ncol = 8) +
  scale_x_continuous(
     breaks = seq(3, 6, by = 1),
     #labels = c("3", "", "", "6")
   ) +
  labs(
    x = "Retention Time (mins)",
    y = "Summed Intensity"
    # title intentionally omitted for a cleaner layout
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.title.x = element_text(),
    axis.title.y = element_text(),
    strip.text = element_text(size = 14)
  )

# Print the plot

contaminent_blanks <- (massspec_ions 
                       / conta_solvent)

print(contaminent_blanks)

```

### Article figure 5.

```{r}


# Create subfolder "PCI ME Figures" inside it
output_dir <- here("Figures")


# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_5.png"),
  plot = contaminent_blanks,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_5.tiff"),
  plot = contaminent_blanks,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## Figure. 6

### Date and Plot:

```{r}
Sup_info <- here("Data","Supplimentary Information_Excel_Files.xlsx")
data3<- read_excel(Sup_info, sheet = "Annotations")

peak_table1 <- data3 %>%
  dplyr::rename(peak_id = "Compound #") %>% 
  select(peak_id, "m/z", rt) %>%  
  mutate(
    intensity = as.numeric(row_number()), 
    rt = as.numeric(rt * 60),
    peak_id = str_remove(peak_id, "X"),      
    peak_id = as.numeric(peak_id) 
  ) %>%
  dplyr::rename( mz = "m/z") %>%
  arrange(rt, mz) 
  
# Define the output file path
output_file <- here("Data","annotated_peak_table_UT.csv")

# Function to run detectHomologues and save results
run_detect_homologues <- function(file) {
  detectHomologues(peak_table1, mz_min = 10, mz_max = 400, 
                   rt_min = 1, rt_max = 900, 
                   ppm_tolerance = 5, 
                   min_series_length = 4,
                   search_mode = "untargeted", 
                   step_mode = "increment", 
                   verbose = FALSE) %>%
    write_csv(file)
  message("Annotated peak table saved as CSV.")
}

# Check if the file exists; if not, run detectHomologues(), else load it
annotated_peak_table_UT <- if (!file.exists(output_file)) {
  run_detect_homologues(output_file)
  read_csv(output_file)
} else {
  message("CSV file already exists. Loading it.")
  read_csv(output_file)
}

# View the loaded or newly created data
head(annotated_peak_table_UT)

annotated_peak_table_UT_Min <- annotated_peak_table_UT %>%
  mutate(homologue_id = as.factor(homologue_id)) %>%
    mutate(
    mz = round(mz, 4),
    rt = round(rt / 60, 2 )) %>%
    filter(between(rt, 0, 15)) 


sdb <- sdbCreate(annotated_peak_table_UT_Min)
summary_sdb <- sdbSummarize(sdb)

# Fuzzy join with closest rt match (within 0.1 range)
merged_df <- difference_left_join(
  annotated_peak_table_UT_Min %>%
    arrange(homologue_id) %>%
   left_join(summary_sdb,
  by = "homologue_id") %>%
  arrange(homologue_id), 
  data3 %>% 
    dplyr::rename( mz = "m/z") %>%
    mutate(
      mz = round(mz, 4),  
      rt = round(rt, 2)   
    ) %>%
    select(
      mz, rt, Formula, "Annotation level", Name, Adduct,
      Polarity,
      #Identifier,
      "Compound #", SMILES, CSID, "InChI Key"
    ),
  by = c("mz", "rt"),  # Match `mz` exactly and `rt` approximately
  max_dist = 0.011  ) %>%
  select(-mz.y, -rt.y) %>%
  dplyr::rename( mz = mz.x, rt = rt.x) %>%
  filter(!is.na(homologue_id)) 

homologue_to_remove <- merged_df %>%
  group_by(homologue_id) %>%
  filter(n_distinct(Polarity) > 1) %>%  # ✅ Find homologue_ids with both POS & NEG
  distinct(homologue_id) %>%
  pull(homologue_id)  # ✅ Extract as vector

# Print the removed homologue_id values
cat("Removed homologue series:\n")
print(homologue_to_remove)

# ✅ Now remove those homologue_id values from merged_df
merged_df <- merged_df %>%
  filter(!homologue_id %in% homologue_to_remove)  

# Define color palette dynamically
colourCount <- nlevels(merged_df$homologue_id)
getPalette <- colorRampPalette(brewer.pal(min(9, max(3, colourCount)), "Set1"))  # Ensure at least 3 colors

# Create named color mapping for homologue_id
homologue_levels <- levels(merged_df$homologue_id)  # Ensure levels match
color_map <- setNames(getPalette(colourCount), homologue_levels)

# Prepare data
merged_df <- merged_df %>%
  filter(!is.na(molecular_formula)) %>%
  mutate(
    homologue_id_original = homologue_id,
    homologue_id = as.integer(factor(homologue_id))
  )

merged_df$molecular_formula <- as.factor(merged_df$molecular_formula)
merged_df$homologue_id <- as.factor(merged_df$homologue_id)

# Levels and palette setup
molecular_formula_levels <- levels(merged_df$molecular_formula)
homologue_levels <- levels(merged_df$homologue_id)
colourCount <- length(homologue_levels)
shapeCount <- length(molecular_formula_levels)

getPalette <- colorRampPalette(brewer.pal(8, "Dark2"))
color_map <- setNames(getPalette(colourCount), homologue_levels)
shape_map <- setNames(rep(19:25, length.out = shapeCount), molecular_formula_levels)

# Plot
g2tax <- ggplot(merged_df, aes(x = rt, y = mz, group = homologue_id)) +

  geom_line(aes(color = homologue_id), alpha = 0.5, size = 0.3) +
  geom_point(aes(shape = molecular_formula, color = homologue_id),
             size = 4, alpha = 1, stroke = 0.3) +

  scale_color_manual(values = color_map, name = "Homologue ID  ") +
  scale_shape_manual(values = shape_map, name = "Repeating Unit") +

  labs(
    x = "Retention Time (mins)",
    y = "Mass to Charge Ratio"
  ) +

  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    #legend.justification = c(-0.15, 0),       # Align legend box to bottom-left corner
    legend.box.just = "left",             # Align contents to the left inside the box
    legend.box = "vertical",              # Stack color and shape legends vertically
    legend.title = element_text(size = 10),
    legend.text = element_text(),
    strip.text = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.title = element_text(),
    axis.text = element_text() 
  )  +
  
   guides(
     color = guide_legend(order = 1, nrow = 3, byrow = TRUE),
     shape = guide_legend(order = 2, nrow = 2)
   )

print(g2tax)
```

### Article figure 6.

```{r}
# Define base file path
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_6.png"),
  plot = g2tax,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_6.tiff"),
  plot = g2tax,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## Figure 7.

### Data and ClassifyR

```{r}

# Path to cached classification file
largelist_path <- here("Data", "largelist.rds")

if (file.exists(largelist_path)) {

  # Load cached results
  classification_list <- readRDS(largelist_path)

} else {

  # Extract InChI Keys
  InChI_Keys <- merged_df %>%
    pull(`InChI Key`) %>%
    as.list()

  # Run classification (expensive step)
  classification_list <- purrr::map(InChI_Keys, get_classification)

  # Save results for future runs
  saveRDS(classification_list, largelist_path)
}

classification_list <- readRDS("~/R scripts/largelist.rds")

meta(classification_list[[1]])
classification(classification_list[[1]])



# Function to safely extract classification data (stopping at `alternative_parents`)
extract_classification_data <- function(class_obj) {
  if (is.null(class_obj)) {
    return(tibble(
      inchikey = NA_character_,
      smiles = NA_character_,
      version = NA_character_,
      kingdom = NA_character_,
      superclass = NA_character_,
      class = NA_character_,
      subclass = NA_character_,
      direct_parent = NA_character_,
      direct_parent_desc = NA_character_,
      alternative_parents = NA_character_,
      alternative_parents_desc = NA_character_
    ))
  }
  
  tibble(
    # Extract `meta` information
    inchikey = class_obj@meta$inchikey %||% NA_character_,
    smiles = class_obj@meta$smiles %||% NA_character_,
    version = class_obj@meta$version %||% NA_character_,
    
    # Extract classification levels (Kingdom, Superclass, Class, Subclass)
    kingdom = class_obj@classification$Classification[class_obj@classification$Level == "kingdom"] %||% NA_character_,
    superclass = class_obj@classification$Classification[class_obj@classification$Level == "superclass"] %||% NA_character_,
    class = class_obj@classification$Classification[class_obj@classification$Level == "class"] %||% NA_character_,
    subclass = class_obj@classification$Classification[class_obj@classification$Level == "subclass"] %||% NA_character_,
    
    # Extract `direct_parent`
    direct_parent = class_obj@direct_parent$name %||% NA_character_,
    direct_parent_desc = class_obj@direct_parent$description %||% NA_character_,
    
    # Extract `alternative_parents`
    alternative_parents = if (nrow(class_obj@alternative_parents) > 0) {
      paste(class_obj@alternative_parents$name, collapse = "; ")
    } else NA_character_,
    
    alternative_parents_desc = if (nrow(class_obj@alternative_parents) > 0) {
      paste(class_obj@alternative_parents$description, collapse = "; ")
    } else NA_character_
  )
}


# Apply function to ALL elements in classification_list
parsed_data <- map_dfr(classification_list, possibly(extract_classification_data, otherwise = tibble()))

# View the final dataframe
print(parsed_data)

# Remove "InChIKey=" prefix from the inchikey column
parsed_data <- parsed_data %>%
  mutate(inchikey = gsub("^InChIKey=", "", inchikey)) %>%
dplyr::rename("InChI Key" = inchikey)

# View cleaned data
print(parsed_data)

merged_class_df <- merged_df %>%
  left_join(
    parsed_data %>%
      select(`InChI Key`, class, direct_parent) %>%
      distinct(`InChI Key`, .keep_all = TRUE),  # Keep only one row per "InChI Key"
    by = "InChI Key"
  )

# Step 1: Count occurrences of class and direct_parent for each homologue_id, excluding NA values
most_frequent_df <- merged_class_df %>%
  filter(!is.na(class) & !is.na(direct_parent)) %>%  # Remove NA values
  group_by(homologue_id, class, direct_parent) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(homologue_id, desc(count))

# Step 2: Select the most frequent non-NA class and direct_parent
final_df <- most_frequent_df %>%
  group_by(homologue_id) %>%
  slice_max(count, n = 1, with_ties = FALSE) %>%  # Pick the most frequent non-NA
  select(homologue_id, class, direct_parent) %>%
  mutate(label = paste(homologue_id, class, direct_parent, sep = " | "))
# Display the result
print(head(final_df))

# Export cleaned data to CSV (Optional)
write.csv(parsed_data, "cleaned_classification_data.csv", row.names = FALSE)

# Step 1: Count occurrences of class and direct_parent for each homologue_id, excluding NA values
most_frequent_df <- merged_class_df %>%
  filter(!is.na(class) & !is.na(direct_parent)) %>%  # Remove NA values
  group_by(homologue_id, class, direct_parent) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(homologue_id, desc(count))

# Step 2: Select the most frequent non-NA class and direct_parent
final_df <- most_frequent_df %>%
  group_by(homologue_id) %>%
  slice_max(count, n = 1, with_ties = FALSE) %>%  # Pick the most frequent non-NA
  select(homologue_id, class, direct_parent) %>%
  mutate(label = paste(homologue_id, class, direct_parent, sep = " | "))
# Display the result
print(head(final_df))


```

### HeapMap

```{r}

Sup_info <- here("Data","Supplimentary Information_Excel_Files.xlsx")
data4<- read_excel(Sup_info, sheet = "Peak Areas")

# Step 1: Extract "Compound #", homologue_id, and molecular_formula from merged_df
compound_info <- merged_df %>%
  select(`Compound #`, homologue_id, molecular_formula, mz) %>%
  unique() %>%
  na.omit()  # Remove NA values

# Step 2: Select the first 5 columns in data
first_five_cols <- data4 %>% select(1:5)

# Step 3: Select only columns in data that match the Compound # list
selected_compound_cols <- data4 %>%
  select(all_of(intersect(names(data4), compound_info$`Compound #`)))

# Step 4: Combine the first 5 columns with selected compound columns
filtered_data <- bind_cols(first_five_cols, selected_compound_cols)

# Step 5: Convert to long format for merging with homologue_id and molecular_formula
long_data_niko <- filtered_data %>%
  pivot_longer(cols = starts_with("X"),  # Convert wide to long format
               names_to = "Compound #",
               values_to = "Intensity") %>%
  left_join(compound_info, by = "Compound #")  # Merge with homologue_id & molecular_formula

# Step 6: Sum Intensity for each homologue_id and molecular_formula while keeping other columns
summarized_data <- long_data_niko %>%
  group_by(`Raw name`, Sequence, Replicate, Wash, Sample, homologue_id, molecular_formula) %>%
  summarise(Intensity = sum(Intensity, na.rm = TRUE), .groups = "drop")  # Sum intensity & remove NA

# 🔹 Preprocess and Transform Data
heatmap_matrix <- summarized_data %>%
  mutate(Sample = ifelse(Sample == "Reference", "Solvent", Sample),
         Wash = ifelse(is.na(Wash), "", Wash)) %>% 
  filter(Sequence %in% 8:45) %>%
  group_by(homologue_id) %>%
  mutate(Intensity = (Intensity - min(Intensity, na.rm = TRUE)) /
                      (max(Intensity, na.rm = TRUE) - min(Intensity, na.rm = TRUE))) %>%
  ungroup() %>%
  mutate(homologue_id = factor(homologue_id, levels = sort(unique(homologue_id), na.last = TRUE))) %>%
  select(-molecular_formula) %>%
  pivot_wider(names_from = homologue_id, values_from = Intensity, values_fill = 0) %>%
  arrange(as.numeric(as.character(Sequence))) %>%
  select(Sequence, sort(names(.)[-1]))

# 🔹 Extract Wash & Sample info before removing them
row_annotation <- heatmap_matrix %>%
  select(Sequence, Wash, Sample) %>%
  mutate(
    Sample = ifelse(Sample == "NIST", "Plasma", Sample),
    Wash = ifelse(Wash == "NoWash", "Unwash", Wash)
  ) %>%
  arrange(Sequence)

# 🔹 Convert to numeric matrix and modify row names
heatmap_matrix <- heatmap_matrix %>%
  select(-c(Sequence, Wash, Sample, Replicate)) %>%
  mutate(across(everything(), as.numeric)) %>%
  as.matrix() 

# Now set row names
rownames(heatmap_matrix) <- paste(
  row_annotation$Sequence, 
  row_annotation$Wash, 
  row_annotation$Sample, 
  sep = " | "
)

# Match heatmap column names to 
final_df$homologue_id 
matched_ids <- match(colnames(heatmap_matrix), final_df$homologue_id) 

# Original IDs 
homologue_ids <- colnames(heatmap_matrix) 

# Get class and parent info 
classes <- final_df$class[matched_ids] 
parents <- final_df$direct_parent[matched_ids] 

# Replace NAs in parents with "Unknown" 
parents[is.na(parents)] <- "Unknown" 
# Apply zero-padding only to numeric values 

padded_ids <- ifelse(grepl("^\\d+$", homologue_ids), sprintf("%02d", as.integer(homologue_ids)), homologue_ids) 

# Find indices of "Unknown" parents
unknown_idx <- which(parents == "Unknown")

# Replace with "Unknown1", "Unknown2", ...
parents[unknown_idx] <- paste0("Unknown ", seq_along(unknown_idx))

# Build labels
col_labels <- paste(padded_ids, parents, sep = " | ")

# Apply to matrix
colnames(heatmap_matrix) <- col_labels

# 🔹 Transpose the matrix
heatmap_matrix <- t(heatmap_matrix)


```

### Plot

```{r}
# 🔹 Generate heatmap and extract gtable object
heatmap_plot <- pheatmap(
  heatmap_matrix,
  scale = "none",
  cluster_rows = T,
  cluster_cols = TRUE,
  method = "ward.D2",
  # cutree_cols = 1,
  # cutree_rows = 3,
  #gaps_row = c(12,14,20),
  labels_row = rownames(heatmap_matrix),  # 🔹 Set y-axis labels (Sequence | Wash | Sample)
  labels_col = colnames(heatmap_matrix),  # 🔹 Set x-axis labels (homologue_id)
  color = colorRampPalette(c("blue", "white", "red"))(50),
  #main = "Clustered Heatmap",
  fontsize_row = 11,
  fontsize_col = 11,
  border_color = NA,
  angle_col = 90,   # 🔹 Rotate x-axis labels to vertical
  )

# 🔹 Convert heatmap to gtable for editing
heatmap_gtable <- heatmap_plot$gtable

# 🔹 Top label: near top-right (not fully right)
top_label <- textGrob(
  "Homologue Series ID | Direct Parent",
  x = unit(0.65, "npc"), y = unit(1, "npc"),
  just = c("left", "top"),
  gp = gpar(fontsize = 14, fontface = "bold")
)

# 🔹 Bottom-center label
bottom_label <- textGrob(
  "Sequence number | Wash | Sample",
  gp = gpar(fontsize = 14, fontface = "bold")
)

# 🔹 Arrange the layout with top and bottom text + heatmap
grid.newpage()
grid.draw(
  arrangeGrob(
    grobs = list(
      top_label,        # Row 1: top-aligned label (80% to the right)
      heatmap_gtable,   # Row 2: heatmap
      bottom_label      # Row 3: bottom-centered label
    ),
    layout_matrix = rbind(
      c(1),
      c(2),
      c(3)
    ),
    heights = unit.c(
      unit(1, "lines"),
      unit(1, "null"),
      unit(1, "lines")
    )
  )
)

# 🔹 Now add floating labels via viewport
# Coordinate system is from 0 to 1 (bottom-left to top-right)
# You can fine-tune x and y values as needed
label_positions <- list(
  Lipids      = c(0.095, 0.35),
  Contaminants= c(0.165, 0.50),
  Sample      = c(0.25, 0.6),
  Background  = c(0.4, 0.8)
)

for (label in names(label_positions)) {
  coords <- label_positions[[label]]
  grid.text(
    label,
    x = unit(coords[1], "npc"),
    y = unit(coords[2], "npc"),
    gp = gpar(fontsize = 13.5, fontface = "bold", col = "black")
  )
}
```

### Article figure 7

```{r}
# Define base file path}
output_dir <- here("Figures")

# ==== TIFF Export (Analytical Chemistry format) ====
tiff(
  filename = file.path(output_dir, "Figure_7.tiff"),
  width = 28,
  height = 20,
  units = "cm",
  res = 600,
  compression = "lzw"
)

# Draw heatmap layout
grid.newpage()
grid.draw(
  arrangeGrob(
    grobs = list(
      top_label,
      heatmap_gtable,
      bottom_label
    ),
    layout_matrix = rbind(
      c(1),
      c(2),
      c(3)
    ),
    heights = unit.c(
      unit(1, "lines"),
      unit(1, "null"),
      unit(1, "lines")
    )
  )
)

# Add floating labels
for (label in names(label_positions)) {
  coords <- label_positions[[label]]
  grid.text(
    label,
    x = unit(coords[1], "npc"),
    y = unit(coords[2], "npc"),
    gp = gpar(fontsize = 11, fontface = "bold", col = "black")
  )
}

# Close TIFF device
dev.off()

# ==== PNG Export (same layout) ====
png(
  filename = file.path(output_dir, "Figure_7.png"),
  width = 28,
  height = 20,
  units = "cm",
  res = 600
)

# Repeat drawing for PNG
grid.newpage()
grid.draw(
  arrangeGrob(
    grobs = list(
      top_label,
      heatmap_gtable,
      bottom_label
    ),
    layout_matrix = rbind(
      c(1),
      c(2),
      c(3)
    ),
    heights = unit.c(
      unit(1, "lines"),
      unit(1, "null"),
      unit(1, "lines")
    )
  )
)

# Floating labels for PNG
for (label in names(label_positions)) {
  coords <- label_positions[[label]]
  grid.text(
    label,
    x = unit(coords[1], "npc"),
    y = unit(coords[2], "npc"),
    gp = gpar(fontsize = 11, fontface = "bold", col = "black")
  )
}

# Close PNG device
dev.off()
```

## Figure 8

### Data and plot MS 1

```{r}
#Change dir
filepath <- "C:/Users/DanielMalheiro/Downloads/Exp7-241008/mzML-PAN"
setwd(filepath)
getwd()
list.files()

# Load the mzML file
file_nowash <- "241008-Exp-PAN-1-035-NoWash-NIST.mzML"

if (!exists("raw_data_glu")) {
  raw_data_glu <- xcmsRaw(file_nowash)
} else {
  message("'raw_data_glu' already exists in the environment.")
}

ppm <- 2

# Define function to extract EIC for a target m/z
extract_eic <- function(raw_data, target_mz, ppm, polarity_label = "positive") {
  mz_tol <- (ppm / 1e6) * target_mz
  mz_range <- c(target_mz - mz_tol, target_mz + mz_tol)

  # Only keep scans in the correct polarity
  positive_scans <- which(raw_data@polarity == polarity_label)  # 1 = positive

  # Extract EIC for those scans
  eic <- rawEIC(raw_data, mzrange = mz_range)

  eic_df <- data.frame(
    rt = raw_data@scantime[positive_scans] / 60,  # Convert to minutes
    intensity = eic$intensity[positive_scans],
    scan = seq_along(positive_scans),
    target = paste0("m/z ", round(target_mz, 4))
  ) %>%
    mutate(average_intensity = rollmean(intensity, k = 3, fill = NA, align = "left"))

  return(eic_df)
}

# Create mapping from m/z to metabolite name
target_labels <- c(
  `204.1173` = "Glucose-13C6",
  `204.1230` = "Acetyl-Carnitine"
)

# Apply names in each EIC dataframe
eic_df_1 <- extract_eic(raw_data_glu, 204.1173, ppm) %>%
  mutate(target = target_labels["204.1173"])

eic_df_2 <- extract_eic(raw_data_glu, 204.1230, ppm) %>%
  mutate(target = target_labels["204.1230"])

# Combine both EICs
combined_eic_df <- bind_rows(eic_df_1, eic_df_2)

combined_eic_df_scaled <- combined_eic_df %>%
  group_by(target) %>%
  mutate(scaled_intensity = average_intensity / max(average_intensity, na.rm = TRUE)) %>%
  ungroup()

# Define RT and m/z range
rt_range <- c(2, 3) * 60  # Convert to seconds
mz_range <- c(204.11, 204.13)

# Find scan indices within the RT range
scan_indices_in_range <- which(raw_data_glu@scantime >= rt_range[1] & raw_data_glu@scantime <= rt_range[2])
rt_values <- raw_data_glu@scantime[scan_indices_in_range] / 60  # Convert to minutes

# Select five scan indices manually
scan_1 <- 91
scan_2 <- 135
scan_3 <- 361
scan_4 <- 407
scan_5 <- 457


selected_scans <- c(scan_1, scan_2, scan_3, scan_4, scan_5)
scan_labels <- paste0("Mass spectrum ", 1:5)

# Print RT values for selected scans
rt_selected <- raw_data_glu@scantime[selected_scans] / 60
rt_df <- data.frame(scan_label = scan_labels, scan_index = selected_scans, RT_min = rt_selected)
print(rt_df)

# Function to extract mass spectrum for a specific scan
extract_mass_spectrum_for_scan <- function(scan_index, raw_data2, mz_range) {
  scan_start <- raw_data2@scanindex[scan_index] + 1
  scan_end <- ifelse(scan_index + 1 <= length(raw_data2@scanindex), 
                     raw_data2@scanindex[scan_index + 1], 
                     length(raw_data2@env$mz))
  
  mz_values <- raw_data2@env$mz[scan_start:scan_end]
  intensity_values <- raw_data2@env$intensity[scan_start:scan_end]
  
  mass_spectrum_df <- data.frame(mz = mz_values, intensity = intensity_values) %>%
    filter(mz >= mz_range[1] & mz <= mz_range[2])
  
  return(mass_spectrum_df)
}

# Helper function to handle empty scans
ensure_spectrum_not_empty <- function(df, scan_label, mz_range) {
  if (nrow(df) == 0) {
    message(paste("⚠️  No data in scan", scan_label, "- inserting zero-intensity points."))
    df <- data.frame(
      mz = c(mz_range[1], mz_range[2]),
      intensity = c(0, 0),
      scan = scan_label
    )
  }
  return(df)
}

# Extract and label mass spectra for each scan
mass_spectrum_1 <- extract_mass_spectrum_for_scan(scan_1, raw_data_glu, mz_range) %>%
  mutate(scan = "1") %>%
  ensure_spectrum_not_empty("1", mz_range)

mass_spectrum_2 <- extract_mass_spectrum_for_scan(scan_2, raw_data_glu, mz_range) %>%
  mutate(scan = "2") %>%
  ensure_spectrum_not_empty("2", mz_range)

mass_spectrum_3 <- extract_mass_spectrum_for_scan(scan_3, raw_data_glu, mz_range) %>%
  mutate(scan = "3") %>%
  ensure_spectrum_not_empty("3", mz_range)

mass_spectrum_4 <- extract_mass_spectrum_for_scan(scan_4, raw_data_glu, mz_range) %>%
  mutate(scan = "4") %>%
  ensure_spectrum_not_empty("4", mz_range)

mass_spectrum_5 <- extract_mass_spectrum_for_scan(scan_5, raw_data_glu, mz_range) %>%
  mutate(scan = "5") %>%
  ensure_spectrum_not_empty("5", mz_range)

# Combine spectra
combined_spectra <- bind_rows(
  mass_spectrum_1,
  mass_spectrum_2,
  mass_spectrum_3,
  mass_spectrum_4,
  mass_spectrum_5
) %>%
  mutate(scan = paste0("Mass Spectrum ", scan))

# Target m/z values and ppm
target_masses <- c(204.1173, 204.1230)

# Plot without shaded regions
spectrum_glucose <- ggplot(combined_spectra, aes(x = mz, y = intensity)) +
  # Mass spectra lines
  geom_line(linewidth = 1, aes(color = scan)) +
  # Vertical dashed lines at target m/z
  geom_vline(xintercept = target_masses, linetype = "dashed", color = "black") +
  # Facet by scan with free x scales
  facet_wrap(~scan, ncol = 5, scales = "free_x") +
  coord_cartesian(ylim = c(0, 2e6)) +
  scale_y_continuous(labels = scales::scientific) +
  # Only show target m/z tick marks
  scale_x_continuous(
    name = "Mass to Charge Ratio",
    breaks = target_masses,
    labels = format(target_masses, digits = 7)
  ) +
  labs(
    #title = "Extracted Mass Spectra at Selected Scans",
    y = "Intensity",
      ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.ticks.x = element_line(),
    axis.text.x = element_text(angle = 45, hjust = 1.0),
    axis.title.x = element_text(),
    axis.title.y = element_text(),
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.text = element_text(size = 10)
  )
  
 

print(spectrum_glucose)

```

### Data and plot 2

```{r}

x_limits <- c(0, 14)
zoom_limits <- c(0, 3)   # Zoomed-in range
vline_positions <- rt_df$RT_min  # Vertical line positions

# Filter data
filtered_data_3 <- long_data %>%
  filter(between(Times, x_limits[1], x_limits[2]),
         Compound %in% c("Glucose-13C6"), 
         Wash %in% c("PPT","NoWash", "22x"),
         Replicate %in% 1:8 ) %>%
  filter(!(Sample == "NIST" & Replicate >= 4)) %>%
  filter(!(Replicate %in% c("1", "2", "3", "4", "6") & Sample == "Solvent")) %>%
  mutate(
    Wash = factor(Wash, levels = c("22x", "08x", "NoWash", "PPT")) # Set order of Wash
  )

# Summary Table for Matrix Effects (with SD Calculation)
summary_table_3 <- filtered_data_3 %>%
  group_by(Scan, Wash, Compound) %>%
  summarise(
    avg_time = mean(Times, na.rm = TRUE),
    Process = mean(Intensities[Sample == "Process"], na.rm = TRUE),
    Process_SD = sd(Intensities[Sample == "Process"], na.rm = TRUE),  # SD Calculation
    NIST = mean(Intensities[Sample == "NIST"], na.rm = TRUE),
    NIST_SD = sd(Intensities[Sample == "NIST"], na.rm = TRUE),  # SD Calculation
    Solvent = mean(Intensities[Sample == "Solvent"], na.rm = TRUE),
    Solvent_SD = sd(Intensities[Sample == "Solvent"], na.rm = TRUE),  # SD Calculation
    .groups = "drop"
  ) %>%
  mutate(
    Matrix_Effect_NIST_Process = ((NIST / Process) * 100) - 100,
    Matrix_Effect_Process_Solvent = ((Process / Solvent) * 100) - 100,
    Matrix_Effect_NIST_Solvent = ((NIST / Solvent) * 100) - 100
  ) %>%
  pivot_longer(
    cols = starts_with("Matrix_Effect"),
    names_to = "Comparison",
    values_to = "Matrix_Effect"
  ) %>%
  mutate(
    Comparison = recode(Comparison,
                        "Matrix_Effect_NIST_Process" = "NIST / Process",
                        "Matrix_Effect_Process_Solvent" = "Process / Solvent",
                        "Matrix_Effect_NIST_Solvent" = "NIST / Solvent")
  )

# **PLOT 2: Zoomed-In Matrix Effect (Facet Labels Removed)**
glucose_me_plot <- summary_table_3 %>%
  filter(Comparison == "NIST / Solvent",
         between(avg_time, zoom_limits[1], zoom_limits[2]),
                 Wash == "NoWash") %>%
  ggplot(aes(x = avg_time, y = Matrix_Effect, color = Wash)) +
  geom_vline(xintercept = vline_positions, linetype = "dotted", color = "black") +
    geom_text(data = rt_df,
            aes(x = RT_min, y = -55, label = scan_label),
            inherit.aes = FALSE,
            angle = 90, vjust = -1, size = 4) +
  geom_line(size = 0.75, alpha = 0.6) +
    labs(
    x = "Retention Time (mins)",  
    y = "Matrix Effect (%)",
    color = NULL  # Remove redundant legend
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.title.x = element_text(),
    axis.title.y = element_text(),
    strip.text = element_text(size = 4)
    )

print(glucose_me_plot)

glu_ME_MS <- glucose_me_plot / spectrum_glucose

print(glu_ME_MS)
```

### Article figure 8.

```{r}
# Define base file path
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_8.png"),
  plot = glu_ME_MS,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_8.tiff"),
  plot = glu_ME_MS,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## Figure 9. Simulated Mass resolution at 60 v 120k

### Data and Plot:

```{r}


# ============================
# 1. Constants
# ============================

mz1 <- 204.1173
mz2 <- 204.1230
int1 <- 2e6
int2 <- 22174204

resolutions <- c("60k" = 60000, "120k" = 120000)

# Use SAME m/z values as the experimental data
x_vals <- mass_spectrum_4$mz

# ============================
# 2. Gaussian Peak Function
# ============================

generate_gaussian <- function(mz_center, intensity, resolution) {
  fwhm <- mz_center / resolution
  sigma <- fwhm / 2.35482
  intensity_vals <- intensity * exp(-(x_vals - mz_center)^2 / (2 * sigma^2))
  return(intensity_vals)
}

# ============================
# 3. Simulation Function
# ============================

simulate_resolution <- function(res_label, resolution) {
  peak1 <- generate_gaussian(mz1, int1, resolution)
  peak2 <- generate_gaussian(mz2, int2, resolution)
  total <- peak1 + peak2
  
  data.frame(
    mz = x_vals,
    peak_204_1173 = peak1,
    peak_204_1230 = peak2,
    combined = total,
    Resolution = res_label
  )
}

# ============================
# 4. Run Simulations
# ============================

sim_60k  <- simulate_resolution("60k",  resolutions["60k"])
sim_120k <- simulate_resolution("120k", resolutions["120k"])

# Combine and reshape simulated data
sim_all <- bind_rows(sim_60k, sim_120k) %>%
  pivot_longer(cols = c("peak_204_1173", "peak_204_1230", "combined"),
               names_to = "Trace",
               values_to = "Intensity")

# ============================
# 5. Prepare Experimental Data
# ============================

mass_spectrum_combine <- mass_spectrum_4 %>%
  select(-scan) %>%
  dplyr::rename(Intensity = intensity) %>%
  mutate(
    Trace = "Experimental",
    Resolution = "Experimental"
  )

# ============================
# 6. Final Combined Dataset
# ============================

combined_simulation <- bind_rows(sim_all, mass_spectrum_combine) %>% 
  filter(!(Trace %in% c("peak_204_1230", "peak_204_1173"))) %>%
  mutate(
    Resolution = recode(Resolution,
      "Experimental" = "Experimental Data",
      "60k" = "60k Resolving Power",
      "120k" = "120k Resolving Power"
    ),
    Resolution = factor(Resolution, 
                        levels = c("Experimental Data", 
                                   "60k Resolving Power", 
                                   "120k Resolving Power"))
  )

# ============================
# 7. Plot
# ============================

mass_simulation_plot <- combined_simulation %>%
  ggplot(aes(x = mz, y = Intensity, color = Resolution)) +
  geom_vline(xintercept = target_masses, linetype = "dashed", color = "black") +
  geom_line(linewidth = 1) +
  facet_wrap(~Resolution) +
  scale_x_continuous(
    name = "Mass to Charge Ratio",
    breaks = target_masses,
    labels = label_number(digits = 6)
  ) +
  labs(
    x = "Mass to Charge Ratio",
    y = "Intensity",
    color = NULL
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none",
    strip.text = element_text(size = 12, face = "bold")
  )

print(mass_simulation_plot)


```

### Article Figure 9

```{r}

# ============================
# 8. Save Output
# ============================
output_dir <- here("Figures")

# PNG
ggsave(
  filename = file.path(output_dir, "Figure_9.png"),
  plot = mass_simulation_plot,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600
)

# TIFF
ggsave(
  filename = file.path(output_dir, "Figure_9.tiff"),
  plot = mass_simulation_plot,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)

```

## Figure 10. Dilution seres

### Data Loading

```{r}
dilution_file <- "Skyline-PCI-InfusionTest-Exp7-Gradient and Dilution.tsv"  
dilution_data <- read_tsv(here("Data", dilution_file))

replacements <- c(
  "Leucine d10" = "Leucine-d10" ,
   "Glutamic acid-d5"= "GlutamicAcid-d5",
   "DL-Tryptophan-d5" = "Tryptophan-d5",
   "Stearic-d35 (18:0)" = "StearicAcid-d35",
   "Cholic acid-d4" = "CholicAcid-d4")

data5 <- dilution_data %>%
  dplyr::rename(
    Chromatograms = FileName,
    Compound = PeptideModifiedSequence,
    Adduct = PrecursorCharge,
    Charge = ProductCharge
  ) %>%
  select(-IsotopeLabelType, -TotalArea, -FragmentIon) %>%
  separate(
    Chromatograms,
    into = c(
      "Date",
      "Exp",
      "PAN",
      "Batch",
      "Sequence",
      "Wash",
      "Sample",
      "Dilution"),
    sep = "-",
    remove = FALSE
  ) %>%
  mutate(
    Sample = str_remove(Sample, "\\.raw"),
    Dilution = str_remove(Dilution,"\\.raw"),
    Wash = str_remove(Wash,"\\.raw"),
    Compound = replace(Compound, Compound == "#N/A", "TIC"),
    Compound = recode(Compound, !!!replacements),  # Apply replacements
    Sequence = as.numeric(Sequence),
    Dilution = as.factor(Dilution)
  ) %>%
  select(-Batch,-Exp) %>%
  arrange(Date) %>%
  filter(#Sample %in% c("Process", "NIST"),
         Adduct != "[M35H2-H]",
        Adduct != "[M5H2+H]",
        Compound != "Isoleucine-13C6",
        Compound != "Arginine-13C6") %>%
  group_by(Wash, Sample, Compound, Charge) %>%
  mutate(Replicate = row_number()) %>%
 ungroup() %>%
  select(1:5, Replicate, everything()) %>%
  mutate(Sample = ifelse(Wash == "NoFilter" & Sample == "Blank", "Reference", Sample)) %>%
   filter(Compound != "TIC") 

# Get unique washes to replicate Reference for each wash
unique_washes <- unique(data5$Wash)
print(unique_washes)

# Add Reference sample for all washes except "NoFilter"
data5 <- data5 %>%
  bind_rows(
    data5 %>%
      filter(Sample == "Reference") %>%
      select(-Wash) %>%  # Remove the existing Wash column
      crossing(Wash = unique(data5$Wash[data5$Wash != "NoFilter"]))  # Add each wash except "NoFilter"
  ) %>%
filter(Wash != "NoFilter") %>%
filter(Wash %in% c("NoFilter", "22x", "08x", "04x","NoWash","PPT")) %>%
   mutate(
    Sample = case_when(
      Sample == "Reference" ~ "Solvent",
      Sample == "Blank" ~ "Process",
      TRUE ~ Sample))  

unique_washes <- unique(data5$Wash) %>% print()
unique_sample <- unique(data5$Sample) %>% print()



data_intensity <- data5 %>%
  select(Chromatograms, Compound, Intensities) %>%
  separate_wider_delim(Intensities,
                       delim = ";",
                      names_sep = "",
                      too_few = "align_start") %>%
  mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))

  
data_time <- data5 %>%
  select(Chromatograms,Compound, Times) %>%
  separate_wider_delim(Times,
                       delim = ";",
                       names_sep = "",
                       too_few = "align_start") %>%
  mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))


combined_data <- data5 %>%
  select(-Intensities,-Times) %>%
  right_join(data_time, by = c("Chromatograms","Compound")) %>%
  right_join(data_intensity, by = c("Chromatograms","Compound"))


long_data_dilu <- combined_data %>%
  filter(Date == "241009",
         Compound %in% c(
           #"Indole-d6",
           "Leucine-d10",
           #"GlutamicAcid-d5",
           "Carnitine-d9",
           #"Tryptophan-d5",
           #"StearicAcid-d35",
           #"CholicAcid-d4",
           "Glucose-13C6"
         ), 
       Wash != "08x",) %>%
    pivot_longer(
    cols = c(starts_with("Times"), starts_with("Intensities")),
    names_to = c(".value", "Scan"),
    names_pattern = "(Times|Intensities)(\\d+)") %>%
    mutate(Scan = as.numeric(Scan)) %>%
    mutate(Average = rollmean(Intensities, k = 9, fill = NA, align = "left")) %>%
  distinct()
```

### Data:2

### PPT LeucineME

```{r}
# Define axis and zoom settings
x_limits <- c(0, 14)
zoom_limits_PPT <- c(7.5, 14)
vline_positions <- c(10.95)

# Filter data
filtered_data_dilu <- long_data_dilu %>%
  filter(
    between(Times, x_limits[1], x_limits[2]),
    Compound == "Leucine-d10",
    Wash == "PPT",
    Sample != "Process"
  ) %>%
  mutate(Wash = factor(Wash, levels = c("22x", "08x", "NoWash", "PPT")))

# Summarise per scan/sample
summary_ppt_dilution <- filtered_data_dilu %>%
  filter(Sample %in% c("NIST", "Solvent"), Date == "241009") %>%
  group_by(Compound, Scan, Wash, Sample, Dilution) %>%
  summarise(
    avg_time = mean(Times, na.rm = TRUE),
    NIST_n = sum(!is.na(Average[Sample == "NIST"])),
    NIST_mean = mean(Average[Sample == "NIST"], na.rm = TRUE),
    NIST_se = sd(Average[Sample == "NIST"], na.rm = TRUE) / sqrt(NIST_n),
    Solvent_n = sum(!is.na(Average[Sample == "Solvent"])),
    Solvent_mean = mean(Average[Sample == "Solvent"], na.rm = TRUE),
    Solvent_se = sd(Average[Sample == "Solvent"], na.rm = TRUE) / sqrt(Solvent_n),
    .groups = "drop"
  ) %>%
  group_by(Compound, Scan, Wash) %>%
  mutate(
    Solvent_mean = dplyr::first(Solvent_mean[Sample == "Solvent" & !is.na(Solvent_mean)]),
    Solvent_se = dplyr::first(Solvent_se[Sample == "Solvent" & !is.na(Solvent_se)]),
    Solvent_n = dplyr::first(Solvent_n[Sample == "Solvent" & !is.na(Solvent_n)])
  ) %>%
  ungroup() %>%
  filter(Sample != "Solvent") %>%
  mutate(
    ME_NS_mean = ((NIST_mean / Solvent_mean) * 100) - 100,
    ME_NS_se = abs((NIST_mean / Solvent_mean) * 100) *
      sqrt((NIST_se / NIST_mean)^2 + (Solvent_se / Solvent_mean)^2),
    df = pmin(NIST_n, Solvent_n) - 1,
    t_val = qt(0.975, df = df),
    ME_NS_lower = ME_NS_mean - t_val * ME_NS_se,
    ME_NS_upper = ME_NS_mean + t_val * ME_NS_se,
    NIST_lower = NIST_mean - t_val * NIST_se,
    NIST_upper = NIST_mean + t_val * NIST_se,
    Solvent_lower = Solvent_mean - t_val * Solvent_se,
    Solvent_upper = Solvent_mean + t_val * Solvent_se
  )  %>%
  mutate(
    # Standard error of the difference
    se_diff = sqrt(NIST_se^2 + Solvent_se^2),

    # t-statistic for Welch's t-test
    t_stat = (NIST_mean - Solvent_mean) / se_diff,

    # Welch-Satterthwaite degrees of freedom
    df_welch = (NIST_se^2 + Solvent_se^2)^2 /
      ((NIST_se^4 / (NIST_n - 1)) + (Solvent_se^4 / (Solvent_n - 1))),

    # two-sided p-value
    p_value = 2 * pt(-abs(t_stat), df = df_welch)
  ) %>%
mutate(
    Dilution = recode(as.character(Dilution),
      "100" = "100%",
      "050" = "50%",
      "025" = "25%",
      "010" = "10%"
    ),
    Dilution = factor(Dilution, levels = c("100%", "50%", "25%", "10%"))
  )

# Plot B: Zoomed matrix effect + significance
plot_ppt_dilution <- summary_ppt_dilution %>%
  filter(between(avg_time, zoom_limits_PPT[1], zoom_limits_PPT[2])) %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean, color = Dilution, fill = Dilution)) +
  geom_ribbon(aes(ymin = ME_NS_lower, ymax = ME_NS_upper), alpha = 0.2, color = NA) +
  geom_line(size = 0.8) +
  #geom_segment(data = sig_regions_ME, aes(x = xmin, xend = xmax, y = y, yend = y), color = "black", size = 0.8) +
  #geom_text(data = sig_regions_ME, aes(x = (xmin + xmax)/2, y = label_y, label = "*"), size = 6, fontface = "bold", color = "black") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_vline(xintercept = vline_positions, linetype = "dotted", color = "black") +
  facet_grid( ~Dilution ~Wash + Compound) +
  #coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  labs(
  title = bquote(atop("PPT treated", "Leucine-d"[10])),
  x = "Retention Time (min)",
  y = NULL) +
  theme_minimal(base_size = 14) +
   theme(
  legend.position = "none",
  strip.text.y = element_text(angle = 0),
  strip.text.x = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  axis.line = element_line(color = "black"),      # ← keep axis line
  axis.ticks = element_line(color = "black"),      # ← keep ticks
 plot.title = element_text(hjust = 0.5, size = 14) # center title
  )
  
# Show final plot
print(plot_ppt_dilution)

summary_ppt_dilution %>% 
  filter(between(avg_time, 10, 11)) %>%
  group_by(Dilution, Compound, Wash) %>%
  summarize(
    max_ME_NS_Mean = min(ME_NS_mean, na.rm = TRUE),  # Get the maximum value of ME_NS_mean for each Dilution
    avg_time_at_max_ME = avg_time[which.min(ME_NS_mean)],  # Get the avg_time corresponding to the max ME_NS_mean
    ME_NS_lower_at_max_ME = ME_NS_lower[which.min(ME_NS_mean)]  # Get the ME_NS_lower corresponding to the max ME_NS_mean
  )

```

### NoWash Glucose ME plots

nowash_dilution

```{r}

# Define axis and zoom settings
x_limits <- c(0, 14)
zoom_limits <- c(0, 5)
vline_positions <- c(0.79, 2.2)

# Filter data
filtered_data_dilu <- long_data_dilu %>%
  filter(
    between(Times, x_limits[1], x_limits[2]),
    Compound == "Glucose-13C6",
    Wash == "NoWash",
    Sample != "Process"
  ) %>%
  mutate(Wash = factor(Wash, levels = c("22x", "08x", "NoWash", "PPT")))

# Summarise per scan/sample
summary_nowash_plot<- filtered_data_dilu %>%
  filter(Sample %in% c("NIST", "Solvent"), Date == "241009") %>%
  group_by(Compound, Scan, Wash, Sample, Dilution) %>%
  summarise(
    avg_time = mean(Times, na.rm = TRUE),
    NIST_n = sum(!is.na(Average[Sample == "NIST"])),
    NIST_mean = mean(Average[Sample == "NIST"], na.rm = TRUE),
    NIST_se = sd(Average[Sample == "NIST"], na.rm = TRUE) / sqrt(NIST_n),
    Solvent_n = sum(!is.na(Average[Sample == "Solvent"])),
    Solvent_mean = mean(Average[Sample == "Solvent"], na.rm = TRUE),
    Solvent_se = sd(Average[Sample == "Solvent"], na.rm = TRUE) / sqrt(Solvent_n),
    .groups = "drop"
  ) %>%
  group_by(Compound, Scan, Wash) %>%
  mutate(
    Solvent_mean = dplyr::first(Solvent_mean[Sample == "Solvent" & !is.na(Solvent_mean)]),
    Solvent_se = dplyr::first(Solvent_se[Sample == "Solvent" & !is.na(Solvent_se)]),
    Solvent_n = dplyr::first(Solvent_n[Sample == "Solvent" & !is.na(Solvent_n)])
  ) %>%
  ungroup() %>%
  filter(Sample != "Solvent") %>%
  mutate(
    ME_NS_mean = ((NIST_mean / Solvent_mean) * 100) - 100,
    ME_NS_se = abs((NIST_mean / Solvent_mean) * 100) *
      sqrt((NIST_se / NIST_mean)^2 + (Solvent_se / Solvent_mean)^2),
    df = pmin(NIST_n, Solvent_n) - 1,
    t_val = qt(0.975, df = df),
    ME_NS_lower = ME_NS_mean - t_val * ME_NS_se,
    ME_NS_upper = ME_NS_mean + t_val * ME_NS_se,
    NIST_lower = NIST_mean - t_val * NIST_se,
    NIST_upper = NIST_mean + t_val * NIST_se,
    Solvent_lower = Solvent_mean - t_val * Solvent_se,
    Solvent_upper = Solvent_mean + t_val * Solvent_se
  )  %>%
  mutate(
    # Standard error of the difference
    se_diff = sqrt(NIST_se^2 + Solvent_se^2),

    # t-statistic for Welch's t-test
    t_stat = (NIST_mean - Solvent_mean) / se_diff,

    # Welch-Satterthwaite degrees of freedom
    df_welch = (NIST_se^2 + Solvent_se^2)^2 /
      ((NIST_se^4 / (NIST_n - 1)) + (Solvent_se^4 / (Solvent_n - 1))),

    # two-sided p-value
    p_value = 2 * pt(-abs(t_stat), df = df_welch)
  ) %>%
mutate(
    Dilution = recode(as.character(Dilution),
      "100" = "100%",
      "050" = "50%",
      "025" = "25%",
      "010" = "10%"
    ),
    Dilution = factor(Dilution, levels = c("100%", "50%", "25%", "10%"))
  )


# Plot B: Zoomed matrix effect + significance
plot_nowash_dilution <- summary_nowash_plot %>%
  filter(between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean, color = Dilution, fill = Dilution)) +
  geom_ribbon(aes(ymin = ME_NS_lower, ymax = ME_NS_upper), alpha = 0.2, color = NA) +
  geom_line(size = 0.8) +
  #geom_segment(data = sig_regions_ME, aes(x = xmin, xend = xmax, y = y, yend = y), color = "black", size = 0.8) +
  #geom_text(data = sig_regions_ME, aes(x = (xmin + xmax)/2, y = label_y, label = "*"), size = 6, fontface = "bold", color = "black") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_vline(xintercept = vline_positions, linetype = "dotted", color = "black") +
  facet_grid(~Dilution ~Wash + Compound) +
  #coord_cartesian(ylim = c(global_min_y, global_max_y)) +
    labs( 
      title = bquote(atop("PLR unwashed plasma", "Glucose -"^{13}*"C"[6])),
   x = "Retention Time (min)",
  y = "Matrix Effect (%)") +
  theme_minimal(base_size = 14) +
 theme(
  legend.position = "none",
   strip.text = element_blank(),        
  #strip.text.y = element_blank(),
  #strip.text.x = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  axis.line = element_line(color = "black"),      # ← keep axis line
  axis.ticks = element_line(color = "black"),      # ← keep ticks
   plot.title = element_text(hjust = 0.5, size = 14) # center title
)
  



# Show final plot
print(plot_nowash_dilution)



```

### Combining dilution PPT and NoWash

```{r}

plot_ppt_nowash_dilution <-plot_nowash_dilution  | plot_ppt_dilution  
print(plot_ppt_nowash_dilution)

```

### Article figure 10

```{r}
# Define base file path
output_dir <- here("Figures")


# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_10.png"),
  plot = plot_ppt_nowash_dilution,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_10.tiff"),
  plot = plot_ppt_nowash_dilution,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## FIgure 11:

### Data + Plot

```{r}
#Change dir
# Load saved spectra
combined_spectra_loaded <- readRDS(here("Data","combined_mass_spectra_241009_NoWash.rds"))

all_combined_spectra <- combined_spectra_loaded

# Split filename into metadata columns
all_combined_spectra <- all_combined_spectra %>%
  separate(
    col = file,
    into = c("Date", "Exp", "PAN", "Batch", "Sequence", "Wash", "Sample", "Dilution"),
    sep = "-",
    remove = FALSE
  )

# Assign replicate number based on unique files per Wash + Sample + Dilution
replicate_table <- all_combined_spectra %>%
  distinct(Wash, Sample, Dilution, file) %>%
  group_by(Wash, Sample, Dilution) %>%
  arrange(file) %>%
  mutate(Replicate = row_number()) %>%
  ungroup()

# Join replicate numbers back and recode Dilution levels
all_combined_spectra <- all_combined_spectra %>%
  left_join(replicate_table, by = c("Wash", "Sample", "Dilution", "file")) %>%
  mutate(
    Dilution = recode(as.character(Dilution),
      "100" = "100%",
      "050" = "50%",
      "025" = "25%",
      "010" = "10%"
    ),
    Dilution = factor(Dilution, levels = c("100%", "50%", "25%", "10%"))
  )

# Manually add zero-intensity rows for Scan 2 and Dilution 025 at m/z 204.1230
rows_to_add <- all_combined_spectra %>%
  filter(scan == "Scan 2", Dilution %in% c("25%", "10%")) %>%   # Use recoded dilution label
  distinct(file, scan, Wash, Sample, Dilution, Replicate) %>%
  mutate(
    mz = 204.13,
    intensity = 0,
     ) %>%
  select(mz, intensity, scan, file, Wash, Sample, Dilution, Replicate)

# Append to original data
all_combined_spectra <- bind_rows(all_combined_spectra, rows_to_add) %>%
  mutate(scan = stringr::str_replace(scan, "Scan", "Mass Spectrum"))

# Define target m/z values to highlight
target_masses <- c(204.1173, 204.1230)

# Plot for Replicate 1 only
MS_dilution <- all_combined_spectra %>% 
  filter(Replicate == 1) %>%
  ggplot(aes(x = mz, y = intensity)) +
  geom_line(linewidth = 1, aes(color = scan)) +
  geom_vline(xintercept = target_masses, linetype = "dashed", color = "black") +
  facet_grid(~Dilution ~ scan, scales = "free_x") +
  coord_cartesian(ylim = c(0, 2.3e6)) +
  scale_x_continuous(
    name = "Mass to Charge Ratio",
    breaks = target_masses,
    labels = format(target_masses, digits = 7)
  ) +
   scale_y_continuous(labels = scientific,
                      breaks = pretty_breaks(n = 3)) +
  labs(y = "Intensity") +
  theme_minimal(base_size = 14) +
  theme(
    axis.ticks.x = element_line(),
    axis.text.x = element_text(angle = 45, hjust = 1.0),
    legend.position = "none",
    strip.text.y = element_text(angle = 0),
    strip.text.x = element_text(size = 10.5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black")
  )

print(MS_dilution)
```

### Article figure 11:

```{r}
# Save
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_11.png"),
  plot = MS_dilution,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_11.tiff"),
  plot = MS_dilution,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## Figure 12:

### Data and plot

```{r}
#Change and test directory
# # Set the filepath to your directory
# filepath <- "C:/Users/DanielMalheiro/Downloads/Exp7-241008/mzML-PAN"
# setwd(filepath)
# 
# # List files in the directory
# list.files()
# 
# # Define function to extract EIC for a target m/z
# extract_eic <- function(file_name, target_mz, ppm, polarity_label = "positive") {
#   # Load mzML file using xcmsRaw
#   raw_data <- xcmsRaw(file_name)
# 
#   # Calculate the m/z tolerance
#   mz_tol <- (ppm / 1e6) * target_mz
#   mz_range <- c(target_mz - mz_tol, target_mz + mz_tol)
# 
#   # Only keep scans in the correct polarity
#   positive_scans <- which(raw_data@polarity == polarity_label)  # 1 = positive
# 
#   # Extract EIC for those scans
#   eic <- rawEIC(raw_data, mzrange = mz_range)
# 
#   # Create the EIC data frame, including the file_name
#   eic_df <- data.frame(
#     rt = raw_data@scantime[positive_scans] / 60,  # Convert to minutes
#     intensity = eic$intensity[positive_scans],
#     scan = seq_along(positive_scans),
#     target = paste0("m/z ", round(target_mz, 4)),
#     file_name = rep(file_name, length(positive_scans))  # Add file_name to the data
#   ) %>%
#     mutate(average_intensity = rollmean(intensity, k = 3, fill = NA, align = "left"))
# 
#   return(eic_df)
# }
# 
# # List of mzML files
# files <- c(
#   "241008-Exp-PAN-1-035-NoWash-NIST.mzML",
#   "241008-Exp-PAN-1-036-NoWash-NIST.mzML",
#   "241008-Exp-PAN-1-037-NoWash-NIST.mzML",
#   "241008-Exp-PAN-1-014-22x-NIST.mzML",
#   "241008-Exp-PAN-1-015-22x-NIST.mzML",
#   "241008-Exp-PAN-1-016-22x-NIST.mzML",
#   "241008-Exp-PAN-1-028-04x-NIST.mzML",
#   "241008-Exp-PAN-1-029-04x-NIST.mzML",
#   "241008-Exp-PAN-1-030-04x-NIST.mzML",
#   "241008-Exp-PAN-1-021-08x-NIST.mzML",
#   "241008-Exp-PAN-1-022-08x-NIST.mzML",
#   "241008-Exp-PAN-1-023-08x-NIST.mzML"
# )
# 
# ppm <- 2
# target_mz <- 205.0972  # Tryptophan m/z value
# 
# # Extract EICs for all files
# eic_list <- lapply(files, function(file_name) {
#   extract_eic(file_name, target_mz, ppm)
# })


# saveRDS(eic_list, file = "eic_list.rds")

eic_list <- readRDS(here("Data","eic_list.rds"))

# Combine all EICs into a single data frame
combined_eic_df <- bind_rows(eic_list)

# Filter data to the retention time between 4 and 6 minutes
combined_eic_df_filtered <- combined_eic_df %>%
  filter(rt >= 4 & rt <= 6) %>%
    separate(
    file_name,
    into = c(
      "Date",
      "Exp",
      "PAN",
      "Batch",
      "Sequence",
      "Wash",
      "Sample"
         ),
    sep = "-", remove = FALSE
  ) %>%
  mutate(
    Sample = str_remove(Sample, "\\.mzML"),
    Wash = str_remove(Wash, "\\..mzML"),
    Sequence = as.numeric(Sequence),
    Wash = as.factor(Wash)
  ) %>%
  select(-Exp, -Batch) %>%
  arrange(Date) %>%
group_by(Wash, Sample) %>%  # Group by Wash and Sample
  mutate(
    Replicate = dense_rank(Sequence)  # Assign replicate numbers based on Sequence within Wash and Sample
  ) %>%
  ungroup()

# View the result
print(combined_eic_df_filtered)


combined_eic_df_filtered %>%
  ggplot(aes(x = rt, y = intensity, color = Wash)) +
  geom_line(linewidth = 1) +
  facet_wrap( ~Wash ~Replicate, ncol = 3) 
  labs(
    title = paste("Overlayed Normalized EICs (", ppm, "ppm, Positive Mode)"),
    x = "Retention Time (min)",
    y = "Normalized Intensity",
    color = "File Name"
  ) +
  theme_minimal()

  
# Assuming 'long_data' is your data frame and 'x_limits' is defined
filtered_data_2 <- long_data %>%
  filter(
    between(Times, 4, 6),
    Sequence %in% 1:45,
    Compound %in% c("Glucose-13C6", "Leucine-d10","Tryptophan-d5") ,
    Wash %in% c("22x", "08x" ,"04x", "NoWash", "PPT"),  # Filter for Wash conditions
    !(Replicate %in% c("1", "2", "3", "4", "6") & Sample == "Solvent"),
    Replicate %in% 1:8
  ) %>%
  mutate(Wash = factor(Wash, levels = c("22x","08x","04x","NoWash", "PPT")))

# Calculate Matrix Effect (ME) and Matrix Effect Factor (MEF) for each NIST replicate
matrix_effect_data <- filtered_data_2 %>%
  filter(Sample %in% c("NIST", "Solvent")) %>%  
  # First, calculate the average Solvent for each Scan and Wash (grouping by Scan and Wash)
  group_by(Sequence, Wash, Scan, Compound, Sample, Replicate) %>%
  summarise(
    Average_value = mean(Intensities, na.rm = TRUE),  # Calculate the average value of Average for each sample
    Times = dplyr::first(Times),  # Keep the Times for each Scan (this will keep the first occurrence)
    .groups = "drop") %>%
  pivot_wider(names_from = Sample, values_from = Average_value) %>%
  # Now, calculate the Matrix Effect (ME) for each NIST replicate using the averaged Solvent value
  group_by(Wash, Scan, Compound) %>%
  summarise(
    Solvent_mean = mean(Solvent, na.rm = TRUE),  # Calculate average Solvent for each Scan and Wash
    NIST_value = NIST[!is.na(NIST)],  # Keep individual NIST values (replicates)
    Times = dplyr::first(Times),  # Keep the Times value for each Scan and Wash
    Replicate = Replicate[!is.na(NIST)],  # Keep individual Replicate values (for NIST)
    .groups = "drop"
  ) %>%
  # Calculate Matrix Effect (ME) and Matrix Effect Factor (MEF) for each NIST replicate
  mutate(
    Matrix_Effect = ((NIST_value / Solvent_mean) * 100) - 100,  # ME
    Matrix_Effect_Factor = 1 + (Matrix_Effect / 100)  # MEF
  )

# Plot Matrix Effect Factor (MEF) over time
matrix_effect_factor_time_plot <- ggplot(matrix_effect_data, aes(x = Times, y = Matrix_Effect_Factor, color = Wash)) +
  geom_line() +
  geom_vline(xintercept = 4.84, linetype = "dotted", color = "black" ) +
 geom_hline(yintercept = 1.00, linetype = "dashed", color = "black" ) +
  facet_grid( ~Wash + Replicate ~Compound ) +
  labs(
    title = "Matrix Effect Factor (MEF) over Time for NIST Replicates",
    x = "Time (minutes)",
    y = "Matrix Effect Factor",
    color = "Wash Condition"
  ) +
  theme_minimal() +
  theme(legend.position = "top")

# Print the Matrix Effect Factor plot
print(matrix_effect_factor_time_plot)
```

### Plot 1

```{r}
# Step 1: Filter for the closest `rt` to 4.84 within each group (Wash and Replicate)
combined_eic_df_filtered2 <- combined_eic_df_filtered %>%
  group_by(Wash, Replicate) %>%  
 #filter(rt == rt[which.min(abs(rt - 4.85))]) %>%
  filter(rt == rt[which.max(intensity)]) %>%
  ungroup()  # Remove grouping after filtering

# Step 2: Find the closest `rt`, `Times`, and `Scan` in `matrix_effect_data` for each `rt`
combined_eic_df_filtered2 <- combined_eic_df_filtered2 %>%
  mutate(
    #closest_rt = purrr::map_dbl(rt, ~matrix_effect_data$Times[which.min(abs(matrix_effect_data$Times - .))]),
    closest_time = purrr::map_dbl(rt, ~matrix_effect_data$Times[which.min(abs(matrix_effect_data$Times - .))]),
    closest_scan = purrr::map_dbl(closest_time, ~matrix_effect_data$Scan[which.min(abs(matrix_effect_data$Times - .))]),
    scan_diff = scan - closest_scan  # Calculate the difference of the scans
  ) %>%
  ungroup()  # Remove grouping after mutation

# Step 3: Apply `scan_diff` to the original data and adjust the scan
combined_eic_df_with_shift <- combined_eic_df_filtered %>%
  left_join(
    combined_eic_df_filtered2 %>% select(Wash, Replicate, scan_diff),
    by = c("Wash", "Replicate")
  ) %>%
  mutate(
    adjusted_scan = scan - scan_diff  # Apply the scan shift to get the adjusted scan
  )

# Step 4: Join `Matrix_Effect_Factor` (MEF) based on `adjusted_scan`
# -----------------------------
combined_eic_df_with_shift <- combined_eic_df_with_shift %>%
  left_join(
    matrix_effect_data %>%
      select(Wash, Replicate, Scan, Matrix_Effect_Factor, Compound),
    by = c("Wash", "Replicate", "adjusted_scan" = "Scan")
  ) %>%
  mutate(
    corrected_intensity = intensity / Matrix_Effect_Factor,
    
    # Wash factor + labels
    Wash = factor(Wash, levels = c("22x", "08x", "04x", "NoWash", "PPT")),
    Wash = recode(
      Wash,
      "22x"    = "PLR 22x Wash",
      "08x"    = "PLR 8x Wash",
      "04x"    = "PLR 4x Wash",
      "NoWash" = "PLR Unwashed",
      "PPT"    = "PPT"
    ),
    
    # Compound labels for plotting (parsed)
    Compound_plot = recode(
      Compound,
      "Average"        = "Average",
      "Tryptophan-d5"  = "Tryptophan-d[5]",
      "Leucine-d10"    = "Leucine-d[10]",
      "Glucose-13C6"   = "Glucose-{}^{13}*C[6]"
    )
  )

# -----------------------------
# Define explicit facet order
# -----------------------------
compound_plot_levels <- c(
  "Tryptophan-d[5]",
  "Leucine-d[10]",
  "Glucose-{}^{13}*C[6]"
)

# -----------------------------
# Step 5: Pivot to long format
# -----------------------------
combined_eic_df_filtered_long <- combined_eic_df_with_shift %>%
  pivot_longer(
    cols = c(intensity, corrected_intensity),
    names_to = "Intensity_Type",
    values_to = "Intensity_Value"
  ) %>%
  group_by(
    Wash, rt, Matrix_Effect_Factor, Sample, Replicate,
    Intensity_Type, Sequence, Compound, Compound_plot
  ) %>%
  summarise(
    Average_Intensity = mean(Intensity_Value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Compound_plot = factor(
      Compound_plot,
      levels = compound_plot_levels
    )
  )

# -----------------------------
# Scaling factor for MEF
# -----------------------------
scaling_factor <-
  max(combined_eic_df_filtered_long$Average_Intensity, na.rm = TRUE) /
  max(combined_eic_df_filtered_long$Matrix_Effect_Factor, na.rm = TRUE)

# -----------------------------
# Step 7: Plot
# -----------------------------
All_plot_EIC_long <- combined_eic_df_filtered_long %>%
  filter(
    between(rt, 4.6, 5.1),
    Wash == "PLR 4x Wash"
  ) %>%
  mutate(
    Intensity_Type = recode(
      Intensity_Type,
      intensity = "Uncorrected Tryptophan Intensity",
      corrected_intensity = "Corrected Tryptophan Intensity"
    ),
    Intensity_Type = factor(
      Intensity_Type,
      levels = c(
        "Uncorrected Tryptophan Intensity",
        "Corrected Tryptophan Intensity",
        "Matrix Factor"
      )
    )
  ) %>%
  ggplot() +
  
  # Intensity traces
  geom_line(
    aes(
      x = rt,
      y = Average_Intensity,
      color = Intensity_Type,
      group = Intensity_Type
    ),
    linewidth = 0.5
  ) +
  
  # MEF trace (secondary axis)
  geom_line(
    aes(
      x = rt,
      y = Matrix_Effect_Factor * scaling_factor,
      color = "Matrix Factor"
    ),
    linewidth = 0.5
  ) +
  
  geom_hline(
    yintercept = 1.0 * scaling_factor,
    color = "red",
    linetype = "dashed"
  ) +
  
  facet_grid(
    Replicate ~ Compound_plot,
    labeller = labeller(Compound_plot = label_parsed)
  ) +
  
  scale_y_continuous(
    name = "Intensity",
    sec.axis = sec_axis(
      trans = ~ . / scaling_factor,
      name = "Matrix Factor"
    )
  ) +
  
  scale_color_manual(
    values = c(
      "Uncorrected Tryptophan Intensity" = "blue",
      "Corrected Tryptophan Intensity"   = "green",
      "Matrix Factor"                    = "red"
    )
  ) +
  
  labs(
    x = "Retention Time (min)",
    y = "Intensity"
  ) +
  
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.title = element_blank(),
    legend.position = "bottom",
    strip.text.y = element_text(angle = 0),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black")
  )

# -----------------------------
# Add panel label "A"
# -----------------------------
All_plot_EIC_long <- All_plot_EIC_long +
  labs(title = "A") +
  theme(
    plot.title.position = "plot",
    plot.title = element_text(
      hjust = 0,          # left-align
      vjust = 1,
      face = "bold",
      size = 14
    )
  )

# -----------------------------
# Print
# -----------------------------
print(All_plot_EIC_long)
```

### Plot 2: barchart with error bars:

```{r}

# Step 1: Apply trapezoidal integration for each Intensity_Type (average and corrected intensity)
integrated_data <- combined_eic_df_filtered_long %>% 
  filter(!is.na(rt) & !is.na(Average_Intensity)) %>%  # Filter out NA values in rt and Average_Intensity
  group_by(Wash, Sample, Replicate, Intensity_Type, Sequence, Compound) %>%
  summarise(
    integration_area = trapz(rt, Average_Intensity),  # Trapezoidal integration
    .groups = "drop"
  )

# Step 2: Reshape data to have 'average_intensity' and 'corrected_intensity' in separate columns
integrated_data_wide <- integrated_data %>%
  pivot_wider(
    names_from = Intensity_Type,  # Spread 'Intensity_Type' into separate columns
    values_from = integration_area  # Fill with integration_area
  )

# Step 3: Pivot back to long format to have the intensity types in a single column again for easier plotting
integrated_data_long_wide <- integrated_data_wide %>%
  pivot_longer(
    cols = starts_with("intensity") | starts_with("corrected_intensity"),  # Include all intensity columns
    names_to = "Intensity_Type",  # Create a column for Intensity_Type
    values_to = "integration_area"  # Store the corresponding values in integration_area
  )
# Step 4: Filter out unwanted rows and create a combined Intensity_Type with Compound

integrated_data_long_wide_filtered <- integrated_data_long_wide %>%
  group_by(Wash, Replicate, Compound) %>%
  filter(!(Intensity_Type == "intensity" & duplicated(Replicate))) %>%  # Remove duplicates of average_intensity for each replicate
  mutate(
    # Create a combined Intensity_Type with Compound to differentiate the intensity types by compound
    Intensity_Compound = paste(Intensity_Type, Compound, sep = "_"),
    Compound = if_else(
      Intensity_Type == "intensity" & Compound == "Glucose-13C6",
      "Uncorrected",
      Compound
    ),
     # Keep other values of Compound unchanged
    Compound = factor(
      Compound,
      levels = c("Uncorrected", "Tryptophan-d5", "Leucine-d10", "Glucose-13C6")
    )  # Set the order of levels for Compound
  ) %>%
  filter(!is.na(Compound),
    !(Intensity_Type == "intensity" & Compound != "Uncorrected")  # Remove all average_intensity except for Normal compound
  )

# Step 1: Calculate the standard deviation (SD), standard error (SE), and RSD% for each Wash and Compound
error_data <- integrated_data_long_wide_filtered %>%
  group_by(Wash, Compound) %>%
  summarise(
    Mean = mean(integration_area, na.rm = TRUE),
    SD = sd(integration_area, na.rm = TRUE),
    SE = SD / sqrt(n()),  # Calculate standard error
    RSD_percent = (SD / Mean) * 100,  # Calculate RSD percentage
    .groups = "drop"
  )

# Step 2: Create the plot with bar chart, error bars, and RSD% labels
barplot_compounds_with_error <- ggplot(error_data, aes(x = Compound, y = Mean, fill = Compound)) +
  # Create the bars
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), color = "black", linewidth = 0.5) + 
  # Add error bars
  geom_errorbar(aes(ymin = Mean - SE, ymax = Mean + SE), 
                position = position_dodge(width = 0.9), width = 0.25, color = "black") + 
  # Add RSD% labels on top of the bars
  geom_text(aes(y = Mean + SE + 0.05,  # Adjust position to be above the error bars
                label = paste0(signif(RSD_percent, 2), "%")),  # Display RSD% with 3 significant figures
            position = position_dodge(width = 0.9), color = "black", size = 3, vjust = -0.5) +  # Position above bars
  scale_y_continuous(labels = scales::scientific,  # Use scientific notation for y-axis
                     limits = c(0, max(error_data$Mean + error_data$SE) * 1.1)) +  # Set a max y limit, 20% above the highest bar
  facet_wrap(~Wash, ncol = 4) +  # Facet by Wash condition
  labs(
    title = "Comparison of Normal vs Corrected Intensity by PCI-IS with Error Bars and RSD%",
    x = NULL,
    y = "Integrated Area",
    fill = "Intensity Type"
  ) + 
  theme_minimal() +
  theme(
    legend.position = "none",  # Hide legend
    plot.title = element_blank(),
    legend.title = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better readability
    panel.border = element_blank(),  # Remove panel border
    panel.grid.major = element_blank(),  # Remove major gridlines
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black"),  # Add axis lines
    axis.ticks = element_line(color = "black")
  )


barplot_compounds_with_error <- barplot_compounds_with_error +
  labs(title = "B") +
  theme(
    plot.title.position = "plot",
    plot.title = element_text(
      hjust = 0,          # left-align
      vjust = 1,
      face = "bold",
      size = 14
    )
  )

print(barplot_compounds_with_error)


```

### Combine Plots:

```{r}
combined_mef_plot <- All_plot_EIC_long / barplot_compounds_with_error 
 
print(combined_mef_plot)

```

### Article figure 12

```{r}

#Save
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_12.png"),
  plot = combined_mef_plot,
  width = 20,
  height = 20,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_12.tiff"),
  plot = combined_mef_plot,
  width = 20,
  height = 20,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## Figure 13. Histogram of RSD uncorrected and correct

### Data Preparation

```{r}
#import
file <- "Skyline-PCI-Exp7-241008.tsv" 
data <- read_tsv(here("Data",file))

#### This should have been prviously load in from Figure 3, or else uncomment it
# replacements <- c(
#   "Leucine d10" = "Leucine-d10" ,
#    "Glutamic acid-d5"= "GlutamicAcid-d5",
#    "DL-Tryptophan-d5" = "Tryptophan-d5",
#    "Stearic-d35 (18:0)" = "StearicAcid-d35",
#    "Cholic acid-d4" = "CholicAcid-d4")
# 
# data1 <- data %>%
#   dplyr::rename(
#     Chromatograms = FileName,
#     Compound = PeptideModifiedSequence,
#     Adduct = PrecursorCharge,
#     Charge = ProductCharge
#   ) %>%
#   select(-IsotopeLabelType, -TotalArea, -FragmentIon) %>%
#   separate(
#     Chromatograms,
#     into = c(
#       "Date",
#       "Exp",
#       "PAN",
#       "Batch",
#       "Sequence",
#       "Wash",
#       "Sample",
#       "Dilution"),
#     sep = "-",
#     remove = FALSE
#   ) %>%
#   mutate(
#     Sample = str_remove(Sample, "\\.raw"),
#     Dilution = str_remove(Dilution,"\\.raw"),
#     Wash = str_remove(Wash,"\\.raw"),
#     Compound = replace(Compound, Compound == "#N/A", "TIC"),
#     Compound = recode(Compound, !!!replacements),  # Apply replacements
#     Sequence = as.numeric(Sequence),
#     Dilution = as.factor(Dilution)
#   ) %>%
#   select(-Batch,-Exp) %>%
#   arrange(Date) %>%
#   filter(#Sample %in% c("Process", "NIST"),
#          Adduct != "[M35H2-H]",
#         Adduct != "[M5H2+H]",
#         Compound != "Isoleucine-13C6",
#         Compound != "Arginine-13C6") %>%
#   group_by(Wash, Sample, Compound, Charge) %>%
#   mutate(Replicate = row_number()) %>%
#  ungroup() %>%
#   select(1:5, Replicate, everything()) %>%
#   #filter(Replicate <= 3) %>%
#   mutate(Sample = ifelse(Wash == "NoFilter" & Sample == "Blank", "Reference", Sample)) %>%
#    filter(Compound != "TIC") 
# 
# # Get unique washes to replicate Reference for each wash
# unique_washes <- unique(data1$Wash)
# print(unique_washes)
# 
# # Add Reference sample for all washes except "NoFilter"
# data1 <- data1 %>%
#   bind_rows(
#     data1 %>%
#       filter(Sample == "Reference") %>%
#       select(-Wash) %>%  # Remove the existing Wash column
#       crossing(Wash = unique(data1$Wash[data1$Wash != "NoFilter"]))  # Add each wash except "NoFilter"
#   ) %>%
# filter(Wash != "NoFilter") %>%
# filter(Wash %in% c("NoFilter", "22x", "08x", "04x","NoWash","PPT")) %>%
#    mutate(
#     Sample = case_when(
#       Sample == "Reference" ~ "Solvent",
#       Sample == "Blank" ~ "Process",
#       TRUE ~ Sample))  
# 
# unique_washes <- unique(data1$Wash) %>% print()
# unique_sample <- unique(data1$Sample) %>% print()
# 
# data_intensity <- data1 %>%
#   select(Chromatograms, Compound, Intensities) %>%
#   separate_wider_delim(Intensities,
#                        delim = ";",
#                       names_sep = "",
#                       too_few = "align_start") %>%
#   mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))  
#   
# data_time <- data1 %>%
#   select(Chromatograms,Compound, Times) %>%
#   separate_wider_delim(Times,
#                        delim = ";",
#                        names_sep = "",
#                        too_few = "align_start") %>%
#   mutate(across(3:ncol(.), ~ as.numeric(gsub(",", ".", .))))
# combined_data <- data1 %>%
#   select(-Intensities,-Times) %>%
#   right_join(data_time, by = c("Chromatograms","Compound")) %>%
#   right_join(data_intensity, by = c("Chromatograms","Compound"))
# 
# long_data_NTC <- combined_data %>%
#   pivot_longer(
#     cols = c(starts_with("Times"), starts_with("Intensities")),
#     names_to = c(".value", "Scan"),
#     names_pattern = "(Times|Intensities)(\\d+)") %>%
#   mutate(
#     Scan = as.numeric(Scan),
#     Intensities = if_else(Intensities == 0, 1, Intensities)  
#   ) %>%
#   filter(Times >= 0, Times <= 15) %>%
#   mutate(Average = rollmean(Intensities, k = 9, fill = NA, align = "left"))

# 1. Read file as raw table
raw <- read_delim(here("Data", "Feature-Boundaries.txt"),
                  delim = "\t", col_names = TRUE, trim_ws = TRUE)

raw2 <- raw %>% mutate(row_id = row_number())

# --------------------------
# COMPOUND ROWS
# --------------------------
# Take row 1 as header
compound_header <- as.character(unlist(raw2[1, ]))

# Keep rows with [M+...]
compound_rows <- raw2 %>%
  filter(if_any(everything(), ~ str_detect(.x, "\\[M\\+"))) %>%
  select(-row_id)

compound_rows <- compound_rows %>%
  select(where(~ !all(is.na(.))))


# --------------------------
# PEAK ROWS
# --------------------------
# Find all "Apex m/z" header rows
peak_header_rows <- raw2 %>%
  filter(if_any(everything(), ~ str_detect(.x, "Apex m/z"))) %>%
  pull(row_id)

# Extract the header (take the text of the first Apex row)
peak_header <- as.character(unlist(raw2[peak_header_rows[1], ]))

# Extract the *first row after each Apex header*
peak_first_rows <- raw2 %>%
  filter(row_id %in% (peak_header_rows + 1)) %>%
  select(-row_id)

# Apply header
names(peak_first_rows) <- peak_header

peak_first_rows <- peak_first_rows %>%
  select(-1)

# --------------------------
# PAIR BY POSITION
# --------------------------
compound_rows <- compound_rows %>% mutate(pair_id = row_number())
peak_first_rows <- peak_first_rows %>% mutate(pair_id = row_number())

paired <- compound_rows %>%
  inner_join(
    peak_first_rows,
    by = c("m/z" = "Apex m/z", "RT [min]" = "Apex RT [min]", "Area" = "Area"),
    suffix = c(".compound", ".peak")
  )

# --------------------------
# RESULT
# --------------------------
paired

clean_numeric <- function(x) {
  as.numeric(gsub(",", ".", x))
}

RT_interval <- paired %>%
  select(
    Ion,
    Charge,
    `Molecular Weight`,
    `m/z`,
    `RT [min]`,
    `# MI`,
    Area,
    `Study File ID.compound`,
    `Left RT [min]`,
    `Right RT [min]`,
    `FWHM [min].peak`,
    pair_id.peak
  ) %>%
   mutate(
    `Molecular Weight` = clean_numeric(`Molecular Weight`),
    `m/z`              = clean_numeric(`m/z`),
    `RT [min]`         = clean_numeric(`RT [min]`),
    `# MI`             = clean_numeric(`# MI`),
    Area      = clean_numeric(Area),
    `Left RT [min]`    = clean_numeric(`Left RT [min]`),
    `Right RT [min]`   = clean_numeric(`Right RT [min]`),
    `FWHM [min].peak`  = clean_numeric(`FWHM [min].peak`)
  ) %>%
  dplyr::rename("Study File ID" = `Study File ID.compound`,
              )
  
file.list <- read_excel(here("Data","Importfiles-CD.xlsx")) %>%
  select(1:2)  %>%
  mutate(
    file = tools::file_path_sans_ext(basename(`File Name`)))  %>%
  select(-`File Name`) %>%
  separate(
    file,
    into = c(
      "Date",
      "Exp",
      "PAN",
      "Batch",
      "Sequence",
      "Wash",
      "Sample"
         ),
    sep = "-", remove = FALSE
  ) %>%
  mutate(
    Sequence = as.numeric(Sequence),
    Wash = as.factor(Wash)
  ) %>%
  select(-Exp, -Batch, -Date, -PAN,-file) %>%
  group_by(Wash, Sample) %>%
  filter(Sequence %in% 8:45) %>%
  mutate(
    Replicate = dense_rank(Sequence)  # Assign replicate numbers based on Sequence within Wash and Sample
  ) %>%
  ungroup()

# Assuming 'long_data' is your data frame and 'x_limits' is defined
filtered_data_2 <- long_data %>%
  filter(
    #between(Times, 4, 6),
    Sequence %in% 1:45,
    Compound %in% c(
    #"Indole-d6",
    "Leucine-d10",
    "GlutamicAcid-d5",
    "Carnitine-d9",
    "Glucose-13C6",
    "Tryptophan-d5",
    #"StearicAcid-d35",
    "CholicAcid-d4"), 
    Charge == 1,
    Wash %in% c("22x", "08x" ,"04x", "NoWash", "PPT"),  # Filter for Wash conditions
    !(Replicate %in% c("1", "2", "3", "4", "6") & Sample == "Solvent"),
    Replicate %in% 1:8
  ) %>%
  mutate(Wash = factor(Wash, levels = c("22x","08x","04x","NoWash", "PPT")))

# Calculate Matrix Effect (ME) and Matrix Effect Factor (MEF) for each NIST replicate
matrix_effect_data <- filtered_data_2 %>%
  filter(Sample %in% c("NIST", "Solvent")) %>%  
  # First, calculate the average Solvent for each Scan and Wash
  group_by(Sequence, Wash, Scan, Compound, Sample, Replicate) %>%
  reframe(
    Average_value = mean(Intensities, na.rm = TRUE),
    Times = dplyr::first(Times)
  ) %>%
  pivot_wider(names_from = Sample, values_from = Average_value) %>%
  # Now calculate ME & MEF
  group_by(Wash, Scan, Compound) %>%
  reframe(
    Solvent_mean = mean(Solvent, na.rm = TRUE),
    NIST_value   = NIST[!is.na(NIST)],      # keep replicate values
    Times        = dplyr::first(Times),
    Replicate    = Replicate[!is.na(NIST)]
  ) %>%
  mutate(
    Matrix_Effect        = ((NIST_value / Solvent_mean) * 100) - 100,
    Matrix_Effect_Factor = 1 + (Matrix_Effect / 100)
  )

feat.intensity.threshold  <- 1e4 #(previous 1e6)
signal.factor <- 3


filepath <- "C:/Users/DanielMalheiro/OneDrive - Clinical Microbiomics/Documents/R scripts"
setwd(filepath)
file <- "PCI-peaksforR.xlsx" 
data <- read_excel(file)
data_meta <- read_excel(file, sheet = 2) %>%
  dplyr::rename(rt = `RT [min]`) %>%
  mutate(
    Charge = case_when(
      Polarity == "POS" ~ 1,
      Polarity == "NEG" ~ -1,
      TRUE              ~ NA_real_
    )
  ) %>%
  select(-Polarity)


# --- Step 1: Pivot to long format ---
data_feature_long <- data %>%
  pivot_longer(
    cols = starts_with("X"),
    names_to = "Feature",
    values_to = "Intensity"
  ) %>%
  inner_join(
    data_meta,
    by = c("Feature" = "Compound #")
  ) %>%
  select(-DP, -"Relative precision (%)", -"LOD")

# --- Step 2: Identify duplicated features (same intensity) ---
dup_features <- data_feature_long %>%
  group_by(Intensity) %>%
  filter(n_distinct(Feature) > 1) %>%    # intensity shared by multiple features
  arrange(Feature) %>%
  slice(-1) %>%                          # remove all except first
  pull(Feature)

# --- Step 3: Remove them ---
data_feature_long <- data_feature_long %>%
  filter(!Feature %in% dup_features)

# Optional: report how many removed
cat("Removed duplicated features:", length(dup_features), "\n")

# --- Step 2: Filter only NIST samples ---
nist_data <- data_feature_long %>%
  filter(Sample == "NIST") #%>%
  #filter(!is.na(Name)) #(previously removed the NA)


# Extract the Compound # values to exclude from homolgue series, exclusde those in homoglogue_id 3 and 6
exclude_compounds <- merged_df %>%
  filter(!homologue_id %in% c(3, 6)) %>%
  pull(`Compound #`)

# --- Step 4: Compute global RSD across ALL Washes (for each feature) ---
rsd_global <- nist_data %>%
  group_by(Feature) %>%
  summarise(
    global_mean = mean(Intensity, na.rm = TRUE),
    global_sd   = sd(Intensity, na.rm = TRUE),
    global_RSD  = (global_sd / global_mean) * 100,
    .groups = "drop"
  )
  

# --- Step 3 + 4 combined: Compute RSD per Wash and Global RSD ---
rsd_per_wash <- nist_data %>%
  group_by(Wash, Feature) %>%
  summarise(
    mean_val = mean(Intensity, na.rm = TRUE),
    sd_val   = sd(Intensity, na.rm = TRUE),
    RSD      = (sd_val / mean_val) * 100,
    .groups = "drop"
  ) %>%
  group_by(Feature) %>%
  filter(all(mean_val > feat.intensity.threshold)) %>%  # keep feature only if ALL washes pass
  ungroup() %>%
  filter(!Feature %in% exclude_compounds) %>%
  group_by(Feature) %>%
  mutate(
    ppt_mean   = mean_val[Wash == "PPT"],
    other_mean = mean(mean_val[Wash != "PPT"], na.rm = TRUE)
  ) %>%
  filter(!(ppt_mean > other_mean * signal.factor)) %>%
  mutate(
    nowash_mean = mean_val[Wash == "NoWash"],
    other_mean2 = mean(mean_val[Wash != "NoWash"], na.rm = TRUE)
  ) %>%
  filter(!(nowash_mean > other_mean2 * signal.factor)) %>%
  ungroup() %>%
  # --- Join with global RSD ---
  left_join(
    nist_data %>%
      group_by(Feature) %>%
      summarise(
        global_mean = mean(Intensity, na.rm = TRUE),
        global_sd   = sd(Intensity, na.rm = TRUE),
        global_RSD  = (global_sd / global_mean) * 100,
        .groups = "drop"
      ),
    by = "Feature"
  ) %>%
  left_join(
    data_meta %>% select(`Compound #`, Name, rt, mz, Adduct, Charge),
    by = c("Feature" = "Compound #")
  ) %>%
  filter(Charge == 1)


#using rsd_per_wash to see if how many files it has found based 

ppm <- 5
rt_tol <- 0.1

# helper function to count files for each compound
count_files_for_compound <- function(name, mz, rt) {
  ppm_tol  <- mz * ppm / 1e6
  mz_lower <- mz - ppm_tol
  mz_upper <- mz + ppm_tol
  
  Tryp_MEF <- RT_interval %>%
    filter(between(`m/z`, mz_lower, mz_upper)) %>%
    filter(between(as.numeric(`RT [min]`), rt - rt_tol, rt + rt_tol)) %>%
    inner_join(file.list, by = "Study File ID") %>%
     filter(Sample != "Blank") %>%
    mutate(`RT [min]` = as.numeric(`RT [min]`)) %>%
    mutate(ref_RT = mean(`RT [min]`, na.rm = TRUE)) %>%
    group_by(`Study File ID`) %>%
    slice_min(abs(`RT [min]` - ref_RT), with_ties = FALSE) %>%
    ungroup()
  
  return(length(unique(Tryp_MEF$`Study File ID`)))
}

# --- apply for all compounds in rsd_per_wash ---
rsd_per_wash15 <- rsd_per_wash %>%
  rowwise() %>%
  mutate(
    n_files = count_files_for_compound(Name, mz, rt)
  ) %>%
  filter(n_files == 15) %>%
  ungroup()

ppm <- 5
rt_tol <- 0.1

# ------------ Helper Function ------------
build_Tryp_MEF <- function(mz, rt) {
  ppm_tol  <- mz * ppm / 1e6
  mz_lower <- mz - ppm_tol
  mz_upper <- mz + ppm_tol
  
  RT_interval %>%
    filter(between(`m/z`, mz_lower, mz_upper)) %>%
    filter(between(as.numeric(`RT [min]`), rt - rt_tol, rt + rt_tol)) %>%
    inner_join(file.list, by = "Study File ID") %>%
    filter(Sample != "Blank") %>%
    mutate(`RT [min]` = as.numeric(`RT [min]`)) %>%
    mutate(ref_RT = mean(`RT [min]`, na.rm = TRUE)) %>%
    group_by(`Study File ID`) %>%
    slice_min(abs(`RT [min]` - ref_RT), with_ties = FALSE) %>%
    ungroup()
}

# ------------ Auto-load or compute ------------
if (file.exists(here("Data", "all_result.rds"))) {
  
  message("▶ Loading saved all_result.rds...")
  all_result <- readRDS(here("Data", "all_result.rds"))
  
} else {

  
  message("▶ No saved file found — running full analysis...")

  all_result <- rsd_per_wash15 %>%
    rowwise() %>%
    do({
      compound_name <- .$Name
      mz_target     <- .$mz
      rt_target     <- .$rt
      feature_id    <- .$Feature
      
      message("Processing: ", compound_name,
              " (m/z=", mz_target, ", rt=", rt_target, ")")
      
      Tryp_MEF <- build_Tryp_MEF(mz_target, rt_target)
      
      result <- Tryp_MEF %>%
        full_join(matrix_effect_data, by = c("Wash", "Replicate")) %>%
        filter(
          Times >= `Left RT [min]`,
          Times <= `Right RT [min]`
        ) %>%
        group_by(Wash, Replicate, Compound) %>%
        summarise(
          mean_rt    = mean(Times, na.rm = TRUE),
          mean_MEF   = mean(Matrix_Effect_Factor, na.rm = TRUE),
          median_MEF = median(Matrix_Effect_Factor, na.rm = TRUE),
          min_MEF    = min(Matrix_Effect_Factor, na.rm = TRUE),
          Area       = dplyr::first(Area),
          .groups    = "drop"
        ) %>%
        mutate(
          corrected_mean   = Area / mean_MEF,
          corrected_median = Area / median_MEF,
          corrected_min    = Area / min_MEF,
          Name             = compound_name,
          Feature          = feature_id
        )
      
      result
    }) %>%
    ungroup()
  
  # Save for next time
  saveRDS(all_result,here("Data", "all_result.rds"))
  message("✔ Saved results to all_result.rds")
}

# ------------ Ready to continue ------------
message("▶ all_result is loaded and ready!")

# --- Step 1: Add "uncorrected" column to the long format ---
result_long <- all_result %>%
  distinct(Feature, Name, Wash, Replicate, Compound, .keep_all = TRUE) %>%
  mutate(uncorrected = Area) %>%   # keep raw area
  pivot_longer(
    cols = c(uncorrected, corrected_mean, corrected_median, corrected_min),
    names_to = "Correction_Type",
    values_to = "Corrected_Value"
  )


```

### Training and Validation

```{r}

# Matrix Effect Correction Evaluation (Training vs Validation)
# =============================

set.seed(1)


table.test <- result_long %>%
select( Wash, Replicate, Feature, Compound, Correction_Type, Corrected_Value) %>%
dplyr::rename(
Treatment = Wash,
Replicate = Replicate,
Feature = Feature,
PCI = Compound,
CorrectionType = Correction_Type,
CorrectedArea = Corrected_Value)

df <- table.test

# =============================
# 1. Data setup
# =============================
df <- df %>%
  mutate(
    CorrectionType = factor(
      CorrectionType,
      levels = c("uncorrected", "corrected_mean", "corrected_median", "corrected_min")
    )
  )

# =============================
# 2. Random Split: 1 Validation per Treatment
# =============================

validation_ids <- df %>%
  distinct(Treatment, Replicate) %>%
  group_by(Treatment) %>%
  sample_n(1) %>%                     # one replicate per treatment for validation
  ungroup() %>%
  mutate(Set = "Validation")

split_df <- df %>%
  left_join(validation_ids, by = c("Treatment", "Replicate")) %>%
  mutate(Set = ifelse(is.na(Set), "Training", Set))

train_df <- split_df %>% filter(Set == "Training" & CorrectionType != "uncorrected")
val_df <- split_df %>%
  filter(Set == "Validation") %>%
  mutate(
    PCI = if_else(
      CorrectionType == "uncorrected",
      "uncorrected",
      PCI
    )
  ) %>%
  distinct(
    Treatment, Replicate, Feature, PCI, CorrectionType,
    .keep_all = TRUE
  )

uncorrected_df <- split_df %>% filter(CorrectionType == "uncorrected")

uncorr_train <- uncorrected_df %>%
  filter( Set == "Training") %>%
  group_by(Feature, PCI) %>%
  summarise(
    RSD_val_uncorr = 100 * sd(CorrectedArea, na.rm = TRUE) / mean(CorrectedArea, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(Feature, PCI) %>%
  summarise(Mean_RSD_val_uncorr = mean(RSD_val_uncorr, na.rm = TRUE), .groups = "drop")

# =============================
# 3. Training RSD calculation (Feature × PCI × CorrectionType)
# =============================


rsd_train <- train_df %>%
  group_by(Feature, PCI, CorrectionType) %>%
  summarise(
    corrected_rsd =
      100 * sd(CorrectedArea, na.rm = TRUE) /
      mean(CorrectedArea, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  left_join(
    uncorr_train %>%
      select(Feature, Mean_RSD_val_uncorr) %>%
      distinct(),
    by = "Feature"
  ) %>%
  pivot_longer(
    cols = c(corrected_rsd, Mean_RSD_val_uncorr),
    names_to = "rsd_source",
    values_to = "train_rsd"
  ) %>%
  filter(!is.na(train_rsd)) %>%
  mutate(
    CorrectionType = if_else(
      rsd_source == "Mean_RSD_val_uncorr",
      "uncorrected",
      CorrectionType
    ),
    PCI = if_else(
      CorrectionType == "uncorrected",
      "uncorrected",
      PCI
    )
  ) %>%
  select(Feature, PCI, CorrectionType, train_rsd) %>%
  distinct(Feature, PCI, CorrectionType, .keep_all = TRUE)


# =============================
# 4. Best correction per Feature (lowest training RSD)
# =============================
best_combo <- rsd_train %>%
  group_by(Feature) %>%
  slice_min(train_rsd, n = 1) %>%
  ungroup() %>%
  dplyr::rename(Best_PCI = PCI, Best_Correction = CorrectionType)

# =============================
# 5. Validation RSDs (using best combo)
# =============================
val_best <- val_df %>%
  inner_join(best_combo, by = c("Feature", "PCI" = "Best_PCI", "CorrectionType" = "Best_Correction"))

rsd_val_best <- val_best %>%
  group_by(Feature, Best_PCI = PCI, Best_Correction = CorrectionType) %>%
  summarise(
    RSD_val_best = 100 * sd(CorrectedArea, na.rm = TRUE) / mean(CorrectedArea, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(Feature, Best_PCI, Best_Correction) %>%
  summarise(Mean_RSD_val_best = mean(RSD_val_best, na.rm = TRUE), .groups = "drop")

# =============================
# 6. Validation uncorrected RSDs (same features + PCI)
# =============================
uncorr_val <- uncorrected_df %>%
  filter( Set == "Validation") %>%
  semi_join(rsd_val_best, by = "Feature") %>%
  group_by(Feature, PCI) %>%
  summarise(
    RSD_val_uncorr = 100 * sd(CorrectedArea, na.rm = TRUE) / mean(CorrectedArea, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(Feature, PCI) %>%
  summarise(Mean_RSD_val_uncorr = mean(RSD_val_uncorr, na.rm = TRUE), .groups = "drop")

# =============================
# 7. Merge results and compute improvement
# =============================
validation_summary <- rsd_val_best %>%
  left_join(uncorr_val, by = c("Feature", "Best_PCI" = "PCI")) %>%
  group_by(Feature, Best_PCI) %>%
 mutate(
  Mean_RSD_val_uncorr = coalesce(Mean_RSD_val_uncorr, Mean_RSD_val_best)
) %>%
  mutate(
    Improvement = Mean_RSD_val_uncorr - Mean_RSD_val_best,
    Percent_Improvement = 100 * Improvement / Mean_RSD_val_uncorr
  )


# Count features that improved (RSD_best < RSD_uncorr)
improvement_count <- validation_summary %>%
  group_by(Best_Correction) %>%
  summarise(
    Improved = sum(Mean_RSD_val_best < Mean_RSD_val_uncorr, na.rm = TRUE),
    Total = n(),
    Percent_Improved = 100 * Improved / Total,
    .groups = "drop"
  )

print(improvement_count)
```

### Plot

```{r}
######## Histogram + RT Chromatogram Improvement Plot (Figure 13)

RSD_CUTOFF <- 5  # change here only (1, 2, 10…)

# ============================================================
# 1️⃣ Prep data for histogram
# ============================================================

plot_rsd_hist <- validation_summary %>%
  select(Feature, Mean_RSD_val_uncorr, Mean_RSD_val_best) %>%
  dplyr::rename(
    Uncorrected = Mean_RSD_val_uncorr,
    Corrected   = Mean_RSD_val_best
  ) %>%
  pivot_longer(cols = c(Uncorrected, Corrected),
               names_to = "Group", values_to = "RSD")

# Compute medians for median lines
median_rsd <- plot_rsd_hist %>%
  group_by(Group) %>%
  summarise(Median_RSD = median(RSD, na.rm = TRUE)) %>%
  pivot_wider(names_from = Group, values_from = Median_RSD)

# ============================================================
# 2️⃣ Normality check (paired differences)
# ============================================================

diff_values <- plot_rsd_hist$RSD[plot_rsd_hist$Group == "Uncorrected"] -
               plot_rsd_hist$RSD[plot_rsd_hist$Group == "Corrected"]

shapiro_res <- shapiro.test(diff_values)

if (shapiro_res$p.value > 0.05) {
  test_res <- t.test(
    plot_rsd_hist$RSD[plot_rsd_hist$Group == "Uncorrected"],
    plot_rsd_hist$RSD[plot_rsd_hist$Group == "Corrected"],
    paired = TRUE, alternative = "greater"
  )
  test_type <- "Paired t-test"
} else {
  test_res <- wilcox.test(
    plot_rsd_hist$RSD[plot_rsd_hist$Group == "Uncorrected"],
    plot_rsd_hist$RSD[plot_rsd_hist$Group == "Corrected"],
    paired = TRUE, alternative = "greater"
  )
  test_type <- "p-value (Wilcoxon test)"
}

pval_text <- paste0(test_type, " p = ",
                    formatC(test_res$p.value, format = "e", digits = 1))

# ============================================================
# 3️⃣ Histogram (Panel A)
# ============================================================

val_histo <- ggplot(plot_rsd_hist, aes(x = RSD, fill = Group)) +
  geom_histogram(bins = 30, position = "identity", alpha = 0.5,
                 color = "black", linewidth = 0.3) +
  
  # Median lines
  geom_vline(xintercept = median_rsd$Uncorrected, linetype = "dashed",
             color = "#e31a1c", linewidth = 1) +
  geom_vline(xintercept = median_rsd$Corrected, linetype = "dashed",
             color = "#1f78b4", linewidth = 1) +

  # Median labels
  annotate("text", x = median_rsd$Uncorrected, y = Inf, vjust = 5, hjust = -0.2,
           label = paste0("Median RSD of uncorrected peak areas = ",
                          sprintf("%.1f", median_rsd$Uncorrected), "%"),
           color = "#e31a1c", size = 4, fontface = "bold") +
  annotate("text", x = median_rsd$Corrected, y = Inf, vjust = 3, hjust = -0.1,
           label = paste0("Median RSD of corrected peak areas = ",
                          sprintf("%.1f", median_rsd$Corrected), "%"),
           color = "#1f78b4", size = 4, fontface = "bold") +

  # p-value annotation
  annotate("text", x = Inf, y = Inf, hjust = 1, vjust = 7,
           label = pval_text, size = 4, fontface = "bold") +

  scale_fill_manual(values = c("Uncorrected" = "#e31a1c",
                               "Corrected"   = "#1f78b4")) +

  # Histogram axis ticks every 5%
  scale_x_continuous(
    breaks = seq(0, max(plot_rsd_hist$RSD, na.rm = TRUE), by = 10),
    expand = expansion(mult = c(0.02, 0.05))
  ) +

  labs(
    x = "Relative Standard Deviation (RSD %)",
    y = "Number of Features",
    fill = NULL
  )

# ============================================================
# 4️⃣ Compute RT + ΔRSD for chromatogram plot
# ============================================================

rsd_delta_rt <- validation_summary %>%
  select(Feature, Mean_RSD_val_uncorr, Mean_RSD_val_best) %>%
  dplyr::rename(
    Uncorrected = Mean_RSD_val_uncorr,
    Corrected   = Mean_RSD_val_best
  ) %>%
  mutate(Delta_RSD = Uncorrected - Corrected) %>%
  left_join(
    result_long %>%
      select(Feature, mean_rt) %>%
      group_by(Feature) %>%
      summarise(RT_min = mean(mean_rt, na.rm = TRUE)),
    by = "Feature"
  )

# ============================================================
# 5️⃣ User-defined cutoff
# ============================================================

# categorize improvement
rsd_delta_rt <- rsd_delta_rt %>%
  mutate(
    Category = case_when(
      Delta_RSD >=  RSD_CUTOFF ~ "Improved",
      Delta_RSD <= -RSD_CUTOFF ~ "Worsened",
      TRUE                     ~ "Less affected"
    )
  )

n_improved  <- sum(rsd_delta_rt$Category == "Improved")
n_worsened  <- sum(rsd_delta_rt$Category == "Worsened")

label_improved <- paste0("ΔRSD ≥ ", RSD_CUTOFF, "%  (n = ", n_improved, ")")
label_worsened <- paste0("ΔRSD ≤ -", RSD_CUTOFF, "%  (n = ", n_worsened, ")")

# ============================================================
# 6️⃣ RT chromatogram improvement plot (Panel B)
# ============================================================

min_rt <- floor(min(rsd_delta_rt$RT_min, na.rm = TRUE))
max_rt <- ceiling(max(rsd_delta_rt$RT_min, na.rm = TRUE))

rt_plot <- ggplot(rsd_delta_rt, aes(x = RT_min, y = Delta_RSD)) +

  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept =  RSD_CUTOFF, size = 1, linetype = "dotted", color = "#1f78b4") +
  geom_hline(yintercept = -RSD_CUTOFF, size = 1, linetype = "dotted", color = "#e31a1c") +

  geom_point(aes(color = Category), size = 2, alpha = 0.85) +
  scale_color_manual(
    values = c("Improved" = "#1f78b4",
               "Worsened" = "#e31a1c",
               "Less affected"  = "grey50")
  ) +

  # Labels on right side
  annotate("text",
           x = Inf, y = RSD_CUTOFF + 2,
           label = label_improved,
           hjust = 1.1, vjust = 0,
           size = 4.8, fontface = "bold", color = "#1f78b4") +

  annotate("text",
           x = Inf, y = -RSD_CUTOFF - 2,
           label = label_worsened,
           hjust = 1.1, vjust = 1,
           size = 4.8, fontface = "bold", color = "#e31a1c") +
  annotate("rect",
         xmin = 0.5, xmax = 1.1,
         ymin = -Inf, ymax = Inf,
         fill = NA, color = "grey40", linetype = "dashed", linewidth = 0.6) +
annotate("rect",
         xmin = 4.0, xmax = 5.5,
         ymin = -Inf, ymax = Inf,
         fill = NA, color = "grey40", linetype = "dashed", linewidth = 0.6) +
annotate("rect",
         xmin = 6.0, xmax = 7.5,
         ymin = -Inf, ymax = Inf,
         fill = NA, color = "grey40", linetype = "dashed", linewidth = 0.6) +

# box 1: 0.5–1.1
annotate("text",
         x = 1.1,           # xmax
         y = Inf,
         label = "1",
         hjust = 1.1,       # pull left slightly
         vjust = 1.5,       # pull down into the panel
         size = 5,
         color = "grey40",
         fontface = "bold") +

# box 2: 4.0–5.5
annotate("text",
         x = 5.5,           # xmax
         y = Inf,
         label = "2",
         hjust = 1.1,
         vjust = 1.5,
         size = 5,
         color = "grey40",
         fontface = "bold") +

# box 3: 6.0–7.0
annotate("text",
         x = 7.5,           # xmax
         y = Inf,
         label = "3",
         hjust = 1.1,
         vjust = 1.5,
         size = 5,
         color = "grey40",
         fontface = "bold") +
  # RT x-axis ticks every 1 min
  scale_x_continuous(
    breaks = seq(min_rt, max_rt, by = 1),
    expand = expansion(mult = c(0.02, 0.05))
  ) +

  labs(
    x = "Retention Time (min)",
    y = "ΔRSD (%)",
    color = "Outcome",
    #title = "Improvement Across the Chromatogram",
    #subtitle = paste0("ΔRSD = Uncorrected - Corrected   |   Cutoff = ±", RSD_CUTOFF, "%")
  )

# ============================================================
# 7️⃣ Unified theme (x/y labels NOT bold)
# ============================================================

aligned_theme <- theme_pubr(base_size = 14) +
  theme(
    axis.title.x = element_text(size = 13, margin = margin(t = 8)),
    axis.title.y = element_text(size = 13),
    axis.line = element_line(color = "black"),
    axis.ticks= element_line(color = "black"),
    panel.border = element_blank(),
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 13),
    legend.position = "right"
  )

val_histo <- val_histo + aligned_theme + labs(title = "A") +
  theme(
    plot.title.position = "plot",
    plot.title = element_text(
      hjust = 0,          # left-align
      vjust = 1,          # move up
      face = "bold",
      size = 14,
      margin = margin(b = 10)
    )
  )


rt_plot   <- rt_plot   + aligned_theme +  labs(title = "B") +
  theme(
    plot.title.position = "plot",
    plot.title = element_text(
      hjust = 0,          # left-align
      vjust = 1,          # move up
      face = "bold",
      size = 14,
      margin = margin(b = 10)
    )
  )



# ============================================================
# 8️⃣ Combine histogram + chromatogram plot
# ============================================================



combined_plot <- val_histo / rt_plot
combined_plot

region_counts <- tibble(
  Region = c("0.5–1.1 min", "4.0–5.5 min", "6.0–7.5 min"),
  Count_Improved = c(
    rsd_delta_rt %>% filter(RT_min >= 0.5, RT_min < 1.1, Category == "Improved") %>% nrow(),
    rsd_delta_rt %>% filter(RT_min >= 4.0, RT_min < 5.5, Category == "Improved") %>% nrow(),
    rsd_delta_rt %>% filter(RT_min >= 6.0, RT_min < 7.5, Category == "Worsened") %>% nrow()
  )
)

region_counts


```

### Article figure 13.

```{r}
#Save
output_dir <- here("Figures")

ggsave(
  file.path(output_dir, "Figure_13.png"),
  plot = combined_plot,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

ggsave(
  file.path(output_dir, "Figure_13.tiff"),
  plot = combined_plot,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)

```

## Extract tryptophan from training set

```{r}
feature <- "X00085" 

rsd_train.tryp <- split_df %>% 
  filter(Set == "Training") %>% 
  group_by(Feature, PCI, CorrectionType) %>%
  summarise(
    train_rsd = 100 * sd(CorrectedArea, na.rm = TRUE) / mean(CorrectedArea, na.rm = TRUE),
    mean_area = mean(CorrectedArea), sd_area = sd(CorrectedArea),
    .groups = "drop"
  ) %>%
  filter(Feature == feature) %>%
  filter(!(CorrectionType == "uncorrected") |
           (CorrectionType == "uncorrected" & PCI == "Tryptophan-d5"))

# ------------------------------
# Publication-ready plot
# ------------------------------

# Optional: nicer scientific color palette
pci_colors <- RColorBrewer::brewer.pal(max(3, length(unique(rsd_train.tryp$PCI))), "Set2")

plot.tryp.test.rsd <- ggplot(rsd_train.tryp, aes(x = PCI, y = train_rsd, fill = PCI)) +
  
  # Bars
  geom_col(width = 0.65, color = "black") +
  
  # RSD labels above bars
  geom_text(
    aes(label = sprintf("%.1f%%", train_rsd)),
    vjust = -0.6,
    size = 4,
    fontface = "bold"
  ) +
  
  # Facet by correction type
  facet_wrap(~ CorrectionType, nrow = 1, strip.position = "top") +
  
  # Cleaner labels
  labs(
    title = paste0("Training Set RSD for ", feature),
    x = NULL,
    y = "RSD (%)"
  ) +
  
  # Publication-ready theme
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
    axis.text.y = element_text(size = 12),
    axis.title.y = element_text(size = 13, face = "bold"),
    
    # Facet strip styling
    strip.text = element_text(size = 12, face = "bold"),
    strip.background = element_rect(fill = "grey90", color = NA),
    
    # Borders and gridlines
    panel.grid.major.x = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_line(color = "grey85", linewidth = 0.3),
    
    legend.position = "none",
    plot.margin = margin(10, 10, 10, 10)
  ) +
  
  scale_fill_manual(values = pci_colors) +
  
  # Add a little extra headroom for text labels
  expand_limits(y = max(rsd_train.tryp$train_rsd) * 1.15)

plot.tryp.test.rsd

```

# Supplementary Tables and Figures

## Table SI-1

```{r}
# Create table
si_table <- tribble(
  ~Formula,              ~`Compound name`,        ~Polarity, ~Adduct,       ~`Monoisotopic m/z (Da)`, ~`LogP (ChemAxon)`, ~`LogD (pH 5.5, ChemSpider)`, ~`Compound class`,            ~`Concentration (µM)`,
  "C8H6D6N",             "Indole-d6",              "+",       "[M+H]+",       124.1028,               2.07,              2.44,                         "Indole",                    8.0,
  "C6H3NO2D10",          "Leucine-d10",            "+",       "[M+H]+",       142.1647,              -1.6,             -1.86,                        "Aliphatic amino acid",      3.0,
  "C5H4NO4D5",           "Glutamic acid-d5",       "-",       "[M−H]−",       151.0773,              -3.2,             -4.77,                        "Acidic amino acid",        10.0,
  "C7H6NO3D9",           "Carnitine-d9",           "+",       "[M+H]+",       171.1690,              -4.9,             -3.61,                        "Carnitine",                0.09,
  "13C6H12O6",           "Glucose-13C6",           "+",       "[M+NH4]+",     204.1173,              -2.9,             -2.21,                        "Sugar",                   13.0,
  "C11H7N2O2D5",         "Tryptophan-d5",          "+",       "[M+H]+",       210.1285,              -1.1,             -1.06,                        "Aromatic amino acid",     10.0,
  "C18H1O2D35",          "Stearic acid-d35",       "+",       "[M+NH4]+",     337.5251,               7.15,             7.26,                         "Fatty acid",             200.0,
  "C24H36O5D4",          "Cholic acid-d4",         "-",       "[M−H]−",       411.3054,               2.48,             1.29,                         "Bile acid",                5.0
)

# Render table with caption
kable(
  si_table,
  format  = "html",
  caption = "Table SI-1. Overview of stable isotope-labelled standards used in the PCI experiments."
) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  )

```

## Table SI-2

```{r}
# Create table
si2_table <- tribble(
  ~`Processing step`,           ~Parameter,                                   ~Value,
  "Spectrum selection",         "Total intensity threshold",                  "500",
  "Spectrum selection",         "S/N threshold (FT)",                          "1.5",
  "Spectrum selection",         "MS order / polarity",                         "Any",
  
  "Feature detection",          "Mass tolerance",                              "3 ppm",
  "Feature detection",          "Minimum peak intensity",                     "2.5 × 10⁵",
  "Feature detection",          "Minimum scans per peak",                     "5",
  "Feature detection",          "Chromatographic S/N threshold",              "3",
  "Feature detection",          "Maximum peak width",                         "1 min",
  "Feature detection",          "Gap ratio threshold",                        "0.35",
  
  "Isotope handling",           "Elements considered",                        "Br, Cl",
  "Isotope handling",           "False-positive isotope removal",             "Enabled",
  
  "Ion/adduct assignment",      "Adducts considered",                         "[M+H]+, [M−H]−, [M+Na]+, [M+K]+, [M+NH4]+, [M+FA−H]−",
  "Ion/adduct assignment",      "Base ions",                                  "[M+H]+, [M−H]−",
  
  "Feature alignment",          "Mass tolerance",                              "3 ppm",
  "Feature alignment",          "RT tolerance",                                "0.25 min",
  "Feature alignment",          "Minimum valley",                              "10%",
  "Feature alignment",          "Area integration",                            "Most common ion",
  
  "Peak quality filtering",     "Peak rating threshold",                      "6.5",
  "Peak quality filtering",     "Minimum number of files",                    "3",
  
  "Gap filling",                "Mass tolerance",                              "5 ppm",
  "Gap filling",                "S/N threshold",                               "1.5",
  "Gap filling",                "Minimum scans per peak",                     "3",
  
  "Background filtering",       "Max sample/blank ratio",                     "6",
  
  "Compound annotation",        "Annotation sources",                         "mzVault, mzCloud, ChemSpider (HMDB), predicted compositions",
  "Compound annotation",        "Mass tolerance",                              "3 ppm",
  
  "Spectral library search",    "mzVault match factor threshold",              "60",
  "Spectral library search",    "mzVault RT tolerance",                        "0.2 min",
  "Spectral library search",    "mzCloud precursor tolerance",                "10 ppm",
  "Spectral library search",    "mzCloud fragment tolerance (FT)",             "10 ppm",
  
  "Elemental composition",      "Mass tolerance",                              "4 ppm",
  "Elemental composition",      "Allowed elements",                            "C, H, N, O, S, P, Br, Cl",
  "Elemental composition",      "Minimum isotope pattern coverage",            "90%"
)

# Render table
kable(
  si2_table,
  format  = "html",
  caption = "Table SI-2. Data-processing parameters used for feature detection, alignment, gap filling, and compound annotation in LC–HRMS data analysis (Thermo Compound Discoverer)."
) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  )

```

## Table SI-3

manually made

```{r}

# Create table
literature_table <- tribble(
  ~Article,                                   ~`Column flowrate (mL/min)`, ~`PCI flowrate (mL/min)`, ~`PCI/Column (%)`, ~Compound,                                                                                         ~`Concentration (µg/mL)`,
  "(Bodnar-Broniarczyk et al., 2019)",         0.75,                        0.5,                      67,                "Tacrolimus",                                                                                      "0.1",
  "(González et al., 2022)",                   0.4,                         0.01,                     3,                 "Atenolol, caffeine, diclofenac, lacidipine, metformin, nifedipine, simvastatin",                     "0.025 – 0.125",
  "(Kamiguchi et al., 2016)",                  0.2,                         0.01,                     5,                 "Hippuric acid and phenylacetylglycine",                                                             "1",
  "(Stahnke et al., 2009)",                    0.2,                         0.02,                     10,                "140 pesticide standard substances",                                                                 "1",
  "(Rossmann et al., 2015)",                   0.4,                         0.1,                      25,                "Pharmaceutical standards",                                                                           "1",
  "(Tisler et al., 2021)",                     0.3,                         0.05,                     17,                "67 compounds: wastewater-relevant pharmaceuticals, pesticides, fungicides, industrial chemicals",    "0.2"
)

# Render table with caption
kable(
  literature_table,
  format = "html",
  caption = "Table SI-3. Overview of different flowrates, analytes and analyte concentrations used for PCI experiments in literature."
) %>%
  kable_styling(full_width = FALSE)

```

## Table SI-4

```{r}
#---------------------------------------------
# 1. Filter and recode wash labels
#---------------------------------------------
wash_subset <- summarized_data %>%
  filter(homologue_id %in% c(1,16,17,18,19),
         Sequence <= 45,
         Wash %in% c("NoWash", "22x", "08x", "04x")) %>%
  mutate(
    Wash = recode(Wash,
                  "22x"    = "PLR 22x Wash",
                  "08x"    = "PLR 8x Wash",
                  "04x"    = "PLR 4x Wash",
                  "NoWash" = "PLR Unwashed"),
    Wash = factor(Wash,
                  levels = c("PLR Unwashed", "PLR 4x Wash",
                             "PLR 8x Wash", "PLR 22x Wash")),
    
    # ⭐ New readable facet labels
    homologue_id = factor(homologue_id,
                          levels = c(1,16,17,18,19),
                          labels = c("1",
                                     "16",
                                     "17",
                                     "18",
                                     "19"))
  )

#---------------------------------------------
# Mean summary table
#---------------------------------------------
wash_means_pub <- wash_subset %>%
  group_by(homologue_id, Wash) %>%
  summarise(
    n    = n(),
    Mean = round(mean(Intensity, na.rm = TRUE), 0),   # no decimals
    SD   = round(sd(Intensity, na.rm = TRUE), 0),     # no decimals
    .groups = "drop"
  ) %>%
  arrange(homologue_id, Wash)

kable(
  wash_means_pub,
  caption = "Table SI-4. Contaminant intensity across PLR wash conditions. Values shown as mean and standard deviation for each homologue series ID.",
  col.names = c("Homologue ID", "Wash Condition", "Sample Count (n)", "Mean Intensity", "SD Intensity"),
  align = "c",
  booktabs = TRUE,
  format = "html"   # ensures nice formatting when copied to Word
) %>%
  kable_styling(
    full_width = FALSE,
    position = "center",
    bootstrap_options = c("striped", "hover", "condensed")
  ) %>%
  row_spec(0, bold = TRUE) %>%                 # bold header
  collapse_rows(columns = 1, valign = "middle")  # group homologues


```

## Figure SI-1

### Data and Plot: Leucine-d10 EIC with replicatets of solvent blank 3- 6 mins

```{r}
solvent_leucine <- long_data %>% 
  filter(
    Compound == "Leucine-d10",
    Wash == "NoWash",
    Sample == "Solvent",
    between(Times, 3, 6),
    Replicate %in% 1:8
  ) %>%
  ggplot(aes(x = Times, y = Average, color = as.factor(Replicate))) +
  
  geom_line(size = 0.8) +
  
  facet_wrap(~ Replicate, ncol = 8, labeller = label_both) +
  
  scale_y_continuous(labels = scientific) +
  
  labs(
    #title = "Leucine-d10 EIC across replicates of solvent blank (3–6 min)",
    x = "Time (min)",
    y = "Intensity",
    color = "Replicate"
  ) +
    theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    strip.text = element_text(size = 12),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
  )

print(solvent_leucine)

# Save
#---------------------------------------------
output_dir <- here("Figures")

ggsave(
  filename = file.path(output_dir, "Figure_SI-1 Article.png"),
  plot = solvent_leucine,
  width = 20, height = 20, units = "cm", dpi = 600
)

ggsave(
  filename = file.path(output_dir, "Figure_SI-1 Article.tiff"),
  plot = solvent_leucine,
  width = 20, height = 20, units = "cm",
  dpi = 600, device = "tiff", compression = "lzw"
)

```

## Figure SI-2: MS of contamiants as image

```{r}
## Screenshot from FreeStyle
```

## Figure SI-3:

### Data: Extracting background contaminates from each files

```{r}

# # Define target masses
# #annotate_masses2 <- c(654.9935, 653.9914, 652.9877, 651.9808, 650.9743, 649.9660, 648.9597, 647.9515)
# annotate_masses3 <- annotated_peaks$mz
# 
# # ppm tolerance
# ppm <- 2
# 
# # Define all mzML files
# mzml_files <- list.files("C:/Users/DanielMalheiro/Downloads/Exp7-241008/mzML-PAN", pattern = "*.mzML", full.names = TRUE)
# 
# # Function to extract EIC from raw file for one mass
# extract_mass_eic <- function(file_path, target_mz, ppm, file_id) {
#   raw_data <- xcmsRaw(file_path)
# 
#   # Calculate mz range
#   mz_tol <- (ppm / 1e6) * target_mz
#   mz_range <- c(target_mz - mz_tol, target_mz + mz_tol)
# 
#   # Get positive mode scans
#   positive_scans <- which(raw_data@polarity == "positive")
# 
#   if (length(positive_scans) > 0) {
#     eic <- rawEIC(raw_data, mzrange = mz_range)
# 
#     df <- data.frame(
#       scan = seq_along(positive_scans),
#       rt = raw_data@scantime[positive_scans] / 60,
#       intensity = eic$intensity[positive_scans],
#       mass = target_mz,
#       file = basename(file_path)
#     ) %>%
#       mutate(average_intensity = rollmean(intensity, k = 9, fill = NA, align = "left"))
# 
#     return(df)
#   } else {
#     return(NULL)
#   }
# }
# 
# # Loop through files and masses
# all_eics <- list()
# 
# for (file in mzml_files) {
#   message("Processing: ", basename(file))
#   for (mass in annotate_masses3) {
#     eic_data <- extract_mass_eic(file, mass, ppm, basename(file))
#     if (!is.null(eic_data)) {
#       all_eics[[length(all_eics) + 1]] <- eic_data
#     }
#   }
# }
# 
# # Combine all into one dataframe
# eic_df <- bind_rows(all_eics)

#saveRDS(eic_df, file = "eic_df_newions.rds")
largelist_contaminants <- readRDS("eic_df_newions.rds")

summed_signals <- largelist_contaminants %>%
  group_by(file, rt) %>%
  summarise(total_intensity = sum(average_intensity, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    file_base = str_remove(file, "\\.mzML$"),
    Sequence  = as.numeric(str_split(file_base, "-", simplify = TRUE)[,5]),
    Wash      = str_split(file_base, "-", simplify = TRUE)[,6],
    Sample    = str_split(file_base, "-", simplify = TRUE)[,7]
  ) %>%
  arrange(Sample, Wash) %>%
  group_by(Sample, Wash) %>%
  mutate(Replicate = dense_rank(Sequence),
         Replicate = as.factor(Replicate)) %>%
  ungroup() %>%
  group_by(file) %>%
  arrange(rt, .by_group = TRUE) %>%
  mutate(scan = row_number()) %>%
  ungroup()



# Set the Wash factor with desired order
summed_signals$Wash <- factor(summed_signals$Wash, levels = c("22x", "08x", "04x", "NoWash", "PPT"))

# Prepare the combined facet label
summed_signals <- summed_signals %>%
  mutate(Facet_Label = paste0(Sequence, " | ", Wash, " | ", Sample))

# Plot
allinter <- summed_signals %>%
  filter(
    rt >= 0 & rt <= 10, # previously 0 to 10
    !is.na(Wash),
    Sequence %in% 8:45
  ) %>%
  ggplot(aes(x = rt, y = total_intensity, color = as.factor(Sequence), group = Replicate)) +
  geom_line(size = 0.8, alpha = 0.8) +
  facet_wrap(~ Facet_Label, ncol = 6) +
  scale_x_continuous(
  breaks = seq(0, 10, by = 2.5),
  labels = c("0", "", "5", "", "10")
) + 
  labs(
    #title = "Summed EICs for All Target Masses",
    x = "Retention Time (min)",
    y = "Summed Intensity of Interfering Ions",
    color = "Sequence | Wash | Sample"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    strip.text = element_text(size = 9, face = "bold"),  # smaller strip text for space
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(face = "bold")
  )

# Print the plot
print(allinter)

#---------------------------------------------
# Save
#---------------------------------------------

output_dir <- here("Figures")

ggsave(
  filename = file.path(output_dir, "Figure_SI-3 Article.png"),
  plot = allinter,
  width = 20, height = 20, units = "cm", dpi = 600
)

ggsave(
  filename = file.path(output_dir, "Figure_SI-3 Article.tiff"),
  plot = allinter,
  width = 20, height = 20, units = "cm",
  dpi = 600, device = "tiff", compression = "lzw"
)



```

## Figure SI-4. Effect of PLR wash intensity on contaminant signals

```{r}

#---------------------------------------------
# 1. Filter and recode wash labels
#---------------------------------------------
wash_subset <- summarized_data %>%
  filter(homologue_id %in% c(1,16,17,18,19),
         Sequence <= 45,
         Wash %in% c("NoWash", "22x", "08x", "04x")) %>%
  mutate(
    Wash = recode(Wash,
                  "22x"    = "PLR 22x Wash",
                  "08x"    = "PLR 8x Wash",
                  "04x"    = "PLR 4x Wash",
                  "NoWash" = "PLR Unwashed"),
    Wash = factor(Wash,
                  levels = c("PLR Unwashed", "PLR 4x Wash",
                             "PLR 8x Wash", "PLR 22x Wash")),
    
    # ⭐ New readable facet labels
    homologue_id = factor(homologue_id,
                          levels = c(1,16,17,18,19),
                          labels = c("Homologue ID 1",
                                     "Homologue ID 16",
                                     "Homologue ID 17",
                                     "Homologue ID 18",
                                     "Homologue ID 19"))
  )

#---------------------------------------------
# 2. Pairwise testing
#---------------------------------------------
#---------------------------------------------
stat_test_raw <- wash_subset %>%
  group_by(homologue_id) %>%
  pairwise_t_test(
    Intensity ~ Wash,
    p.adjust.method = "BH"
  )

# Keep only significant comparisons
stat_sig <- stat_test_raw %>%
  filter(p.adj.signif != "ns")

#---------------------------------------------
# 2. Compute per-facet max Y + padding for bracket placement
#---------------------------------------------
#---------------------------------------------
# 2. Pairwise testing
#---------------------------------------------
stat_test_raw <- wash_subset %>%
  group_by(homologue_id) %>%
  pairwise_t_test(
    Intensity ~ Wash,
    p.adjust.method = "BH"
  )

# Keep only significant comparisons
stat_sig <- stat_test_raw #%>%
  #filter(p.adj.signif != "ns")

#---------------------------------------------
# 3. Compute per-facet max and spacing
#---------------------------------------------
y_max <- wash_subset %>%
  group_by(homologue_id) %>%
  summarise(max_y = max(Intensity, na.rm = TRUE))

# Add spacing: 20% above max for first bracket, 
# then +10% for each additional bracket in same panel
stat_sig <- stat_sig %>%
  left_join(y_max, by = "homologue_id") %>%
  group_by(homologue_id) %>%
  mutate(
    bracket_index = row_number(),              # 1st, 2nd, 3rd bracket, etc.
    y.position = max_y * (1.20 + 0.12*(bracket_index - 1))  # ⭐ spacing
  ) %>%
  ungroup()

#---------------------------------------------
# 3. Boxplot  + correct bracket positions
#---------------------------------------------
box_sig_plot <- wash_subset %>%
  ggplot(aes(x = Wash, y = Intensity, fill = Wash)) +
  
  geom_boxplot(outlier.alpha = 0.25, linewidth = 0.5) +
  facet_wrap(~ homologue_id, scales = "free_y", ncol = 3) +

  scale_fill_manual(values = c(
    "PLR Unwashed" = "grey40",
    "PLR 4x Wash"  = "#e31a1c",
    "PLR 8x Wash"  = "#33a02c",
    "PLR 22x Wash" = "#1f78b4"
  )) +

    stat_pvalue_manual(
    stat_sig,
    label = "p.adj.signif",
    size = 3,
    tip.length = 0.01
  ) +

  labs(
    x = "Wash Condition",
    y = "Summed Intensity"
  ) +

  theme_bw(base_size = 14) +
  theme(
    strip.text  = element_text(size = 12, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

box_sig_plot
#---------------------------------------------
# Save
#---------------------------------------------
output_dir <- here("Figures")

ggsave(
  filename = file.path(output_dir, "Figure_SI-4 Article.png"),
  plot = box_sig_plot,
  width = 20, height = 20, units = "cm", dpi = 600
)

ggsave(
  filename = file.path(output_dir, "Figure_SI-4 Article.tiff"),
  plot = box_sig_plot,
  width = 20, height = 20, units = "cm",
  dpi = 600, device = "tiff", compression = "lzw"
)


```

## Figure SI-5. Over laps of contaminant ions and ME

```{r}
# Define plot range and lines
zoomlimits22only <- c(3, 6)
vline_positions22only <- c(4.375, 4.835)

# ---- PLOT A: Zoomed-In Matrix Effect for 22x ----
plot_matrix_effect_zoom_22xonly <- summary_table_2 %>%
  filter(
    Comparison == "NIST / Solvent",
    Wash == "22x wash PLR",
    between(avg_time, zoomlimits22only[1], zoomlimits22only[2])
  ) %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean)) +
  geom_ribbon(
    aes(ymin = ME_NS_lower, ymax = ME_NS_upper),
    fill = "red", alpha = 0.2
  ) +
  geom_line(color = "red", size = 0.8) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.7) +
  geom_vline(xintercept = vline_positions22only, linetype = "dotted", color = "black", size = 0.8) +
  coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  scale_x_continuous(
    breaks = seq(3, 6, by = 1),
      ) +
  labs(
    #title = "Matrix Effect (NIST / Solvent) – 22x only",
    x = NULL,
    y = "Matrix Effect (%)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black")
  )

# ---- PLOT B: Interfering Ions (Summed Trace) for NIST-22x ----
average_nist_22x <- summed_signals %>%
  filter(
    Sequence %in% 8:45,
    Sample == "NIST", Wash == "22x",
    between(rt, zoomlimits22only[1], zoomlimits22only[2]),
    Replicate == 1
  ) %>%
  group_by(scan) %>%
  summarise(
    total_intensity = sum(total_intensity, na.rm = TRUE),
    rt = mean(rt),
    .groups = "drop"
  ) %>%
  mutate(
    rolling_intensity = rollmean(total_intensity, k = 9, fill = NA, align = "right")
  )

nist_22x_rep <- ggplot(average_nist_22x, aes(x = rt)) +
  geom_line(aes(y = rolling_intensity), color = "blue", size = 0.8) +
  geom_vline(xintercept = vline_positions22only, linetype = "dotted", color = "black", size = 0.8) +
  scale_y_continuous(labels = scales::scientific) +
  scale_x_continuous(
    breaks = seq(3, 6, by = 1),
      ) +
  labs(
    #title = "Summed Interfering Ion Signal",
    x = "Retention Time (min)",
    y = "Summed Intensity"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black")
  )

# ---- Combine A + B Vertically ----
pub_ready_plot <- plot_matrix_effect_zoom_22xonly / nist_22x_rep

# ---- Display ----
print(pub_ready_plot)

# Save
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_SI-5 Article.png"),
  plot = pub_ready_plot,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_SI-5 Article.tiff"),
  plot = pub_ready_plot,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)

```

## Figure SI-6: Injecion time plot

### 2data

```{r}
#Change dir
filepath <- "C:/Users/DanielMalheiro/Downloads/Exp7-241008/mzML-PAN"
setwd(filepath)
getwd()
list.files()

# Load the mzML file
file_path <- "241008-Exp-PAN-1-035-NoWash-NIST.mzML"
raw_data <- xcmsRaw(file_path)
raw_data <- readMSData(file_path, mode = "onDisk")

# Extract full scan-level metadata
scan_info <- fData(raw_data)

# Inspect available metadata columns (optional)
colnames(scan_info)

# Filter for positive polarity scans
# Polarity values: 1 = positive, 0 = negative
positive_scans <- scan_info %>%
  filter(polarity == 1)

# Extract retention time (convert to minutes) and injection time
scan_df <- data.frame(
  retention_time = positive_scans$retentionTime / 60,
  injection_time = positive_scans$injectionTime
)
```

### plot

```{r}
# Define zoom range and vertical line positions
zoom_limits <- c(0, 3)   # Zoomed-in range
vline_positions <- rt_df$RT_min  # Vertical line positions

# Create the injection time plot with formatting for publication
Ioninjection_plot <- scan_df %>%
  filter(between(retention_time, zoom_limits[1], zoom_limits[2])) %>%
  ggplot(aes(x = retention_time, y = injection_time)) +
  geom_vline(xintercept = vline_positions, linetype = "dotted", color = "black") +  # Add vertical lines
  geom_line(color = "darkgreen", size = 0.75) +
    geom_text(data = rt_df,
            aes(x = RT_min, y = 5, label = scan_label),
            inherit.aes = FALSE,
            angle = 90, vjust = -1, size = 4) +
  geom_line(size = 0.75, alpha = 0.6) +
  labs(
    #title = "Injection Time vs Retention Time (Positive Polarity)",
    x = "Retention Time (min)",
    y = "Injection Time (ms)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    axis.title.x = element_text(),
    axis.title.y = element_text()
  )

# Print the plot
print(Ioninjection_plot)

# Save
output_dir <- here("Figures")


# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_SI-6 Article.png"),
  plot = Ioninjection_plot,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_SI-6 Article.tiff"),
  plot = Ioninjection_plot,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
```

## Figure SI-7. EIC of Acetyl-Carnitine and Glucose-13C6

### Data and Plot:

```{r}
filepath <- "C:/Users/DanielMalheiro/Downloads/Exp7-241008/mzML-PAN"
setwd(filepath)
getwd()
list.files()

# Load the mzML file
file_nowash <- "241008-Exp-PAN-1-035-NoWash-NIST.mzML"

if (!exists("raw_data_glu")) {
  raw_data_glu <- xcmsRaw(file_nowash)
} else {
  message("'raw_data_glu' already exists in the environment.")
}

ppm <- 2

# Define function to extract EIC for a target m/z
extract_eic <- function(raw_data, target_mz, ppm, polarity_label = "positive") {
  mz_tol <- (ppm / 1e6) * target_mz
  mz_range <- c(target_mz - mz_tol, target_mz + mz_tol)

  positive_scans <- which(raw_data@polarity == polarity_label)  # 1 = positive

  eic <- rawEIC(raw_data, mzrange = mz_range)

  eic_df <- data.frame(
    rt = raw_data@scantime[positive_scans] / 60,  # Convert to minutes
    intensity = eic$intensity[positive_scans],
    scan = seq_along(positive_scans),
    target = paste0("m/z ", round(target_mz, 4))
  ) %>%
    mutate(average_intensity = rollmean(intensity, k = 3, fill = NA, align = "left"))

  return(eic_df)
}

# Create mapping from m/z to metabolite name
target_labels <- c(
  `204.1173` = "Glucose-13C6",
  `204.1230` = "Acetyl-carnitine"
)

target_labels_plot <- c(
  `204.1173` = "Glucose-{}^{13}*C[6]",
  `204.1230` = "Acetyl-carnitine"
)

eic_df_1 <- extract_eic(raw_data_glu, 204.1173, ppm) %>%
  mutate(
    target = target_labels["204.1173"],
    target_plot = target_labels_plot["204.1173"]
  )

eic_df_2 <- extract_eic(raw_data_glu, 204.1230, ppm) %>%
  mutate(
    target = target_labels["204.1230"],
    target_plot = target_labels_plot["204.1230"]
  )

combined_eic_df <- bind_rows(eic_df_1, eic_df_2)

combined_eic_df_scaled <- combined_eic_df %>%
  group_by(target, target_plot) %>%
  mutate(scaled_intensity = average_intensity / max(average_intensity, na.rm = TRUE)) %>%
  ungroup()

chromatogram_overlay_scaled <- combined_eic_df_scaled %>%
  filter(between(rt, 0, 5)) %>%
  ggplot(aes(x = rt, y = scaled_intensity, color = target_plot)) +
  geom_line(linewidth = 0.8) +
  labs(
    x = "Retention Time (min)",
    y = "Normalized Intensity",
    color = "Compound"
  ) +
  scale_color_discrete(labels = scales::label_parse()) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "right",
    #legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 11),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    #axis.title = element_text(face = "bold"),
    plot.title = element_text(hjust = 0.5)
  )

print(chromatogram_overlay_scaled)

# Save
output_dir <- here("Figures")


ggsave(
  filename = file.path(output_dir, "Figure_SI-7 Article.png"),
  plot = chromatogram_overlay_scaled,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600
)

ggsave(
  filename = file.path(output_dir, "Figure_SI-7 Article.tiff"),
  plot = chromatogram_overlay_scaled,
  width = 20,
  height = 10,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)

```

## Figure SI-8. Improved and Worsened Features

```{r}
# ============================================================
# 1️⃣ Prepare data for arrow plots
# ============================================================

rsd_rt_arrow <- validation_summary %>%
  select(Feature, Mean_RSD_val_uncorr, Mean_RSD_val_best) %>%
  dplyr::rename(
    Uncorrected = Mean_RSD_val_uncorr,
    Corrected   = Mean_RSD_val_best
  ) %>%
  mutate(
    Delta_RSD = Corrected - Uncorrected,
    Change_Class = case_when(
      Delta_RSD <= -5 ~ "Improved",
      Delta_RSD >= +5 ~ "Worsened",
      TRUE            ~ "Less affected"
    )
  ) %>%
  left_join(
    result_long %>%
      group_by(Feature) %>%
      summarise(RT_min = mean(mean_rt, na.rm = TRUE)),
    by = "Feature"
  )

# Separate improved and worsened
df_improved  <- rsd_rt_arrow %>% filter(Change_Class == "Improved")
df_worsened  <- rsd_rt_arrow %>% filter(Change_Class == "Worsened")

# RT axis limits
min_rt <- floor(min(rsd_rt_arrow$RT_min, na.rm = TRUE))
max_rt <- ceiling(max(rsd_rt_arrow$RT_min, na.rm = TRUE))

# ============================================================
# 2️⃣ Compute MEANS per group (SEPARATELY)
# ============================================================

# Improved means
imp_mu_uncorr <- mean(df_improved$Uncorrected, na.rm = TRUE)
imp_mu_corr   <- mean(df_improved$Corrected,   na.rm = TRUE)

# Worsened means
wrs_mu_uncorr <- mean(df_worsened$Uncorrected, na.rm = TRUE)
wrs_mu_corr   <- mean(df_worsened$Corrected,   na.rm = TRUE)

# ============================================================
# 3️⃣ Shared theme
# ============================================================

aligned_theme <- theme_pubr(base_size = 14) +
  theme(
    axis.title.x = element_text(size = 13),
    axis.title.y = element_text(size = 13),
    axis.line    = element_line(color = "black"),
    axis.ticks   = element_line(color = "black"),
    panel.border = element_blank(),
    plot.title   = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13)
  )

# ============================================================
# 4️⃣ Plot A — Improved Only
# ============================================================

plot_improved <- ggplot(df_improved) +

  geom_segment(
    aes(x = RT_min, xend = RT_min, y = Uncorrected, yend = Corrected),
    color = "grey40", linewidth = 1, alpha = 0.9,
    arrow = arrow(length = unit(0.3, "cm"), type = "closed")
  ) +

  geom_point(aes(x = RT_min, y = Uncorrected), color = "#e31a1c", size = 2) +
  geom_point(aes(x = RT_min, y = Corrected),   color = "#1f78b4", size = 2) +

  # ⭐ IMPROVED mean lines
  geom_hline(yintercept = imp_mu_uncorr, color = "#e31a1c", linetype = "dashed", linewidth = 0.8) +
  geom_hline(yintercept = imp_mu_corr,   color = "#1f78b4", linetype = "dashed", linewidth = 0.8) +

  # Labels
  annotate("text", x = max_rt, y = imp_mu_uncorr,
           label = paste0("Mean Uncorrected = ", round(imp_mu_uncorr, 1), "%"),
           hjust = 1.1, vjust = -0.3, color = "#e31a1c", fontface = "bold", size = 4) +
  annotate("text", x = max_rt, y = imp_mu_corr,
           label = paste0("Mean Corrected = ", round(imp_mu_corr, 1), "%"),
           hjust = 1.1, vjust = -0.3, color = "#1f78b4", fontface = "bold", size = 4) +

  scale_x_continuous(
    breaks = seq(min_rt, max_rt, by = 1),
    expand = expansion(mult = c(0.02, 0.05))
  ) +

  labs(
    x = "Retention Time (min)",
    y = "RSD (%)",
    title = "A"
  ) +
  aligned_theme +
  theme(
    plot.title.position = "plot",
    plot.title = element_text(hjust = 0, vjust = 1,
                              face = "bold", size = 16,
                              margin = margin(b = 10))
  )

# ============================================================
# 5️⃣ Plot B — Worsened Only
# ============================================================

plot_worsened <- ggplot(df_worsened) +

  geom_segment(
    aes(x = RT_min, xend = RT_min, y = Uncorrected, yend = Corrected),
    color = "grey40", linewidth = 1, alpha = 0.9,
    arrow = arrow(length = unit(0.3, "cm"), type = "closed")
  ) +
  geom_point(aes(x = RT_min, y = Uncorrected), color = "#e31a1c", size = 2) +
  geom_point(aes(x = RT_min, y = Corrected),   color = "#1f78b4", size = 2) +

  # ⭐ WORSENED mean lines
  geom_hline(yintercept = wrs_mu_uncorr, color = "#e31a1c", linetype = "dashed", linewidth = 0.8) +
  geom_hline(yintercept = wrs_mu_corr,   color = "#1f78b4", linetype = "dashed", linewidth = 0.8) +

  annotate("text", x = max_rt, y = wrs_mu_uncorr,
           label = paste0("Mean Uncorrected = ", round(wrs_mu_uncorr, 1), "%"),
           hjust = 1.1, vjust = -0.3, color = "#e31a1c", fontface = "bold", size = 4) +
  annotate("text", x = max_rt, y = wrs_mu_corr,
           label = paste0("Mean Corrected = ", round(wrs_mu_corr, 1), "%"),
           hjust = 1.1, vjust = -0.3, color = "#1f78b4", fontface = "bold", size = 4) +

  scale_x_continuous(
    breaks = seq(min_rt, max_rt, by = 1),
    expand = expansion(mult = c(0.02, 0.05))
  ) +

  labs(
    x = "Retention Time (min)",
    y = "RSD (%)",
    title = "B"
  ) +
  aligned_theme +
  theme(
    plot.title.position = "plot",
    plot.title = element_text(hjust = 0, vjust = 1,
                              face = "bold", size = 16,
                              margin = margin(b = 10))
  )

# ============================================================
# 6️⃣ Combine and plot
# ============================================================

plot_all <- plot_improved / plot_worsened
plot_all

filepath <- "C:/Users/DanielMalheiro/OneDrive - Clinical Microbiomics/Documents/R scripts"

# Create subfolder "PCI ME Figures" inside it
output_dir <- file.path(filepath, "PCI ME Figures")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_SI-8. Article.png"),
  plot = plot_all,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_SI-8. Article.tiff"),
  plot = plot_all,
  width = 20,
  height = 15,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)


```

## Figure SI-9. Plotting individual Worsened Features

```{r}
uncorrected_clean <- uncorrected_df %>%
  filter(CorrectionType == "uncorrected") %>%
  dplyr::rename(UncorrectedArea = CorrectedArea)

val_best2 <- val_best %>%
  left_join(
    uncorrected_clean %>% 
      select(Treatment, Replicate, Feature, PCI, UncorrectedArea),
    by = c("Treatment", "Replicate", "Feature", "PCI")
  )

val_best_worsened <- val_best2 %>%
  filter(Feature %in% df_worsened$Feature) %>%
  left_join(
    df_worsened %>% select(Feature, RT_min),
    by = "Feature"
  )

facet_levels <- val_best_worsened %>%
  distinct(Feature, RT_min, PCI, CorrectionType) %>%   # unique combos
  mutate(
    Correction_clean = str_remove(CorrectionType, "^corrected_")   # remove corrected_
  ) %>%
  arrange(RT_min, Feature) %>%
  mutate(
    Feature_RT = paste0(
      Feature, " (", round(RT_min, 2), " min)\n",
      "PCI: ", PCI, "\n",
      "Correction: ", Correction_clean
    )
  ) %>%
  pull(Feature_RT)



plot_df <- val_best_worsened %>%
  pivot_longer(
    cols = c(CorrectedArea, UncorrectedArea),
    names_to = "Signal",
    values_to = "Area"
  ) %>%
  mutate(
    # Pretty signal labels for the legend
    Signal = recode(Signal,
                    "CorrectedArea"   = "Corrected Area",
                    "UncorrectedArea" = "Uncorrected Area"),
    
    # Clean correction type
    Correction_clean = str_remove(CorrectionType, "^corrected_"),
    
    # Full facet label
    Feature_RT = paste0(
      Feature, " (", round(RT_min, 2), " min)\n",
      "PCI: ", PCI, "\n",
      "Correction: ", Correction_clean
    ),
    
    # Safe factor reordering
    Feature_RT = factor(Feature_RT, levels = facet_levels)
  )



WC_plot <- ggplot(plot_df,
       aes(x = Treatment,
           y = Area,
           color = Signal,
           group = Signal)) +
  geom_point(size = 2, alpha = 0.85) +
  geom_line(alpha = 0.7) +
  scale_color_manual(values = c(
    "Corrected Area" = "#1f78b4",
    "Uncorrected Area" = "#e31a1c"
  )) +
  
 # ⭐ Force ALL facets and ALL values to 2 significant digits
  scale_y_continuous(
    labels = function(x) format(signif(x, 2), scientific = T)
  ) +
  
  facet_wrap(~ Feature_RT, scales = "free_y", ncol = 3) +
  theme_bw(base_size = 12) +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )

WC_plot

# Save
output_dir <- here("Figures")

# Save PNG
ggsave(
  filename = file.path(output_dir, "Figure_SI-9. Article.png"),
  plot = WC_plot,
  width = 20,
  height = 25,
  units = "cm",
  dpi = 600
)

# Save TIFF
ggsave(
  filename = file.path(output_dir, "Figure_SI-9. Article.tiff"),
  plot = WC_plot,
  width = 20,
  height = 25,
  units = "cm",
  dpi = 600,
  device = "tiff",
  compression = "lzw"
)
  
```

```{r}
write_files_to_excel <- function(files, sheet_names = NULL, out_file = "combined_output.xlsx") {
  
  # If sheet names not provided, use file names without extension
  if (is.null(sheet_names)) {
    sheet_names <- tools::file_path_sans_ext(basename(files))
  }
  
  # Check sheet names length
  if (length(sheet_names) != length(files)) {
    stop("sheet_names must be the same length as files.")
  }
  
  df_list <- list()
  
  for (i in seq_along(files)) {
    file <- files[i]
    ext <- tools::file_ext(file)
    
    # Detect Excel files
    if (ext %in% c("xlsx", "xls")) {
      
      # Special rule:
      if (basename(file) == "LC_Final results_ver12-Exp7-PCI.xlsx") {
        df <- read_excel(file, sheet = "Meta")
      } else {
        df <- read_excel(file)
      }
      
    } else if (ext == "tsv") {
      df <- read.delim(file)
    } else if (ext == "csv") {
      df <- read.csv(file)
    } else {
      stop(paste("Unsupported file type:", ext))
    }
    
    df_list[[sheet_names[i]]] <- df
  }
  
  write_xlsx(df_list, out_file)
  message("Excel file written: ", out_file)
}

setwd("C:/Users/DanielMalheiro/OneDrive - Clinical Microbiomics/Documents/R scripts")

files <- c(
  "merged_class_df.xlsx",
  "LC_Final results_ver12-Exp7-PCI.xlsx",
  "PCI-peaksforR.xlsx"
  )

# Optional custom sheet names
sheet_names <- c("MetaResults", "Peaks","Homologue Series")

write_files_to_excel(files, sheet_names, out_file = "Supplimentary Information_Excel_Files.xlsx")

```

## Graphical Abstract

### Blank Selection

```{r}

library(dplyr)
library(ggplot2)
library(patchwork)

# -------------------------------
# ---- PLOT B: Zoomed-In ME -----
# -------------------------------

# ---- FIRST PLOT (RED) ----
Blank.selection.1 <- summary_table_1 %>%
  filter(Comparison == "NIST / Solvent",
         Wash == "Unwashed PLR",
         between(avg_time, 0, 10)
  ) %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean)) +
  geom_line(size = 0.8, color = "#C03830") +   # RED LINE
  facet_wrap(~ Wash) +
  coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  labs(x = NULL, y = "Matrix Effect (%)") +
  theme_void(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    axis.title.x = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_blank(),      # remove axis lines
    axis.ticks = element_blank(),     # remove ticks
    axis.text = element_blank()       # remove axis text
  )


# ---- SECOND PLOT (GREEN) ----
Blank.selection.2 <- summary_table_2 %>%
  filter(Comparison == "NIST / Solvent",
         Wash == "Unwashed PLR",
         between(avg_time, 0, 10)
  ) %>%
  ggplot(aes(x = avg_time, y = ME_NS_mean)) +
  geom_line(size = 0.8, color = "#5AAA46") +   # GREEN LINE
  facet_wrap(~ Wash) +
  coord_cartesian(ylim = c(global_min_y, global_max_y)) +
  labs(x = NULL, y = "Matrix Effect (%)") +
  theme_void(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    axis.title.x = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_blank(),      # remove axis lines
    axis.ticks = element_blank(),     # remove ticks
    axis.text = element_blank()       # remove axis text
  )


# ---- COMBINE PLOTS ----
Blank.correction <- Blank.selection.1 | Blank.selection.2

Blank.correction


# ---- EXPORT AS PNG ----
ggsave(
  filename = "Blank_correction.png",
  plot = Blank.correction,
  width = 8,
  height = 4,
  dpi = 600,
  bg = "white"
)

```

### Mass Resolution

```{r}

filepath <- "C:/Users/DanielMalheiro/OneDrive - Clinical Microbiomics/Documents/R scripts"
setwd(filepath)
# ============================
# 1. Constants
# ============================

mz1 <- 204.1173
mz2 <- 204.1230
int1 <- 2e6
int2 <- 22174204

resolutions <- c("60k" = 60000, "120k" = 120000)

# Use SAME m/z values as the experimental data
x_vals <- mass_spectrum_4$mz

# ============================
# 2. Gaussian Peak Function
# ============================

generate_gaussian <- function(mz_center, intensity, resolution) {
  fwhm <- mz_center / resolution
  sigma <- fwhm / 2.35482
  intensity_vals <- intensity * exp(-(x_vals - mz_center)^2 / (2 * sigma^2))
  return(intensity_vals)
}

# ============================
# 3. Simulation Function
# ============================

simulate_resolution <- function(res_label, resolution) {
  peak1 <- generate_gaussian(mz1, int1, resolution)
  peak2 <- generate_gaussian(mz2, int2, resolution)
  total <- peak1 + peak2
  
  data.frame(
    mz = x_vals,
    peak_204_1173 = peak1,
    peak_204_1230 = peak2,
    combined = total,
    Resolution = res_label
  )
}

# ============================
# 4. Run Simulations
# ============================

sim_60k  <- simulate_resolution("60k",  resolutions["60k"])
sim_120k <- simulate_resolution("120k", resolutions["120k"])

# Combine and reshape simulated data
sim_all <- bind_rows(sim_60k, sim_120k) %>%
  pivot_longer(cols = c("peak_204_1173", "peak_204_1230", "combined"),
               names_to = "Trace",
               values_to = "Intensity")

# ============================
# 5. Prepare Experimental Data
# ============================

mass_spectrum_combine <- mass_spectrum_4 %>%
  select(-scan) %>%
  dplyr::rename(Intensity = intensity) %>%
  mutate(
    Trace = "Experimental",
    Resolution = "Experimental"
  )

# ============================
# 6. Final Combined Dataset
# ============================

combined_simulation <- bind_rows(sim_all, mass_spectrum_combine) %>% 
  filter(!(Trace %in% c("peak_204_1230", "peak_204_1173"))) %>%
  mutate(
    Resolution = recode(Resolution,
      "Experimental" = "Experimental Data",
      "60k" = "60k Resolving Power",
      "120k" = "120k Resolving Power"
    ),
    Resolution = factor(Resolution, 
                        levels = c("Experimental Data", 
                                   "60k Resolving Power", 
                                   "120k Resolving Power"))
  )

# ============================
# 7. Plot
# ============================

 # Plot
mass_simulation_plot <- combined_simulation %>%
  filter(Resolution != "60k Resolving Power") %>%   # remove 60k
  ggplot(aes(x = mz, y = Intensity, color = Resolution)) +
  #geom_vline(xintercept = target_masses, linetype = "dashed", color = "black") +
  geom_line(linewidth = 1) +
  facet_wrap(~Resolution) +
  scale_x_continuous(
    name = "m/z",
    breaks = target_masses,
    labels = scales::label_number(digits = 6)
  ) +
  
  # ---- FIXED COLORS ----
  scale_color_manual(
    values = c(
      "120k Resolving Power" = "#5AAA46",   # green
      "Experimental Data"    = "#C03830"    # red
    )
  ) +
  
  labs(
    x = "m/z",
    y = "Intensity",
    color = NULL
  ) +
  theme_void(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    axis.title.x = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_blank(),      # remove axis lines
    axis.ticks = element_blank(),     # remove ticks
    axis.text = element_blank()       # remove axis text
  )

print(mass_simulation_plot)



# ---- EXPORT AS PNG ----
ggsave(
  filename = "mass_simulation_plot.png",
  plot = mass_simulation_plot,
  width = 8,
  height = 4,
  dpi = 600,
  bg = "white"
)
```

### Dilution

```{r}
# Define axis and zoom settings
x_limits <- c(0, 14)
zoom_limits <- c(0, 10)
vline_positions <- c(0.79, 2.2)

# Filter data
filtered_data_dilu <- long_data_dilu %>%
  filter(
    between(Times, x_limits[1], x_limits[2]),
    Compound == "Glucose-13C6",
    Wash == "NoWash",
    Sample != "Process"
  ) %>%
  mutate(Wash = factor(Wash, levels = c("22x", "08x", "NoWash", "PPT")))

# Summarise per scan/sample
summary_nowash_plot<- filtered_data_dilu %>%
  filter(Sample %in% c("NIST", "Solvent"), Date == "241009") %>%
  group_by(Compound, Scan, Wash, Sample, Dilution) %>%
  summarise(
    avg_time = mean(Times, na.rm = TRUE),
    NIST_n = sum(!is.na(Average[Sample == "NIST"])),
    NIST_mean = mean(Average[Sample == "NIST"], na.rm = TRUE),
    NIST_se = sd(Average[Sample == "NIST"], na.rm = TRUE) / sqrt(NIST_n),
    Solvent_n = sum(!is.na(Average[Sample == "Solvent"])),
    Solvent_mean = mean(Average[Sample == "Solvent"], na.rm = TRUE),
    Solvent_se = sd(Average[Sample == "Solvent"], na.rm = TRUE) / sqrt(Solvent_n),
    .groups = "drop"
  ) %>%
  group_by(Compound, Scan, Wash) %>%
  mutate(
    Solvent_mean = dplyr::first(Solvent_mean[Sample == "Solvent" & !is.na(Solvent_mean)]),
    Solvent_se = dplyr::first(Solvent_se[Sample == "Solvent" & !is.na(Solvent_se)]),
    Solvent_n = dplyr::first(Solvent_n[Sample == "Solvent" & !is.na(Solvent_n)])
  ) %>%
  ungroup() %>%
  filter(Sample != "Solvent") %>%
  mutate(
    ME_NS_mean = ((NIST_mean / Solvent_mean) * 100) - 100,
    ME_NS_se = abs((NIST_mean / Solvent_mean) * 100) *
      sqrt((NIST_se / NIST_mean)^2 + (Solvent_se / Solvent_mean)^2),
    df = pmin(NIST_n, Solvent_n) - 1,
    t_val = qt(0.975, df = df),
    ME_NS_lower = ME_NS_mean - t_val * ME_NS_se,
    ME_NS_upper = ME_NS_mean + t_val * ME_NS_se,
    NIST_lower = NIST_mean - t_val * NIST_se,
    NIST_upper = NIST_mean + t_val * NIST_se,
    Solvent_lower = Solvent_mean - t_val * Solvent_se,
    Solvent_upper = Solvent_mean + t_val * Solvent_se
  )  %>%
  mutate(
    # Standard error of the difference
    se_diff = sqrt(NIST_se^2 + Solvent_se^2),

    # t-statistic for Welch's t-test
    t_stat = (NIST_mean - Solvent_mean) / se_diff,

    # Welch-Satterthwaite degrees of freedom
    df_welch = (NIST_se^2 + Solvent_se^2)^2 /
      ((NIST_se^4 / (NIST_n - 1)) + (Solvent_se^4 / (Solvent_n - 1))),

    # two-sided p-value
    p_value = 2 * pt(-abs(t_stat), df = df_welch)
  ) %>%
mutate(
    Dilution = recode(as.character(Dilution),
      "100" = "100%",
      "050" = "50%",
      "025" = "25%",
      "010" = "10%"
    ),
    Dilution = factor(Dilution, levels = c("100%", "50%", "25%", "10%"))
  )


# ---- Define fixed colors and alpha per dilution ----
summary_nowash_plot <- summary_nowash_plot %>%
  mutate(
    Dilution_color = case_when(
      Dilution == "100%" ~ "#C03830",  # red
      Dilution == "50%"  ~ "#C03830",  # same red
      Dilution == "25%"  ~ "#5AAA46",  # same green
      Dilution == "10%"  ~ "#5AAA46"   # green
    ),
    Dilution_alpha = case_when(
      Dilution == "100%" ~ 1.0,
      Dilution == "50%"  ~ 0.5,
      Dilution == "25%"  ~ 0.5,
      Dilution == "10%"  ~ 1.0
    )
  )

# ---- FINAL PLOT ----
plot_nowash_dilution <- summary_nowash_plot %>%
  filter(between(avg_time, zoom_limits[1], zoom_limits[2])) %>%
  ggplot(aes(
    x = avg_time,
    y = ME_NS_mean + as.numeric(Dilution) * 40,
    group = Dilution
  )) +
  geom_line(aes(color = Dilution_color, alpha = Dilution_alpha),
            size = 0.8, lineend = "round") +

  scale_color_identity() +   # use colors as defined (no legend remapping)
  scale_alpha_identity() +   # use alpha as defined

  labs(
    x = "Retention Time (min)",
    y = "Matrix Effect (%)"
  ) +
  theme_void(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    axis.title.x = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
  )

print(plot_nowash_dilution)

# ---- EXPORT PNG ----
ggsave(
  filename = "Dilution.png",
  plot = plot_nowash_dilution,
  width = 8,
  height = 4,
  dpi = 600,
  bg = "white"
)
```

### MF Correction

```{r}
# Step 1: Filter for the closest `rt` to 4.84 within each group (Wash and Replicate)
combined_eic_df_filtered2 <- combined_eic_df_filtered %>%
  group_by(Wash, Replicate) %>%  
 #filter(rt == rt[which.min(abs(rt - 4.85))]) %>%
  filter(rt == rt[which.max(intensity)]) %>%
  ungroup()  # Remove grouping after filtering

# Step 2: Find the closest `rt`, `Times`, and `Scan` in `matrix_effect_data` for each `rt`
combined_eic_df_filtered2 <- combined_eic_df_filtered2 %>%
  mutate(
    #closest_rt = purrr::map_dbl(rt, ~matrix_effect_data$Times[which.min(abs(matrix_effect_data$Times - .))]),
    closest_time = purrr::map_dbl(rt, ~matrix_effect_data$Times[which.min(abs(matrix_effect_data$Times - .))]),
    closest_scan = purrr::map_dbl(closest_time, ~matrix_effect_data$Scan[which.min(abs(matrix_effect_data$Times - .))]),
    scan_diff = scan - closest_scan  # Calculate the difference of the scans
  ) %>%
  ungroup()  # Remove grouping after mutation

# Step 3: Apply `scan_diff` to the original data and adjust the scan
combined_eic_df_with_shift <- combined_eic_df_filtered %>%
  left_join(
    combined_eic_df_filtered2 %>% select(Wash, Replicate, scan_diff),
    by = c("Wash", "Replicate")
  ) %>%
  mutate(
    adjusted_scan = scan - scan_diff  # Apply the scan shift to get the adjusted scan
  )

# Step 4: Join `Matrix_Effect_Factor` (MEF) based on `adjusted_scan`
combined_eic_df_with_shift <- combined_eic_df_with_shift %>%
  left_join(
    matrix_effect_data %>% select(Wash, Replicate, Scan, Matrix_Effect_Factor, Compound),
    by = c("Wash", "Replicate", "adjusted_scan" = "Scan")
  ) %>%
  mutate(
    corrected_intensity = intensity / Matrix_Effect_Factor,  # Calculate corrected intensity
    Wash = factor(Wash, levels = c("22x", "08x", "04x", "NoWash", "PPT")),  # Ensure Wash is a factor with defined levels
    Wash = recode(Wash,  # Rename Wash levels
                  "22x" = "PLR 22x Wash",
                  "08x" = "PLR 8x Wash",
                  "04x" = "PLR 4x Wash",
                  "NoWash" = "PLR Unwashed",
                  "PPT" = "PPT"),
    Compound_plot = recode(
      Compound,
      "Average"        = "Average",
      "Tryptophan-d5"  = "Tryptophan-d[5]",
      "Leucine-d10"    = "Leucine-d[10]",
      "Glucose-13C6"   = "Glucose-{}^{13}*C[6]"
    )
  )

# View the updated levels and names of the Wash factor
levels(combined_eic_df_with_shift$Wash)

# Step 5: Pivot the data to group `average_intensity` and `corrected_intensity`
combined_eic_df_filtered_long <- combined_eic_df_with_shift %>%
  pivot_longer(
    cols = c(intensity, corrected_intensity),
    names_to = "Intensity_Type", 
    values_to = "Intensity_Value"
  ) %>%
  group_by(Wash, rt, Matrix_Effect_Factor, Sample, Replicate, Intensity_Type, Sequence, Compound, Compound_plot) %>%  # <-- Compound kept
  summarise(Average_Intensity = mean(Intensity_Value, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    Compound = factor(Compound, levels = c("Average", "Tryptophan-d5", "Leucine-d10", "Glucose-13C6"))  # Set the order of levels for Compound
  )

# Calculate scaling factor for Matrix Effect Factor (MEF) to fit on the secondary axis
scaling_factor <- max(combined_eic_df_filtered_long$Average_Intensity, na.rm = TRUE)/ max(combined_eic_df_filtered_long$Matrix_Effect_Factor, na.rm = TRUE)

# Step 7: Plot with alignment by rt and Times
MF_correction <- combined_eic_df_filtered_long %>%
  filter(
    between(rt, 4.7, 5.1),
    Wash == "PLR 4x Wash",
    Compound == "Tryptophan-d5"
  ) %>%
  mutate(
    Intensity_Type = recode(
      Intensity_Type,
      intensity = "Uncorrected Tryptophan Intensity",
      corrected_intensity = "Corrected Tryptophan Intensity"
    ),
    Intensity_Type = factor(
      Intensity_Type,
      levels = c(
        "Uncorrected Tryptophan Intensity",
        "Corrected Tryptophan Intensity",
        "Matrix Factor"
      )
    )
  ) %>%
  ggplot() +
  
  # --- EIC curves for Uncorrected & Corrected ---
  geom_smooth(
  aes(
    x = rt,
    y = Average_Intensity,
    color = Intensity_Type,
    group = interaction(Intensity_Type, Replicate)
  ),
  method = "loess",
  span = 0.17,      # adjust smoothness (lower = more wiggly)
  se = FALSE,
  linewidth = 0.7
) +
  
  # facet grid (optional)
  facet_grid(~ Intensity_Type) +
  
  labs(
    #title = "Overlayed Normalized EICs with Matrix Effect Factor",
    x = "Retention Time (min)",
    y = "Intensity",
    color = "Intensity Type"
  ) +
  
  # --- FIXED COLORS ---
  scale_color_manual(
    values = c(
      "Uncorrected Tryptophan Intensity" = "#C03830",  # RED
      "Corrected Tryptophan Intensity"   = "#5AAA46",  # GREEN
      "Matrix Factor"                    = "red"       # keep or remove
    )
  ) +
  
  theme_void(base_size = 14) +
  theme(
    legend.position = "none",
    strip.text = element_blank(),
    axis.title.x = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
  )

print(MF_correction)


# ---- EXPORT PNG ----
ggsave(
  filename = "MF_correction.png",
  plot = MF_correction,
  width = 8,
  height = 4,
  dpi = 600,
  bg = "white"
)

```
